{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pre_data_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/notebook_util/pre_data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH"
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown Enter dataset location.  \n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.)\n",
        "#@markdown - zipfile example: `/content/drive/My Drive/h/k/a.zip`\n",
        "#@markdown - file folder example: `/content/drive/My Drive/h/k`\n",
        "#@markdown - if data_location_option is not empty, data_location_option will overwrite data_location_default\n",
        "data_location_default = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj_auto_generated/sessions/simplified/tree-session-2020-09-14_23-23-Friedrich_2-target-face-num-1000.zip\" #@param [\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj_auto_generated/sessions/simplified/tree-session-2020-09-14_23-23-Friedrich_2-target-face-num-1000.zip\", \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj_auto_generated/sessions/simplified/tree-sessions-2020-09-10-simplified-26k-target-face-num-1000.zip\", \"/content/drive/My Drive/Hand-Tool-Data-Set/turbosquid_thingiverse_dataset/dataset_ply_out_zipped.zip\", \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Chairs_Princeton/chair_train.zip\", \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj_auto_generated/sessions/simplified/tree-sessions-2020-09-10-simplified-26k-target-face-num-1000-class-label.zip\"] \n",
        "data_location_option = \"\" #@param {type:\"string\"}\n",
        "#@markdown Enter save location and file name of the processed npy file.\n",
        "#@markdown - if save_location is empty, will save to the same folder specified by the data_location  \n",
        "save_location = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Data augmentation Config\n",
        "#@markdown - enter the scale of data augmentation\n",
        "#@markdown - if dataset_size_scale = 2, the final dataset size = len(dataset) * dataset_size_scale\n",
        "dataset_size_scale = 2    #@param {type:\"integer\"}\n",
        "#@markdown - choose rotation augmentation\n",
        "aug_rotation_type = \"random rotation\"  #@param [\"random rotation\", \"axis rotation\"]\n",
        "#@markdown - specify the rotation axis [x,y,z] (only for aug_rotation_type = \"axis rotation\")\n",
        "rotation_axis_x = 0    #@param {type:\"number\"}\n",
        "rotation_axis_y = 1    #@param {type:\"number\"}\n",
        "rotation_axis_z = 0    #@param {type:\"number\"}\n",
        "\n",
        "#@markdown - resolution of the voxelized array (shape resolution**3)\n",
        "resolution = \"32\"    #@param [32, 64]\n",
        "\n",
        "#@markdown - For conditional dataset\n",
        "#@markdown - maximum number of classes to extract based on the data_location path\n",
        "#@markdown - If the dataset to be processed is unconditional, please manually set this to 0\n",
        "num_classes = 0 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#adjust parameter datatype\n",
        "resolution = int(resolution)\n",
        "if data_location_option:\n",
        "    data_location = data_location_option\n",
        "else:\n",
        "    data_location = data_location_default\n",
        "if data_location.endswith(\".zip\"):\n",
        "    dataset = Path(data_location).stem\n",
        "else:\n",
        "    dataset = \"dataset_array_custom\"\n",
        "data_augmentation = True\n",
        "\n",
        "if not save_location:\n",
        "    filename = f\"{dataset}_res{resolution}_aug{dataset_size_scale}\"\n",
        "    if num_classes > 0:\n",
        "        filename = filename + f\"_c{num_classes}.npz\"\n",
        "    else:\n",
        "        filename = filename + \".npy\"\n",
        "    save_location = Path(data_location).parent / filename\n",
        "\n",
        "colab_config = {\n",
        "    \"aug_rotation_type\": aug_rotation_type,\n",
        "    \"data_augmentation\": data_augmentation,\n",
        "    \"aug_rotation_axis\": (rotation_axis_x,rotation_axis_y,rotation_axis_z),\n",
        "    \"data_location\": data_location,\n",
        "    \"dataset\": dataset,\n",
        "    \"resolution\": resolution,\n",
        "    \"num_classes\": num_classes,\n",
        "    \"save_location\":save_location,\n",
        "}\n",
        "\n",
        "for k, v in colab_config.items():\n",
        "    print(f\"=> {k:20}: {v}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt"
      },
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "dataset_path = Path(data_location)\n",
        "\n",
        "from argparse import Namespace\n",
        "config = Namespace(**colab_config)\n",
        "config.seed = 1234\n",
        "config.batch_size = 32\n",
        "\n",
        "print(\"loading BUGAN package latest\")\n",
        "%pip install --upgrade git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "output.clear()\n",
        "\n",
        "from bugan.trainPL import setup_datamodule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k0Th_FtGJ-h"
      },
      "source": [
        "dataModule = setup_datamodule(config, tmp_folder=\"/tmp/\")\r\n",
        "dataModule.prepare_data()\r\n",
        "dataModule.setup()\r\n",
        "dataloader = dataModule.train_dataloader()\r\n",
        "num_classes = dataModule.num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwysDDE4IzCo"
      },
      "source": [
        "final_data_array = []\r\n",
        "final_index_array = []\r\n",
        "\r\n",
        "for i in range(dataset_size_scale):\r\n",
        "    if num_classes is None:\r\n",
        "        for dataset_batch in dataloader:\r\n",
        "            #len of shape of data should be around 4 - 6\r\n",
        "            dataset_batch = dataset_batch.detach().cpu().numpy()\r\n",
        "            if len(dataset_batch.shape) > 5:\r\n",
        "                dataset_batch = dataset_batch[:,0]\r\n",
        "            elif len(dataset_batch.shape) < 5:\r\n",
        "                dataset_batch = dataset_batch[:,np.newaxis,:,:,:]\r\n",
        "            final_data_array.append(dataset_batch)\r\n",
        "    else:\r\n",
        "        for dataset_batch, dataset_index in dataloader:\r\n",
        "            #len of shape of data should be around 4 - 6\r\n",
        "            dataset_batch = dataset_batch.detach().cpu().numpy()\r\n",
        "            if len(dataset_batch.shape) > 5:\r\n",
        "                dataset_batch = dataset_batch[:,0]\r\n",
        "            elif len(dataset_batch.shape) < 5:\r\n",
        "                dataset_batch = dataset_batch[:,np.newaxis,:,:,:]\r\n",
        "            final_data_array.append(dataset_batch)\r\n",
        "            final_index_array.append(dataset_index)\r\n",
        "\r\n",
        "# concatenate all the data samples\r\n",
        "final_data_array = np.concatenate(final_data_array, axis=0)\r\n",
        "print(\"final_data_array.shape:\", final_data_array.shape)\r\n",
        "\r\n",
        "#save to save_location\r\n",
        "if num_classes is None:\r\n",
        "    np.save(save_location, final_data_array)\r\n",
        "else:\r\n",
        "    final_index_array = np.concatenate(final_index_array, axis=0)\r\n",
        "    print(\"final_index_array.shape:\", final_index_array.shape)\r\n",
        "    np.savez(save_location, data=final_data_array, index=final_index_array,class_list=dataModule.class_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}