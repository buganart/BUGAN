{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script_GAN_ver2_voxel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/script_GAN_ver2_voxel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f31c23e5-0f97-4b92-9548-fc605c95471a"
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "279d806e-6c55-4da7-9ef1-fda9d1fd420d"
      },
      "source": [
        "#right click shared folder IRCMS_GAN_collaborative_database and \"Add shortcut to Drive\" to My drive\n",
        "%cd drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj/generated_files/\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ylB2p6N0qQ-G4OsBuwcZ9C0tsqVu9ww4/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj/generated_files\n",
            "maple_1_voxel_size03.ply  old_1_voxel_size03.ply  wandb\n",
            "maple_2_voxel_size03.ply  old_2_voxel_size03.ply\n",
            "maple_3_voxel_size03.ply  old_3_voxel_size03.ply\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LzAiBuWu6pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install open3d\n",
        "!pip install wandb -q\n",
        "output.clear()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpnFurJt0Pu",
        "colab_type": "text"
      },
      "source": [
        "#add libraries, and login to wandb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_fQzoLaVP2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login\n",
        "output.clear()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "963be3fe-1145-4022-8133-5dc1654595fa"
      },
      "source": [
        "wandb.init(project=\"tree-gan\")\n",
        "wandb.run.name = str(wandb.run.entity) +\" modelv2 g1d1 \"+ str(wandb.run.id) # number N after g and d means lr are 0.0001 * N\n",
        "wandb.watch_called = False"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/bugan/tree-gan\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/bugan/tree-gan/runs/3oaoqt4o\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan/runs/3oaoqt4o</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gr3PMthXkdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keep track of hyperparams\n",
        "config = wandb.config\n",
        "config.batch_size = 1\n",
        "config.test_batch_size = 1\n",
        "config.epochs = 100\n",
        "config.g_lr = 0.0001\n",
        "config.d_lr = 0.0001            \n",
        "config.seed = 1234\n",
        "config.log_interval = 10"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI",
        "colab_type": "text"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwCa8fUMRcZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def voxel2arrayCentered(voxel, tree_size_scale = 1):\n",
        "    array_size = np.array([250, 250, 250])\n",
        "    vox_array = np.zeros(array_size, dtype=int)  \n",
        "    tree_size = np.array(voxel.get_axis_aligned_bounding_box().get_extent())\n",
        "    tree_size = np.ceil(tree_size / tree_size_scale)    #voxel_size = tree_size_scale\n",
        "    tree_center = (np.ceil(tree_size / 2)).astype(int)\n",
        "\n",
        "    vox_list = voxel.get_voxels()\n",
        "    for vox in vox_list:\n",
        "        coord = vox.grid_index\n",
        "        #center the tree\n",
        "        coord = coord - tree_center + (array_size/2)\n",
        "        coord = tuple(coord.astype(int))\n",
        "\n",
        "        vox_array[coord] = 1.\n",
        "\n",
        "    return vox_array.astype(bool)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf2GIoAjLCCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f5cd897a-99ec-4c56-c420-ddcee184d0d9"
      },
      "source": [
        "#process all files in the generated file folder to generate dataset \n",
        "import os\n",
        "\n",
        "dataset = []\n",
        "for file_name in os.listdir():\n",
        "    if file_name.endswith(\"voxel_size03.ply\"):\n",
        "        #note that the voxel_size of vox is 0.3, so we scale it back to one for indexing\n",
        "        print(file_name)\n",
        "        dataset.append(voxel2arrayCentered(o3d.io.read_voxel_grid(file_name), 0.3))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maple_2_voxel_size03.ply\n",
            "maple_3_voxel_size03.ply\n",
            "maple_1_voxel_size03.ply\n",
            "old_1_voxel_size03.ply\n",
            "old_2_voxel_size03.ply\n",
            "old_3_voxel_size03.ply\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "187e3860-16dd-4122-d629-e4a59856d918"
      },
      "source": [
        "dataset = torch.tensor(dataset)\n",
        "print(torch.unsqueeze(dataset, -1).shape)\n",
        "tensor_dataset = TensorDataset(torch.unsqueeze(dataset, 1))\n",
        "dataloader = DataLoader(tensor_dataset, batch_size=config.batch_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 250, 250, 250, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIaapsqSK5h2",
        "colab_type": "text"
      },
      "source": [
        "#model description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodI2E4ANdYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input: 128-d noise vector\n",
        "#output: (250,250,250) array with values in [0,1]\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.fc_channel = 8 #16\n",
        "        self.fc_size = 5\n",
        "\n",
        "        num_unit1 = self.fc_channel   \n",
        "        num_unit2 = 8   #32\n",
        "        num_unit3 = 8   #64\n",
        "        num_unit4 = 8   #128\n",
        "        num_unit5 = 8   #256\n",
        "        num_unit6 = 8   #512\n",
        "        self.gen_fc = nn.Linear(128, num_unit1 * self.fc_size * self.fc_size * self.fc_size)\n",
        "        self.gen = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit1, num_unit2, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit2, num_unit3, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit4, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit5, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit5, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit6, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit5, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit3, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit1, 3, 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit1, 1, 3, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.gen_fc(x)\n",
        "        x = x.view(x.shape[0], self.fc_channel, self.fc_size, self.fc_size, self.fc_size)\n",
        "        x = self.gen(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        num_unit1 = 8   #16\n",
        "        num_unit2 = 8   #32\n",
        "        num_unit3 = 8   #64\n",
        "        num_unit4 = 8   #128\n",
        "        num_unit5 = 8   #256\n",
        "        num_unit6 = 8   #512\n",
        "        \n",
        "        self.dis = nn.Sequential(\n",
        "            nn.Conv3d(1, num_unit1, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit3, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit3, num_unit5, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit6, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit6, num_unit5, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit4, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit4, num_unit3, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit3, num_unit3, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit3, num_unit2, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit2, num_unit2, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit2, num_unit1, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit1, 3, 1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.dis_fc = nn.Sequential(\n",
        "            nn.Linear(num_unit1 * 3 * 3 * 3, 128),\n",
        "            nn.LeakyReLU(0.1, True),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dis(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dis_fc(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6CzSW9jATSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# G = Generator().to(device)\n",
        "# summary(G, (128,))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFZSVCCBIuPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# D = Discriminator().to(device)\n",
        "# summary(D, (1, 250, 250, 250))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrRSqnqK20W",
        "colab_type": "text"
      },
      "source": [
        "#functions for pytorch network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHZ9sGFVspXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def array2voxel(array):\n",
        "    coord_list = []\n",
        "    if len(array.shape) == 5:\n",
        "        array = array[0][0]\n",
        "    x,y,z = array.shape\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            for k in range(z):\n",
        "                if array[i,j,k] > 0.5:\n",
        "                    coord_list.append([i,j,k])\n",
        "    print(len(coord_list))\n",
        "    if len(coord_list) == 0:\n",
        "        return np.array([[0,0,0]])  #return at least one point to prevent wandb 3dobject error\n",
        "    return np.array(coord_list)\n",
        "\n",
        "def train_model(generator, discriminator, dataloader):   \n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='sum')\n",
        "    #optimizer\n",
        "    dis_optimizer = optim.Adam(discriminator.parameters(), lr=config.d_lr)\n",
        "    gen_optimizer = optim.Adam(generator.parameters(), lr=config.g_lr)   \n",
        "\n",
        "    #log models\n",
        "    wandb.watch(generator, log=\"all\")\n",
        "    wandb.watch(discriminator, log=\"all\")\n",
        "\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "    for epoch in range(config.epochs):\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        d_ep_loss = 0.\n",
        "        g_ep_loss = 0.\n",
        "        for dataset_batch in dataloader:\n",
        "            dis_optimizer.zero_grad()\n",
        "            gen_optimizer.zero_grad()\n",
        "            \n",
        "            dloss, gloss = compute_loss(generator, discriminator, dataset_batch)\n",
        "\n",
        "\n",
        "            #optimize generator\n",
        "            gloss.backward()\n",
        "            gen_optimizer.step()\n",
        "\n",
        "            #optimize discriminator\n",
        "            dloss.backward()\n",
        "            dis_optimizer.step()\n",
        "          \n",
        "\n",
        "            #record loss\n",
        "            d_ep_loss += dloss.detach()  \n",
        "            g_ep_loss += gloss.detach()\n",
        "\n",
        "        #after each epoch, record total loss and sample generated obj\n",
        "        d_losses.append(d_ep_loss)\n",
        "        g_losses.append(g_ep_loss)\n",
        "        print(\"discriminator, epoch\"+str(epoch)+\" : \"+str(d_ep_loss))\n",
        "        print(\"generator, epoch\"+str(epoch)+\" : \"+str(g_ep_loss))\n",
        "\n",
        "        #save model if necessary\n",
        "        if epoch % config.log_interval == 0:\n",
        "            sample_tree = array2voxel(generate_tree(generator))\n",
        "\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss,\n",
        "            \"sample_tree\": wandb.Object3D(sample_tree)})\n",
        "            torch.save(generator.state_dict(), os.path.join(wandb.run.dir, 'generator.pth'))\n",
        "            torch.save(discriminator.state_dict(), os.path.join(wandb.run.dir, 'discriminator.pth'))\n",
        "        else:\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss})\n",
        "    \n",
        "    #training end, save model again\n",
        "    torch.save(generator.state_dict(), os.path.join(wandb.run.dir, 'generator.pth'))\n",
        "    torch.save(discriminator.state_dict(), os.path.join(wandb.run.dir, 'discriminator.pth'))\n",
        "    print(d_losses)\n",
        "    print(g_losses)\n",
        "\n",
        "# this function calculate loss of the model, \n",
        "def compute_loss(generator, discriminator, dataset_batch):\n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='sum')   \n",
        "\n",
        "\n",
        "    dataset_batch = dataset_batch[0]\n",
        "    dataset_batch = dataset_batch.float().to(device)\n",
        "    batch_size = dataset_batch.shape[0]\n",
        "        \n",
        "    #labels\n",
        "    real_label = torch.unsqueeze(torch.ones(batch_size),1).float().to(device)\n",
        "    fake_label = torch.unsqueeze(torch.zeros(batch_size),1).float().to(device)\n",
        "\n",
        "    ############\n",
        "    #   discriminator\n",
        "    ############\n",
        "    #generate fake trees\n",
        "    z = torch.randn(batch_size, 128).float().to(device) #128-d noise vector\n",
        "    tree_fake = generator(z)\n",
        "\n",
        "    #real data (data from dataloader)\n",
        "    dout_real = discriminator(dataset_batch)\n",
        "    dloss_real = criterion(dout_real, real_label)\n",
        "    score_real = dout_real\n",
        "    #fake data (data from generator)            \n",
        "    dout_fake = discriminator(tree_fake.clone().detach())   #detach so no double update on the same batch of tree_fake\n",
        "    dloss_fake = criterion(dout_fake, fake_label)\n",
        "    score_fake = dout_fake\n",
        "\n",
        "    #loss function (discriminator classify real data vs generated data)\n",
        "    dloss = dloss_real + dloss_fake\n",
        "\n",
        "    ############\n",
        "    #   generator\n",
        "    ############\n",
        "\n",
        "    #tree_fake is already computed above\n",
        "    dout_fake = discriminator(tree_fake)\n",
        "    #generator should generate trees that discriminator think they are real\n",
        "    gloss = criterion(dout_fake, real_label)    \n",
        "\n",
        "    return dloss, gloss\n",
        "\n",
        "\n",
        "def save_model(generator, discriminator, g_path = os.path.join(wandb.run.dir, 'generator.pth') , d_path = os.path.join(wandb.run.dir, 'discriminator.pth')):\n",
        "    torch.save(generator.state_dict(), g_path)\n",
        "    torch.save(discriminator.state_dict(), d_path)\n",
        "\n",
        "def load_model(g_path = os.path.join(wandb.run.dir, 'generator.pth'), d_path = os.path.join(wandb.run.dir, 'discriminator.pth')):\n",
        "    generator = Generator()\n",
        "    generator.load_state_dict(torch.load(g_path))\n",
        "    generator.eval()\n",
        "\n",
        "    discriminator = Discriminator()\n",
        "    discriminator.load_state_dict(torch.load(d_path))\n",
        "    discriminator.eval()\n",
        "    return generator, discriminator\n",
        "\n",
        "def generate_tree(generator, num_trees = 1):\n",
        "    \n",
        "    #generate noise vector\n",
        "    z = torch.randn(num_trees, 128).to(device)\n",
        "    generator.to(device).eval()\n",
        "    tree_fake = generator(z)\n",
        "    return tree_fake.detach().cpu().numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3",
        "colab_type": "text"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQWIWapYOsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "9bb8dfcd-1a28-4026-e05c-826bd80f72a7"
      },
      "source": [
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "train_model(G, D, dataloader)        #if dataloader has only 1 tree, the training time is 72s per epoch."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch0 : tensor(8.3226, device='cuda:0')\n",
            "generator, epoch0 : tensor(3.9907, device='cuda:0')\n",
            "15625000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/wandb/data_types.py:464: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  elif 'type' in data_or_path:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch1 : tensor(8.3237, device='cuda:0')\n",
            "generator, epoch1 : tensor(3.9730, device='cuda:0')\n",
            "discriminator, epoch2 : tensor(8.3251, device='cuda:0')\n",
            "generator, epoch2 : tensor(3.9531, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}