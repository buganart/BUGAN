{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script_GAN_ver3_voxelsize1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/script_GAN_ver3_voxelsize1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "013a5a6d-6e49-40cf-e4b8-7b955e492428"
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74061bd1-2c35-46a2-fd77-124dfb5ca3df"
      },
      "source": [
        "#right click shared folder IRCMS_GAN_collaborative_database and \"Add shortcut to Drive\" to My drive\n",
        "%cd drive/My Drive/IRCMS_GAN_collaborative_database/\n",
        "\n",
        "#record paths to resources\n",
        "data_path = \"Research/Peter/Tree_3D_models_obj/obj_files/\"\n",
        "run_path = \"Experiments/colab-treegan/\"\n",
        "\n",
        "# !ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ylB2p6N0qQ-G4OsBuwcZ9C0tsqVu9ww4/IRCMS_GAN_collaborative_database\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LzAiBuWu6pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install trimesh\n",
        "!pip install wandb -q\n",
        "output.clear()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpnFurJt0Pu",
        "colab_type": "text"
      },
      "source": [
        "#add libraries, and login to wandb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import os\n",
        "import trimesh\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# WandB â€“ Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_fQzoLaVP2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login\n",
        "output.clear()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "cf9a714b-16c0-49c4-9610-946c08e1fc22"
      },
      "source": [
        "#id None to start a new run. For resuming run, put the id of the run below\n",
        "id = \"11d67bs4\"\n",
        "resume = False\n",
        "if id is None:\n",
        "    id = wandb.util.generate_id()\n",
        "else:\n",
        "    resume = True\n",
        "\n",
        "run = wandb.init(project=\"tree-gan\", id=id, resume=\"allow\", dir=run_path)\n",
        "print(\"run id:\" + str(wandb.run.id))\n",
        "wandb.run.name = str(wandb.run.id)\n",
        "wandb.watch_called = False\n",
        "wandb.run.save_code = True\n",
        "\n",
        "wandb.run.group = \"GANv3.2\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/bugan/tree-gan\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/bugan/tree-gan/runs/11d67bs4\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan/runs/11d67bs4</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "run id:11d67bs4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Streaming file created twice in same run: Experiments/colab-treegan/wandb/run-20200814_080813-11d67bs4/wandb-history.jsonl\n",
            "Streaming file created twice in same run: Experiments/colab-treegan/wandb/run-20200814_080813-11d67bs4/wandb-events.jsonl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww3zbHkxAw8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keep track of hyperparams\n",
        "config = wandb.config\n",
        "config.batch_size = 16\n",
        "config.epochs = 10\n",
        "config.g_lr = 0.0001\n",
        "config.g_layer = 2\n",
        "config.d_lr = 0.00003           \n",
        "config.d_layer = 1\n",
        "config.seed = 1234\n",
        "config.log_interval = 20\n",
        "config.data_augmentation = True\n",
        "config.num_augment_data = 4"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI",
        "colab_type": "text"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qoPjcAGrimt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mesh2arrayCentered(mesh, voxel_size = 1, array_length = 64):\n",
        "    #given array length 64, voxel size 2, then output array size is [128,128,128]\n",
        "    array_size = np.ceil(np.array([array_length, array_length, array_length]) / voxel_size).astype(int)\n",
        "    vox_array = np.zeros(array_size, dtype=bool)    #tanh: voxel representation [-1,1], sigmoid: [0,1]\n",
        "    #scale mesh extent to fit array_length\n",
        "    max_length = np.max(np.array(mesh.extents))\n",
        "    mesh = mesh.apply_transform(trimesh.transformations.scale_matrix((array_length-1)/max_length))  #now the extent is [array_length**3]\n",
        "    v = mesh.voxelized(voxel_size)  #max voxel array length = array_length / voxel_size\n",
        "\n",
        "    #find indices in the v.matrix to center it in vox_array\n",
        "    indices = ((array_size - v.matrix.shape)/2).astype(int)\n",
        "    vox_array[indices[0]:indices[0]+v.matrix.shape[0], indices[1]:indices[1]+v.matrix.shape[1], indices[2]:indices[2]+v.matrix.shape[2]] = v.matrix\n",
        "\n",
        "    return vox_array\n",
        "\n",
        "\n",
        "def data_augmentation(mesh, array_length = 64, num_augment_data = 4, scale_max_margin = 3):\n",
        "\n",
        "    retval = np.zeros((num_augment_data, array_length, array_length, array_length))\n",
        "\n",
        "    for i in range(num_augment_data):\n",
        "\n",
        "        #first select rotation angle (angle in radian)\n",
        "        angle = 2 * np.pi * (np.random.rand(1)[0])\n",
        "\n",
        "        #scale is implemented based on the bounding box with box margin (larger margin, smaller scale)\n",
        "        box_margin = np.random.randint(scale_max_margin + 1)\n",
        "\n",
        "        #pick a random starting point within margin as translation\n",
        "        initial_position = np.random.randint(box_margin + 1, size=3)\n",
        "\n",
        "        result_array = modify_mesh(mesh, array_length, angle, box_margin, initial_position)\n",
        "        retval[i] = result_array\n",
        "\n",
        "    return retval\n",
        "\n",
        "\n",
        "def modify_mesh(mesh, out_array_length, rot_angle, scale_box_margin, array_init_pos):\n",
        "    #first copy mesh\n",
        "    mesh = mesh.copy()\n",
        "    #rotate mesh by rot_angle in radian\n",
        "    mesh = mesh.apply_transform(trimesh.transformations.rotation_matrix(rot_angle, (0,1,0)))\n",
        "\n",
        "    #scale is implemented based on the bounding box with box margin (larger margin, smaller scale)\n",
        "        #example (assume out_array_length=64): margin = 0, bounding box shape = (64,64,64); margin = 3, bounding box shape = (61,61,61)\n",
        "    scaled_size = out_array_length - scale_box_margin\n",
        "    mesh_array = mesh2arrayCentered(mesh, array_length = scaled_size)\n",
        "\n",
        "    #put them into bounding box (and translation)\n",
        "    retval = np.zeros((out_array_length, out_array_length, out_array_length))\n",
        "    #apply translation by selecting initial position\n",
        "        #example: same mesh array of size (61,61,61) but with two position (0,1,0) and (1,0,0) is just a translation of 2 units\n",
        "    x,y,z = array_init_pos\n",
        "    retval[x:x+scaled_size, y:y+scaled_size, z:z+scaled_size] = mesh_array\n",
        "\n",
        "    return retval"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTTG-zCl8kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "57e68caa-8556-47cd-e74c-a96c1ada58e6"
      },
      "source": [
        "dataset_artifact = run.use_artifact(\"dataset-tree:full\", type='dataset')\n",
        "dir_dict = dataset_artifact.metadata['dir_dict']\n",
        "artifact_dir = dataset_artifact.download()\n",
        "print(dir_dict)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dataset-tree:full, 566.02MB. 216 files... Done. 19.4s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'old': ['old_1.obj', 'old_2.obj', 'old_3.obj'], 'raft': ['raft_1_1.obj', 'raft_1_2.obj', 'raft_1_4.obj', 'raft_1_3.obj', 'raft_1_5.obj', 'raft_1_6.obj', 'raft_1_7.obj', 'raft_1_8.obj', 'raft_1_9.obj', 'raft_1_10.obj'], 'group': ['group_1_1.obj', 'group_1_2.obj', 'group_1_3.obj', 'group_1_4.obj', 'group_1_5.obj', 'group_1_6.obj', 'group_1_7.obj', 'group_1_8.obj', 'group_1_9.obj', 'group_1_10.obj'], 'leaning': ['leaning_1_1.obj', 'leaning_1_2.obj', 'leaning_1_3.obj', 'leaning_1_4.obj', 'leaning_1_5.obj', 'leaning_1_6.obj', 'leaning_1_7.obj', 'leaning_1_8.obj', 'leaning_1_9.obj', 'leaning_1_10.obj', 'leaning_2_1.obj', 'leaning_2_2.obj', 'leaning_2_3.obj', 'leaning_2_4.obj', 'leaning_2_5.obj', 'leaning_2_6.obj', 'leaning_2_8.obj', 'leaning_2_10.obj', 'leaning_2_7.obj', 'leaning_2_9.obj'], 'windswept': ['windswept_1_1.obj', 'windswept_1_2.obj', 'windswept_1_3.obj', 'windswept_1_4.obj', 'windswept_1_5.obj', 'windswept_1_6.obj', 'windswept_1_7.obj', 'windswept_1_8.obj', 'windswept_1_9.obj', 'windswept_1_10.obj', 'windswept_2_1.obj', 'windswept_2_2.obj', 'windswept_2_3.obj', 'windswept_2_4.obj', 'windswept_2_5.obj', 'windswept_2_6.obj', 'windswept_2_7.obj', 'windswept_2_8.obj', 'windswept_2_9.obj', 'windswept_2_10.obj'], 'double_trunk': ['double_trunk_1_1.obj', 'double_trunk_1_2.obj', 'double_trunk_1_3.obj', 'double_trunk_1_4.obj', 'double_trunk_1_5.obj', 'double_trunk_1_6.obj', 'double_trunk_1_7.obj', 'double_trunk_1_8.obj', 'double_trunk_1_9.obj', 'double_trunk_1_10.obj', 'double_trunk_2_1.obj', 'double_trunk_2_2.obj', 'double_trunk_2_3.obj', 'double_trunk_2_4.obj', 'double_trunk_2_5.obj', 'double_trunk_2_6.obj', 'double_trunk_2_7.obj', 'double_trunk_2_8.obj', 'double_trunk_2_9.obj', 'double_trunk_2_10.obj'], 'semi_cascade': ['semi_cascade_1_1.obj', 'semi_cascade_1_2.obj', 'semi_cascade_1_3.obj', 'semi_cascade_1_4.obj', 'semi_cascade_1_5.obj', 'semi_cascade_1_6.obj', 'semi_cascade_1_7.obj', 'semi_cascade_1_8.obj', 'semi_cascade_1_9.obj', 'semi_cascade_1_10.obj', 'semi_cascade_2_1.obj', 'semi_cascade_2_2.obj', 'semi_cascade_2_3.obj', 'semi_cascade_2_4.obj', 'semi_cascade_2_5.obj', 'semi_cascade_2_6.obj', 'semi_cascade_2_7.obj', 'semi_cascade_2_8.obj', 'semi_cascade_2_9.obj', 'semi_cascade_2_10.obj'], 'zan_gentlemen': ['zan_gentlemen_1_1.obj', 'zan_gentlemen_1_3.obj', 'zan_gentlemen_1_2.obj', 'zan_gentlemen_1_4.obj', 'zan_gentlemen_1_5.obj', 'zan_gentlemen_1_6.obj', 'zan_gentlemen_1_7.obj', 'zan_gentlemen_1_8.obj', 'zan_gentlemen_1_9.obj', 'zan_gentlemen_1_10.obj', 'zan_gentlemen_2_1.obj', 'zan_gentlemen_2_2.obj', 'zan_gentlemen_2_3.obj', 'zan_gentlemen_2_4.obj', 'zan_gentlemen_2_5.obj', 'zan_gentlemen_2_6.obj', 'zan_gentlemen_2_7.obj', 'zan_gentlemen_2_8.obj', 'zan_gentlemen_2_9.obj', 'zan_gentlemen_2_10.obj', 'zan_gentlemen_3_1.obj', 'zan_gentlemen_3_2.obj', 'zan_gentlemen_3_3.obj', 'zan_gentlemen_3_4.obj', 'zan_gentlemen_3_5.obj', 'zan_gentlemen_3_6.obj', 'zan_gentlemen_3_7.obj', 'zan_gentlemen_3_8.obj', 'zan_gentlemen_3_9.obj', 'zan_gentlemen_3_10.obj', 'zan_gentlemen_4_1.obj', 'zan_gentlemen_4_2.obj', 'zan_gentlemen_4_3.obj', 'zan_gentlemen_4_4.obj', 'zan_gentlemen_4_5.obj', 'zan_gentlemen_4_6.obj', 'zan_gentlemen_4_7.obj', 'zan_gentlemen_4_8.obj', 'zan_gentlemen_4_9.obj', 'zan_gentlemen_4_10.obj', 'zan_gentlemen_5_1.obj', 'zan_gentlemen_5_2.obj', 'zan_gentlemen_5_3.obj', 'zan_gentlemen_5_4.obj', 'zan_gentlemen_5_5.obj', 'zan_gentlemen_5_6.obj', 'zan_gentlemen_5_8.obj', 'zan_gentlemen_5_9.obj', 'zan_gentlemen_5_10.obj', 'zan_gentlemen_5_7.obj'], 'formal_upright': ['formal_upright_1_1.obj', 'formal_upright_1_2.obj', 'formal_upright_1_3.obj', 'formal_upright_1_4.obj', 'formal_upright_1_5.obj', 'formal_upright_1_6.obj', 'formal_upright_1_7.obj', 'formal_upright_1_9.obj', 'formal_upright_1_10.obj', 'formal_upright_1_8.obj', 'formal_upright_2_1.obj', 'formal_upright_2_2.obj', 'formal_upright_2_3.obj', 'formal_upright_2_4.obj', 'formal_upright_2_5.obj', 'formal_upright_2_6.obj', 'formal_upright_2_7.obj', 'formal_upright_2_8.obj', 'formal_upright_2_10.obj', 'formal_upright_2_9.obj'], 'mustard_sapling': ['mustard_sapling_2_1.obj', 'mustard_sapling_2_2.obj', 'mustard_sapling_2_3.obj', 'mustard_sapling_2_4.obj', 'mustard_sapling_2_5.obj', 'mustard_sapling_2_6.obj', 'mustard_sapling_2_7.obj', 'mustard_sapling_2_8.obj', 'mustard_sapling_2_9.obj', 'mustard_sapling_2_10.obj'], 'informal_upright': ['informal_upright_1_1.obj', 'informal_upright_1_2.obj', 'informal_upright_1_3.obj', 'informal_upright_1_4.obj', 'informal_upright_1_5.obj', 'informal_upright_1_6.obj', 'informal_upright_1_7.obj', 'informal_upright_1_8.obj', 'informal_upright_1_9.obj', 'informal_upright_1_10.obj', 'informal_upright_2_1.obj', 'informal_upright_2_2.obj', 'informal_upright_2_3.obj', 'informal_upright_2_4.obj', 'informal_upright_2_5.obj', 'informal_upright_2_6.obj', 'informal_upright_2_7.obj', 'informal_upright_2_8.obj', 'informal_upright_2_9.obj', 'informal_upright_2_10.obj'], 'mustard_reaching': ['mustard_reaching_1_1.obj', 'mustard_reaching_1_2.obj', 'mustard_reaching_1_3.obj', 'mustard_reaching_1_4.obj', 'mustard_reaching_1_5.obj', 'mustard_reaching_1_6.obj', 'mustard_reaching_1_7.obj', 'mustard_reaching_1_8.obj', 'mustard_reaching_1_9.obj', 'mustard_reaching_1_10.obj'], 'pn_tall_straight': ['pn_tall_straight_1.obj'], 'maple_example2.obj': ['maple_example2.obj'], 'pn_tall_straight_old': ['pn_tall_straight_old_1.obj']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh1RWa6qoVUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = []\n",
        "\n",
        "for data_cat in dir_dict:\n",
        "    filename_list = dir_dict[data_cat]\n",
        "    for filename in filename_list:\n",
        "        filename = artifact_dir + \"/\" + data_cat + \"/\" + filename\n",
        "        m = trimesh.load(filename, force='mesh')\n",
        "        #augment data\n",
        "        if config.data_augmentation:\n",
        "            array = data_augmentation(m, num_augment_data = config.num_augment_data)\n",
        "        else:\n",
        "            array = mesh2arrayCentered(mesh)[np.newaxis, :, :, :]\n",
        "        dataset.append(array)\n",
        "#now all the returned array contains multiple samples\n",
        "dataset = np.concatenate(dataset)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fbb20b9-9503-4f75-f2de-8ee954aef472"
      },
      "source": [
        "dataset = torch.tensor(dataset)\n",
        "print(torch.unsqueeze(dataset, -1).shape)\n",
        "tensor_dataset = TensorDataset(torch.unsqueeze(dataset, 1))\n",
        "\n",
        "dataloader = DataLoader(tensor_dataset, batch_size=config.batch_size, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([864, 64, 64, 64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIaapsqSK5h2",
        "colab_type": "text"
      },
      "source": [
        "#model description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodI2E4ANdYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input: 128-d noise vector\n",
        "#output: (250,250,250) array with values in [0,1]\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, layer_per_block=1):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "\n",
        "        #layer_per_block must be >= 1\n",
        "        if layer_per_block < 1:\n",
        "            layer_per_block = 1\n",
        "\n",
        "        self.fc_channel = 8 #16\n",
        "        self.fc_size = 4\n",
        "\n",
        "        num_unit1 = self.fc_channel   \n",
        "        num_unit2 = 16   #32\n",
        "        num_unit3 = 32   #64\n",
        "        num_unit4 = 64   #128\n",
        "        num_unit5 = 32   #256\n",
        "        num_unit6 = 16   #512\n",
        "\n",
        "        num_layer_unit_list = [num_unit1, num_unit2, num_unit3, num_unit4, num_unit5, num_unit6]\n",
        "        gen_module = []\n",
        "        #5 blocks (need 4 pool to reduce size)\n",
        "        for i in range(5):\n",
        "            num_layer_unit1, num_layer_unit2 = num_layer_unit_list[i], num_layer_unit_list[i+1]\n",
        "\n",
        "            gen_module.append(nn.ConvTranspose3d(num_layer_unit1, num_layer_unit2, 3, 1, padding = 1))\n",
        "            gen_module.append(nn.BatchNorm3d(num_layer_unit2))\n",
        "            gen_module.append(nn.ReLU(True))\n",
        "\n",
        "            for _ in range(layer_per_block):\n",
        "                gen_module.append(nn.ConvTranspose3d(num_layer_unit2, num_layer_unit2, 3, 1, padding = 1))\n",
        "                gen_module.append(nn.BatchNorm3d(num_layer_unit2))\n",
        "                gen_module.append(nn.ReLU(True))\n",
        "\n",
        "            gen_module.append(nn.Upsample(scale_factor=2, mode='trilinear'))\n",
        "\n",
        "        #remove extra pool layer\n",
        "        gen_module = gen_module[:-1]\n",
        "\n",
        "        #add final sigmoid \n",
        "        gen_module.append(nn.ConvTranspose3d(num_unit6, 1, 3, 1, padding = 1))\n",
        "        gen_module.append(nn.Sigmoid())\n",
        "\n",
        "        \n",
        "\n",
        "        self.gen_fc = nn.Linear(128, num_unit1 * self.fc_size * self.fc_size * self.fc_size)\n",
        "        self.gen = nn.Sequential(*gen_module)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.gen_fc(x)\n",
        "        x = x.view(x.shape[0], self.fc_channel, self.fc_size, self.fc_size, self.fc_size)\n",
        "        x = self.gen(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, layer_per_block=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "         #layer_per_block must be >= 1\n",
        "        if layer_per_block < 1:\n",
        "            layer_per_block = 1\n",
        "\n",
        "        num_unit1 = 1   #input channel number\n",
        "        num_unit2 = 8   #32\n",
        "        num_unit3 = 16   #64\n",
        "        num_unit4 = 32  #128\n",
        "        num_unit5 = 16   #256\n",
        "        num_unit6 = 8   #512\n",
        "\n",
        "\n",
        "        num_layer_unit_list = [num_unit1, num_unit2, num_unit3, num_unit4, num_unit5, num_unit6]\n",
        "        dis_module = []\n",
        "        #5 blocks (need 4 pool to reduce size)\n",
        "        for i in range(5):\n",
        "            num_layer_unit1, num_layer_unit2 = num_layer_unit_list[i], num_layer_unit_list[i+1]\n",
        "\n",
        "            dis_module.append(nn.Conv3d(num_layer_unit1, num_layer_unit2, 3, 1, padding = 1))\n",
        "            dis_module.append(nn.BatchNorm3d(num_layer_unit2))\n",
        "            dis_module.append(nn.ReLU(True))\n",
        "\n",
        "            for _ in range(layer_per_block):\n",
        "                dis_module.append(nn.Conv3d(num_layer_unit2, num_layer_unit2, 3, 1, padding = 1))\n",
        "                dis_module.append(nn.BatchNorm3d(num_layer_unit2))\n",
        "                dis_module.append(nn.ReLU(True))\n",
        "\n",
        "            dis_module.append(nn.MaxPool3d((2, 2, 2)))\n",
        "\n",
        "        #remove extra pool layer\n",
        "        dis_module = dis_module[:-1]\n",
        "\n",
        "        \n",
        "        self.dis = nn.Sequential(*dis_module)\n",
        "\n",
        "        self.dis_fc1 = nn.Sequential(\n",
        "            nn.Linear(num_unit6 * 4 * 4 * 4, 128),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.dis_fc2 = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dis(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        fx = self.dis_fc1(x)\n",
        "        x = self.dis_fc2(fx)\n",
        "        return x, fx\n",
        "\n",
        "\n",
        "class GAN(nn.Module):\n",
        "    def __init__(self, g_layer = config.g_layer, d_layer = config.d_layer):\n",
        "        super(GAN, self).__init__()\n",
        "        self.generator = Generator(g_layer)\n",
        "        self.discriminator = Discriminator(d_layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.generator(x)\n",
        "        x = self.discriminator(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFZSVCCBIuPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba968c23-a73f-41c0-b688-7ab5633f06b5"
      },
      "source": [
        "G = GAN(config.g_layer, config.d_layer).to(device)\n",
        "summary(G, (128,))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 512]          66,048\n",
            "   ConvTranspose3d-2          [-1, 16, 4, 4, 4]           3,472\n",
            "       BatchNorm3d-3          [-1, 16, 4, 4, 4]              32\n",
            "              ReLU-4          [-1, 16, 4, 4, 4]               0\n",
            "   ConvTranspose3d-5          [-1, 16, 4, 4, 4]           6,928\n",
            "       BatchNorm3d-6          [-1, 16, 4, 4, 4]              32\n",
            "              ReLU-7          [-1, 16, 4, 4, 4]               0\n",
            "   ConvTranspose3d-8          [-1, 16, 4, 4, 4]           6,928\n",
            "       BatchNorm3d-9          [-1, 16, 4, 4, 4]              32\n",
            "             ReLU-10          [-1, 16, 4, 4, 4]               0\n",
            "         Upsample-11          [-1, 16, 8, 8, 8]               0\n",
            "  ConvTranspose3d-12          [-1, 32, 8, 8, 8]          13,856\n",
            "      BatchNorm3d-13          [-1, 32, 8, 8, 8]              64\n",
            "             ReLU-14          [-1, 32, 8, 8, 8]               0\n",
            "  ConvTranspose3d-15          [-1, 32, 8, 8, 8]          27,680\n",
            "      BatchNorm3d-16          [-1, 32, 8, 8, 8]              64\n",
            "             ReLU-17          [-1, 32, 8, 8, 8]               0\n",
            "  ConvTranspose3d-18          [-1, 32, 8, 8, 8]          27,680\n",
            "      BatchNorm3d-19          [-1, 32, 8, 8, 8]              64\n",
            "             ReLU-20          [-1, 32, 8, 8, 8]               0\n",
            "         Upsample-21       [-1, 32, 16, 16, 16]               0\n",
            "  ConvTranspose3d-22       [-1, 64, 16, 16, 16]          55,360\n",
            "      BatchNorm3d-23       [-1, 64, 16, 16, 16]             128\n",
            "             ReLU-24       [-1, 64, 16, 16, 16]               0\n",
            "  ConvTranspose3d-25       [-1, 64, 16, 16, 16]         110,656\n",
            "      BatchNorm3d-26       [-1, 64, 16, 16, 16]             128\n",
            "             ReLU-27       [-1, 64, 16, 16, 16]               0\n",
            "  ConvTranspose3d-28       [-1, 64, 16, 16, 16]         110,656\n",
            "      BatchNorm3d-29       [-1, 64, 16, 16, 16]             128\n",
            "             ReLU-30       [-1, 64, 16, 16, 16]               0\n",
            "         Upsample-31       [-1, 64, 32, 32, 32]               0\n",
            "  ConvTranspose3d-32       [-1, 32, 32, 32, 32]          55,328\n",
            "      BatchNorm3d-33       [-1, 32, 32, 32, 32]              64\n",
            "             ReLU-34       [-1, 32, 32, 32, 32]               0\n",
            "  ConvTranspose3d-35       [-1, 32, 32, 32, 32]          27,680\n",
            "      BatchNorm3d-36       [-1, 32, 32, 32, 32]              64\n",
            "             ReLU-37       [-1, 32, 32, 32, 32]               0\n",
            "  ConvTranspose3d-38       [-1, 32, 32, 32, 32]          27,680\n",
            "      BatchNorm3d-39       [-1, 32, 32, 32, 32]              64\n",
            "             ReLU-40       [-1, 32, 32, 32, 32]               0\n",
            "         Upsample-41       [-1, 32, 64, 64, 64]               0\n",
            "  ConvTranspose3d-42       [-1, 16, 64, 64, 64]          13,840\n",
            "      BatchNorm3d-43       [-1, 16, 64, 64, 64]              32\n",
            "             ReLU-44       [-1, 16, 64, 64, 64]               0\n",
            "  ConvTranspose3d-45       [-1, 16, 64, 64, 64]           6,928\n",
            "      BatchNorm3d-46       [-1, 16, 64, 64, 64]              32\n",
            "             ReLU-47       [-1, 16, 64, 64, 64]               0\n",
            "  ConvTranspose3d-48       [-1, 16, 64, 64, 64]           6,928\n",
            "      BatchNorm3d-49       [-1, 16, 64, 64, 64]              32\n",
            "             ReLU-50       [-1, 16, 64, 64, 64]               0\n",
            "  ConvTranspose3d-51        [-1, 1, 64, 64, 64]             433\n",
            "          Sigmoid-52        [-1, 1, 64, 64, 64]               0\n",
            "        Generator-53        [-1, 1, 64, 64, 64]               0\n",
            "           Conv3d-54        [-1, 8, 64, 64, 64]             224\n",
            "      BatchNorm3d-55        [-1, 8, 64, 64, 64]              16\n",
            "             ReLU-56        [-1, 8, 64, 64, 64]               0\n",
            "           Conv3d-57        [-1, 8, 64, 64, 64]           1,736\n",
            "      BatchNorm3d-58        [-1, 8, 64, 64, 64]              16\n",
            "             ReLU-59        [-1, 8, 64, 64, 64]               0\n",
            "        MaxPool3d-60        [-1, 8, 32, 32, 32]               0\n",
            "           Conv3d-61       [-1, 16, 32, 32, 32]           3,472\n",
            "      BatchNorm3d-62       [-1, 16, 32, 32, 32]              32\n",
            "             ReLU-63       [-1, 16, 32, 32, 32]               0\n",
            "           Conv3d-64       [-1, 16, 32, 32, 32]           6,928\n",
            "      BatchNorm3d-65       [-1, 16, 32, 32, 32]              32\n",
            "             ReLU-66       [-1, 16, 32, 32, 32]               0\n",
            "        MaxPool3d-67       [-1, 16, 16, 16, 16]               0\n",
            "           Conv3d-68       [-1, 32, 16, 16, 16]          13,856\n",
            "      BatchNorm3d-69       [-1, 32, 16, 16, 16]              64\n",
            "             ReLU-70       [-1, 32, 16, 16, 16]               0\n",
            "           Conv3d-71       [-1, 32, 16, 16, 16]          27,680\n",
            "      BatchNorm3d-72       [-1, 32, 16, 16, 16]              64\n",
            "             ReLU-73       [-1, 32, 16, 16, 16]               0\n",
            "        MaxPool3d-74          [-1, 32, 8, 8, 8]               0\n",
            "           Conv3d-75          [-1, 16, 8, 8, 8]          13,840\n",
            "      BatchNorm3d-76          [-1, 16, 8, 8, 8]              32\n",
            "             ReLU-77          [-1, 16, 8, 8, 8]               0\n",
            "           Conv3d-78          [-1, 16, 8, 8, 8]           6,928\n",
            "      BatchNorm3d-79          [-1, 16, 8, 8, 8]              32\n",
            "             ReLU-80          [-1, 16, 8, 8, 8]               0\n",
            "        MaxPool3d-81          [-1, 16, 4, 4, 4]               0\n",
            "           Conv3d-82           [-1, 8, 4, 4, 4]           3,464\n",
            "      BatchNorm3d-83           [-1, 8, 4, 4, 4]              16\n",
            "             ReLU-84           [-1, 8, 4, 4, 4]               0\n",
            "           Conv3d-85           [-1, 8, 4, 4, 4]           1,736\n",
            "      BatchNorm3d-86           [-1, 8, 4, 4, 4]              16\n",
            "             ReLU-87           [-1, 8, 4, 4, 4]               0\n",
            "           Linear-88                  [-1, 128]          65,664\n",
            "             ReLU-89                  [-1, 128]               0\n",
            "           Linear-90                    [-1, 1]             129\n",
            "          Sigmoid-91                    [-1, 1]               0\n",
            "    Discriminator-92       [[-1, 1], [-1, 128]]               0\n",
            "================================================================\n",
            "Total params: 715,018\n",
            "Trainable params: 715,018\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 595.29\n",
            "Params size (MB): 2.73\n",
            "Estimated Total Size (MB): 598.02\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrRSqnqK20W",
        "colab_type": "text"
      },
      "source": [
        "#functions for pytorch network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHZ9sGFVspXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def netarray2indices(array):\n",
        "    coord_list = []\n",
        "    if len(array.shape) == 5:\n",
        "        array = array[0][0]\n",
        "    x,y,z = array.shape\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            for k in range(z):\n",
        "                if array[i,j,k] > 0.5:        #tanh: voxel representation [-1,1], sigmoid: [0,1]\n",
        "                    coord_list.append([i,j,k])\n",
        "    print(len(coord_list))\n",
        "    if len(coord_list) == 0:\n",
        "        return np.array([[0,0,0]])  #return at least one point to prevent wandb 3dobject error\n",
        "    return np.array(coord_list)\n",
        "\n",
        "# array should be 3d\n",
        "def netarray2mesh(array):\n",
        "    if len(array.shape) != 3:\n",
        "        raise Exception(\"netarray2mesh: input array should be 3d\")\n",
        "\n",
        "    #convert to bool dtype\n",
        "    array = array > 0.5\n",
        "    #array all zero gives error\n",
        "    if np.sum(array) == 0:\n",
        "        array[0,0,0] = True\n",
        "    voxelmesh = trimesh.voxel.base.VoxelGrid(trimesh.voxel.encoding.DenseEncoding(array)).marching_cubes\n",
        "    voxelmeshfile = voxelmesh.export(file_type='obj')\n",
        "    voxelmeshfile = wandb.Object3D(io.StringIO(voxelmeshfile),file_type='obj')\n",
        "\n",
        "    return voxelmesh, voxelmeshfile\n",
        "\n",
        "def train_model(GAN, dataloader):\n",
        "\n",
        "    \n",
        "    torch.save(GAN, os.path.join(wandb.run.dir, 'GAN_model.pth'))\n",
        "    wandb.save(os.path.join(wandb.run.dir, 'GAN_model.pth'))\n",
        "\n",
        "    #start training\n",
        "    GAN.to(device)\n",
        "    generator = GAN.generator.to(device)\n",
        "    discriminator = GAN.discriminator.to(device)\n",
        "\n",
        "    \n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='mean')\n",
        "    #optimizer \n",
        "    dis_optimizer = optim.Adam(discriminator.parameters(), lr=config.d_lr)\n",
        "    gen_optimizer = optim.Adam(generator.parameters(), lr=config.g_lr)\n",
        "\n",
        "    #log models\n",
        "    wandb.watch(GAN, log=\"all\")\n",
        "\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "    for epoch in range(config.epochs):\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        d_ep_loss = 0.\n",
        "        g_ep_loss = 0.\n",
        "        for dataset_batch in dataloader:\n",
        "\n",
        "            dataset_batch = dataset_batch[0]        #dataset_batch was a list: [array], so just take the array inside                \n",
        "            dataset_batch = dataset_batch.float().to(device)\n",
        "            dloss, gloss = compute_loss(generator, discriminator, dataset_batch)\n",
        "\n",
        "\n",
        "            #optimize generator\n",
        "            gen_optimizer.zero_grad()\n",
        "            gloss.backward(retain_graph=True)\n",
        "            gen_optimizer.step()\n",
        "\n",
        "            #optimize discriminator\n",
        "            dis_optimizer.zero_grad()\n",
        "            dloss.backward(retain_graph=False)\n",
        "            dis_optimizer.step()\n",
        "          \n",
        "\n",
        "            #record loss\n",
        "            d_ep_loss += dloss.detach()  \n",
        "            g_ep_loss += gloss.detach()\n",
        "\n",
        "        #after each epoch, record total loss and sample generated obj\n",
        "        d_losses.append(d_ep_loss)\n",
        "        g_losses.append(g_ep_loss)\n",
        "        print(\"discriminator, epoch\"+str(epoch)+\" : \"+str(d_ep_loss))\n",
        "        print(\"generator, epoch\"+str(epoch)+\" : \"+str(g_ep_loss))\n",
        "\n",
        "        #save model if necessary\n",
        "        if epoch % config.log_interval == 0:\n",
        "\n",
        "            sample_tree_array = generate_tree(GAN)[0]  #only 1 tree\n",
        "            sample_tree_indices = netarray2indices(sample_tree_array)\n",
        "            _, voxelmeshfile = netarray2mesh(sample_tree_array)\n",
        "\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss,\n",
        "            \"sample_tree_indices\": sample_tree_indices,\n",
        "            \"sample_tree_voxelmesh\": voxelmeshfile})\n",
        "            save_model(GAN)\n",
        "\n",
        "        else:\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss})\n",
        "    \n",
        "    #training end, save model again\n",
        "    sample_tree_array = generate_tree(GAN)[0] #only 1 tree\n",
        "    sample_tree_indices = netarray2indices(sample_tree_array)\n",
        "    _, voxelmeshfile = netarray2mesh(sample_tree_array)\n",
        "\n",
        "    wandb.log({\n",
        "    \"discriminator loss\": d_ep_loss,\n",
        "    \"generator loss\": g_ep_loss,\n",
        "    \"sample_tree_indices\": sample_tree_indices,\n",
        "    \"sample_tree_voxelmesh\": voxelmeshfile})\n",
        "    save_model(GAN)\n",
        "    \n",
        "    \n",
        "    print(d_losses)\n",
        "    print(g_losses)\n",
        "\n",
        "# this function calculate loss of the model, \n",
        "def compute_loss(generator, discriminator, dataset_batch):\n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='mean')   \n",
        "\n",
        "    batch_size = dataset_batch.shape[0]\n",
        "        \n",
        "    #labels\n",
        "    real_label = torch.unsqueeze(torch.ones(batch_size),1).float().to(device)\n",
        "    fake_label = torch.unsqueeze(torch.zeros(batch_size),1).float().to(device)\n",
        "\n",
        "    ############\n",
        "    #   discriminator\n",
        "    ############\n",
        "    #generate fake trees\n",
        "    z = torch.randn(batch_size, 128).float().to(device) #128-d noise vector\n",
        "    tree_fake = generator(z)\n",
        "\n",
        "    #real data (data from dataloader)\n",
        "    dout_real, features_real = discriminator(dataset_batch)\n",
        "    dloss_real = criterion(dout_real, real_label)\n",
        "    score_real = dout_real\n",
        "    #fake data (data from generator)            \n",
        "    dout_fake, _ = discriminator(tree_fake.clone().detach())   #detach so no update to generator\n",
        "    dloss_fake = criterion(dout_fake, fake_label)\n",
        "    score_fake = dout_fake\n",
        "\n",
        "    #loss function (discriminator classify real data vs generated data)\n",
        "    dloss = (dloss_real + dloss_fake)/2\n",
        "\n",
        "    ############\n",
        "    #   generator\n",
        "    ############\n",
        "\n",
        "    #tree_fake is already computed above\n",
        "    dout_fake, features_fake = discriminator(tree_fake)\n",
        "    #generator should generate trees that discriminator think they are real\n",
        "    gloss = criterion(dout_fake, real_label)\n",
        "    #add feature matching\n",
        "    # mseloss = nn.MSELoss(reduction=\"sum\")\n",
        "    # gloss += mseloss(torch.mean(features_fake), torch.mean(features_real))\n",
        "\n",
        "    return dloss, gloss\n",
        "\n",
        "\n",
        "def save_model(model, model_path = os.path.join(wandb.run.dir, 'model_dict.pth')):\n",
        "\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    wandb.save(model_path)\n",
        "\n",
        "def load_model(model_path = 'model_dict.pth'):\n",
        "    model = GAN()\n",
        "\n",
        "    model_file = wandb.restore(model_path)\n",
        "    model.load_state_dict(torch.load(model_file.name))\n",
        "\n",
        "    return model\n",
        "\n",
        "# def generate_tree(generator, num_trees = 1):\n",
        "    \n",
        "#     #generate noise vector\n",
        "#     z = torch.randn(num_trees, 128).to(device)\n",
        "#     generator.to(device).eval()\n",
        "#     tree_fake = generator(z)\n",
        "#     return tree_fake.detach().cpu().numpy()\n",
        "\n",
        "def generate_tree(model, check_D = False, num_trees = 1, num_try = 100):\n",
        "    #num_try is number of trial to generate a tree that can fool D\n",
        "    #total number of sample generated = num_trees * num_try\n",
        "    \n",
        "\n",
        "    model.to(device).eval()\n",
        "    generator = model.generator.to(device).eval()\n",
        "    discriminator = model.discriminator.to(device).eval()\n",
        "\n",
        "    result = None\n",
        "\n",
        "\n",
        "    if not check_D:\n",
        "        num_tree_total = num_trees\n",
        "        num_runs = int(np.ceil(num_tree_total / config.batch_size))\n",
        "        #ignore discriminator\n",
        "        for i in range(num_runs):\n",
        "            #generate noise vector\n",
        "            z = torch.randn(config.batch_size, 128).to(device)\n",
        "            \n",
        "            tree_fake = generator(z)[:,0,:,:,:]\n",
        "            selected_trees = tree_fake.detach().cpu().numpy()\n",
        "            if result is None:\n",
        "                result = selected_trees\n",
        "            else:\n",
        "                result = np.concatenate((result, selected_trees), axis=0)\n",
        "    else:\n",
        "        num_tree_total = num_trees * num_try\n",
        "        num_runs = int(np.ceil(num_tree_total / config.batch_size))\n",
        "        #only show samples can fool discriminator\n",
        "        for i in range(num_runs):\n",
        "            #generate noise vector\n",
        "            z = torch.randn(config.batch_size, 128).to(device)\n",
        "            \n",
        "            tree_fake = generator(z)\n",
        "            dout, _ = discriminator(tree_fake)\n",
        "            dout = dout > 0.5\n",
        "            selected_trees = tree_fake[dout].detach().cpu().numpy()\n",
        "            if result is None:\n",
        "                result = selected_trees\n",
        "            else:\n",
        "                result = np.concatenate((result, selected_trees), axis=0)\n",
        "    #select at most num_trees\n",
        "    if result.shape[0] > num_trees:\n",
        "        result = result[:num_trees]\n",
        "    #in case no good result\n",
        "    if result.shape[0] <= 0:\n",
        "        result = np.zeros((1,64,64,64))\n",
        "        result[0,0,0,0] = 1\n",
        "    return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3",
        "colab_type": "text"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQWIWapYOsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "6398d6d6-73ef-4133-edd4-d7cd1be28d12"
      },
      "source": [
        "# check if resume\n",
        "if resume:\n",
        "    gan = load_model()\n",
        "else:\n",
        "    gan = GAN(config.g_layer, config.d_layer)\n",
        "\n",
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "train_model(gan, dataloader)        #if dataloader has only 1 tree, the training time is 72s per epoch."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch0 : tensor(0.0101, device='cuda:0')\n",
            "generator, epoch0 : tensor(598.7605, device='cuda:0')\n",
            "1809\n",
            "discriminator, epoch1 : tensor(0.0068, device='cuda:0')\n",
            "generator, epoch1 : tensor(526.7350, device='cuda:0')\n",
            "discriminator, epoch2 : tensor(0.0032, device='cuda:0')\n",
            "generator, epoch2 : tensor(541.1215, device='cuda:0')\n",
            "discriminator, epoch3 : tensor(0.0060, device='cuda:0')\n",
            "generator, epoch3 : tensor(565.5887, device='cuda:0')\n",
            "discriminator, epoch4 : tensor(0.0004, device='cuda:0')\n",
            "generator, epoch4 : tensor(639.7161, device='cuda:0')\n",
            "discriminator, epoch5 : tensor(0.0005, device='cuda:0')\n",
            "generator, epoch5 : tensor(626.5934, device='cuda:0')\n",
            "discriminator, epoch6 : tensor(0.0021, device='cuda:0')\n",
            "generator, epoch6 : tensor(592.4025, device='cuda:0')\n",
            "discriminator, epoch7 : tensor(0.0002, device='cuda:0')\n",
            "generator, epoch7 : tensor(646.8451, device='cuda:0')\n",
            "discriminator, epoch8 : tensor(0.0001, device='cuda:0')\n",
            "generator, epoch8 : tensor(667.7565, device='cuda:0')\n",
            "discriminator, epoch9 : tensor(0.0001, device='cuda:0')\n",
            "generator, epoch9 : tensor(683.6749, device='cuda:0')\n",
            "1912\n",
            "[tensor(0.0101, device='cuda:0'), tensor(0.0068, device='cuda:0'), tensor(0.0032, device='cuda:0'), tensor(0.0060, device='cuda:0'), tensor(0.0004, device='cuda:0'), tensor(0.0005, device='cuda:0'), tensor(0.0021, device='cuda:0'), tensor(0.0002, device='cuda:0'), tensor(0.0001, device='cuda:0'), tensor(0.0001, device='cuda:0')]\n",
            "[tensor(598.7605, device='cuda:0'), tensor(526.7350, device='cuda:0'), tensor(541.1215, device='cuda:0'), tensor(565.5887, device='cuda:0'), tensor(639.7161, device='cuda:0'), tensor(626.5934, device='cuda:0'), tensor(592.4025, device='cuda:0'), tensor(646.8451, device='cuda:0'), tensor(667.7565, device='cuda:0'), tensor(683.6749, device='cuda:0')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}