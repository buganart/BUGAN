{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script_GAN_ver3_voxelsize1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/script_GAN_ver3_voxelsize1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3882d0ec-3dd2-47ba-c2fe-e3b3c0e987ff"
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f407b5f-23cb-4979-9e98-1525506ad4a8"
      },
      "source": [
        "#right click shared folder IRCMS_GAN_collaborative_database and \"Add shortcut to Drive\" to My drive\n",
        "%cd drive/My Drive/IRCMS_GAN_collaborative_database/\n",
        "\n",
        "#record paths to resources\n",
        "data_path = \"Research/Peter/Tree_3D_models_obj/obj_files/\"\n",
        "run_path = \"Experiments/colab-treegan/\"\n",
        "\n",
        "# !ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ylB2p6N0qQ-G4OsBuwcZ9C0tsqVu9ww4/IRCMS_GAN_collaborative_database\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LzAiBuWu6pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install trimesh\n",
        "!pip install wandb -q\n",
        "output.clear()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpnFurJt0Pu",
        "colab_type": "text"
      },
      "source": [
        "#add libraries, and login to wandb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import trimesh\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_fQzoLaVP2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login\n",
        "output.clear()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3eb3d6e1-b835-408a-befd-65e84a2f9758"
      },
      "source": [
        "run = wandb.init(project=\"tree-gan\", dir=run_path)\n",
        "wandb.run.name = str(wandb.run.id)\n",
        "wandb.watch_called = False\n",
        "wandb.run.save_code = True\n",
        "\n",
        "#tag\n",
        "wandb.run.tags = [\"testing\",\"dev\"]\n",
        "wandb.run.notes = \"testing\"\n",
        "wandb.run.group = \"test wandb\"\n",
        "\n",
        "\n",
        "#keep track of hyperparams\n",
        "config = wandb.config\n",
        "config.batch_size = 3\n",
        "config.test_batch_size = 1\n",
        "config.epochs = 10000\n",
        "config.g_lr = 0.0001\n",
        "config.d_lr = 0.00001           \n",
        "config.seed = 1234\n",
        "config.log_interval = 200"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/bugan/tree-gan\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/bugan/tree-gan/runs/3vqpjt8u\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan/runs/3vqpjt8u</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI",
        "colab_type": "text"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qoPjcAGrimt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mesh2arrayCentered(mesh, voxel_size = 1, array_length = 64):\n",
        "    #given array length 64, voxel size 2, then output array size is [128,128,128]\n",
        "    array_size = np.ceil(np.array([array_length, array_length, array_length]) / voxel_size).astype(int)\n",
        "    vox_array = np.zeros(array_size, dtype=bool)\n",
        "    #scale mesh extent to fit array_length\n",
        "    max_length = np.max(np.array(mesh.extents))\n",
        "    mesh = mesh.apply_transform(trimesh.transformations.scale_matrix((array_length-1)/max_length))  #now the extent is [array_length**3]\n",
        "    v = mesh.voxelized(voxel_size)  #max voxel array length = array_length / voxel_size\n",
        "\n",
        "    #find indices in the v.matrix to center it in vox_array\n",
        "    indices = ((array_size - v.matrix.shape)/2).astype(int)\n",
        "    vox_array[indices[0]:indices[0]+v.matrix.shape[0], indices[1]:indices[1]+v.matrix.shape[1], indices[2]:indices[2]+v.matrix.shape[2]] = v.matrix\n",
        "\n",
        "    return vox_array"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTTG-zCl8kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6271b056-363f-4249-fca2-f384ddcc38ca"
      },
      "source": [
        "dataset_artifact = run.use_artifact(\"dataset-tree-typeold-3:latest\", type='dataset')\n",
        "dir_dict = dataset_artifact.metadata['dir_dict']\n",
        "print(dir_dict)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'old': ['old_1.obj', 'old_2.obj', 'old_3.obj']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh1RWa6qoVUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = []\n",
        "\n",
        "for data_cat in dir_dict:\n",
        "    filename_list = dir_dict[data_cat]\n",
        "    for filename in filename_list:\n",
        "        filename = data_path + filename\n",
        "        m = trimesh.load(filename, force='mesh')\n",
        "        array = mesh2arrayCentered(m)\n",
        "        dataset.append(array)\n",
        "dataset = np.array(dataset)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f3bf328-b5a4-45eb-b8ae-ad1eb42dd947"
      },
      "source": [
        "dataset = torch.tensor(dataset)\n",
        "print(torch.unsqueeze(dataset, -1).shape)\n",
        "tensor_dataset = TensorDataset(torch.unsqueeze(dataset, 1))\n",
        "\n",
        "#TODO: augment data\n",
        "\n",
        "dataloader = DataLoader(tensor_dataset, batch_size=config.batch_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 64, 64, 64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIaapsqSK5h2",
        "colab_type": "text"
      },
      "source": [
        "#model description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodI2E4ANdYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input: 128-d noise vector\n",
        "#output: (250,250,250) array with values in [0,1]\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.fc_channel = 8 #16\n",
        "        self.fc_size = 4\n",
        "\n",
        "        num_unit1 = self.fc_channel   \n",
        "        num_unit2 = 32   #32\n",
        "        num_unit3 = 64   #64\n",
        "        num_unit4 = 128   #128\n",
        "        num_unit5 = 256   #256\n",
        "        num_unit6 = 256   #512\n",
        "        self.gen_fc = nn.Linear(128, num_unit1 * self.fc_size * self.fc_size * self.fc_size)\n",
        "        self.gen = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit1, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit2, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit2, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit1, 1, 3, 1, padding = 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.gen_fc(x)\n",
        "        x = x.view(x.shape[0], self.fc_channel, self.fc_size, self.fc_size, self.fc_size)\n",
        "        x = self.gen(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        num_unit1 = 8   #16\n",
        "        num_unit2 = 16   #32\n",
        "        num_unit3 = 32   #64\n",
        "        num_unit4 = 64  #128\n",
        "        num_unit5 = 128   #256\n",
        "        num_unit6 = 128   #512\n",
        "        \n",
        "        self.dis = nn.Sequential(\n",
        "            nn.Conv3d(1, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit2, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit3, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit3, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit4, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit4, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),            \n",
        "            nn.Conv3d(num_unit3, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "\n",
        "            nn.Conv3d(num_unit2, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.dis_fc1 = nn.Sequential(\n",
        "            nn.Linear(num_unit1 * 4 * 4 * 4, 128),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.dis_fc2 = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dis(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        fx = self.dis_fc1(x)\n",
        "        x = self.dis_fc2(fx)\n",
        "        return x, fx"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6CzSW9jATSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# G = Generator().to(device)\n",
        "# summary(G, (128,))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFZSVCCBIuPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# D = Discriminator().to(device)\n",
        "# summary(D, (1, 64, 64, 64))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrRSqnqK20W",
        "colab_type": "text"
      },
      "source": [
        "#functions for pytorch network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHZ9sGFVspXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def netarray2voxel(array):\n",
        "    coord_list = []\n",
        "    if len(array.shape) == 5:\n",
        "        array = array[0][0]\n",
        "    x,y,z = array.shape\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            for k in range(z):\n",
        "                if array[i,j,k] > 0:        #tanh: voxel representation [-1,1]\n",
        "                    coord_list.append([i,j,k])\n",
        "    print(len(coord_list))\n",
        "    if len(coord_list) == 0:\n",
        "        return np.array([[0,0,0]])  #return at least one point to prevent wandb 3dobject error\n",
        "    return np.array(coord_list)\n",
        "\n",
        "def train_model(generator, discriminator, dataloader):\n",
        "    #save model first\n",
        "    torch.save(Generator, os.path.join(wandb.run.dir, 'generator_model.pth'))\n",
        "    torch.save(discriminator, os.path.join(wandb.run.dir, 'discriminator_model.pth'))\n",
        "    artifact = wandb.Artifact(type='model', name=wandb.run.name)\n",
        "    artifact.add_file(os.path.join(wandb.run.dir, 'generator_model.pth'))\n",
        "    artifact.add_file(os.path.join(wandb.run.dir, 'discriminator_model.pth'))\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "\n",
        "    #start training\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='sum')\n",
        "    #optimizer\n",
        "    # dis_optimizer = optim.SGD(discriminator.parameters(), lr=config.d_lr)\n",
        "    # gen_optimizer = optim.SGD(generator.parameters(), lr=config.g_lr)   \n",
        "    dis_optimizer = optim.Adam(discriminator.parameters(), lr=config.d_lr)\n",
        "    gen_optimizer = optim.Adam(generator.parameters(), lr=config.g_lr)\n",
        "\n",
        "    #log models\n",
        "    wandb.watch(generator, log=\"all\")\n",
        "    wandb.watch(discriminator, log=\"all\")\n",
        "\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "    for epoch in range(config.epochs):\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        d_ep_loss = 0.\n",
        "        g_ep_loss = 0.\n",
        "        for dataset_batch in dataloader:\n",
        "\n",
        "            dataset_batch = dataset_batch[0]\n",
        "            #add data augmentation (rotate 90/180/270)\n",
        "            #this modify the whole batch at the same time\n",
        "            # rand_num = torch.randn(2)\n",
        "            # if rand_num[0] > 0.5:\n",
        "            #     dataset_batch = dataset_batch.permute(0, 1, 3,2,4)\n",
        "            # if rand_num[1] > 0.5: \n",
        "            #     dataset_batch = dataset_batch.flip([4])\n",
        "                \n",
        "            dataset_batch = dataset_batch.float().to(device)\n",
        "            dloss, gloss = compute_loss(generator, discriminator, dataset_batch)\n",
        "\n",
        "\n",
        "            #optimize generator\n",
        "            gen_optimizer.zero_grad()\n",
        "            gloss.backward(retain_graph=True)\n",
        "            gen_optimizer.step()\n",
        "\n",
        "            #optimize discriminator\n",
        "            dis_optimizer.zero_grad()\n",
        "            dloss.backward(retain_graph=False)\n",
        "            dis_optimizer.step()\n",
        "          \n",
        "\n",
        "            #record loss\n",
        "            d_ep_loss += dloss.detach()  \n",
        "            g_ep_loss += gloss.detach()\n",
        "\n",
        "        #after each epoch, record total loss and sample generated obj\n",
        "        d_losses.append(d_ep_loss)\n",
        "        g_losses.append(g_ep_loss)\n",
        "        print(\"discriminator, epoch\"+str(epoch)+\" : \"+str(d_ep_loss))\n",
        "        print(\"generator, epoch\"+str(epoch)+\" : \"+str(g_ep_loss))\n",
        "\n",
        "        #save model if necessary\n",
        "        if epoch % config.log_interval == 0:\n",
        "            sample_tree = netarray2voxel(generate_tree(generator))\n",
        "\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss,\n",
        "            \"sample_tree\": wandb.Object3D(sample_tree)})\n",
        "            torch.save(generator.state_dict(), os.path.join(wandb.run.dir, 'generator_dict.pth'))\n",
        "            torch.save(discriminator.state_dict(), os.path.join(wandb.run.dir, 'discriminator_dict.pth'))\n",
        "\n",
        "            artifact = wandb.Artifact(type='model', name=wandb.run.name)\n",
        "            artifact.add_file(os.path.join(wandb.run.dir, 'generator_dict.pth'))\n",
        "            artifact.add_file(os.path.join(wandb.run.dir, 'discriminator_dict.pth'))\n",
        "            run.log_artifact(artifact)\n",
        "\n",
        "        else:\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss})\n",
        "    \n",
        "    #training end, save model again\n",
        "    sample_tree = netarray2voxel(generate_tree(generator))\n",
        "\n",
        "    wandb.log({\n",
        "    \"discriminator loss\": d_ep_loss,\n",
        "    \"generator loss\": g_ep_loss,\n",
        "    \"sample_tree\": wandb.Object3D(sample_tree)})\n",
        "    torch.save(generator.state_dict(), os.path.join(wandb.run.dir, 'generator.pth'))\n",
        "    torch.save(discriminator.state_dict(), os.path.join(wandb.run.dir, 'discriminator.pth'))\n",
        "\n",
        "    artifact = wandb.Artifact(type='model', name=wandb.run.name)\n",
        "    artifact.add_file(os.path.join(wandb.run.dir, 'generator_dict.pth'))\n",
        "    artifact.add_file(os.path.join(wandb.run.dir, 'discriminator_dict.pth'))\n",
        "    run.log_artifact(artifact)\n",
        "    \n",
        "    print(d_losses)\n",
        "    print(g_losses)\n",
        "\n",
        "# this function calculate loss of the model, \n",
        "def compute_loss(generator, discriminator, dataset_batch):\n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='sum')   \n",
        "\n",
        "    batch_size = dataset_batch.shape[0]\n",
        "        \n",
        "    #labels\n",
        "    real_label = torch.unsqueeze(torch.ones(batch_size),1).float().to(device) * 0.9     # one side label smoothing\n",
        "    fake_label = torch.unsqueeze(torch.zeros(batch_size),1).float().to(device)\n",
        "\n",
        "    ############\n",
        "    #   discriminator\n",
        "    ############\n",
        "    #generate fake trees\n",
        "    z = torch.randn(batch_size, 128).float().to(device) #128-d noise vector\n",
        "    tree_fake = generator(z)\n",
        "\n",
        "    #real data (data from dataloader)\n",
        "    dout_real, features_real = discriminator(dataset_batch)\n",
        "    dloss_real = criterion(dout_real, real_label)\n",
        "    score_real = dout_real\n",
        "    #fake data (data from generator)            \n",
        "    dout_fake, _ = discriminator(tree_fake.clone().detach())   #detach so no double update on the same batch of tree_fake\n",
        "    dloss_fake = criterion(dout_fake, fake_label)\n",
        "    score_fake = dout_fake\n",
        "\n",
        "    #loss function (discriminator classify real data vs generated data)\n",
        "    dloss = dloss_real + dloss_fake\n",
        "\n",
        "    ############\n",
        "    #   generator\n",
        "    ############\n",
        "\n",
        "    #tree_fake is already computed above\n",
        "    dout_fake, features_fake = discriminator(tree_fake)\n",
        "    #generator should generate trees that discriminator think they are real\n",
        "    gloss = criterion(dout_fake, real_label)\n",
        "    #add feature matching\n",
        "    mseloss = nn.MSELoss(reduction=\"sum\")\n",
        "    gloss += mseloss(torch.mean(features_fake), torch.mean(features_real))\n",
        "\n",
        "    return dloss, gloss\n",
        "\n",
        "\n",
        "def save_model(generator, discriminator, g_path = os.path.join(wandb.run.dir, 'generator.pth') , d_path = os.path.join(wandb.run.dir, 'discriminator.pth')):\n",
        "    torch.save(generator.state_dict(), g_path)\n",
        "    torch.save(discriminator.state_dict(), d_path)\n",
        "\n",
        "def load_model(g_path = os.path.join(wandb.run.dir, 'generator.pth'), d_path = os.path.join(wandb.run.dir, 'discriminator.pth')):\n",
        "    generator = Generator()\n",
        "    generator.load_state_dict(torch.load(g_path))\n",
        "    generator.eval()\n",
        "\n",
        "    discriminator = Discriminator()\n",
        "    discriminator.load_state_dict(torch.load(d_path))\n",
        "    discriminator.eval()\n",
        "    return generator, discriminator\n",
        "\n",
        "def generate_tree(generator, num_trees = 1):\n",
        "    \n",
        "    #generate noise vector\n",
        "    z = torch.randn(num_trees, 128).to(device)\n",
        "    generator.to(device).eval()\n",
        "    tree_fake = generator(z)\n",
        "    return tree_fake.detach().cpu().numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3",
        "colab_type": "text"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQWIWapYOsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e1ec7ca-a8c6-4d19-d3ef-9424a13ab5a4"
      },
      "source": [
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "train_model(G, D, dataloader)        #if dataloader has only 1 tree, the training time is 72s per epoch."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n",
            "Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
            "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
            "If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch0 : tensor(4.1307, device='cuda:0')\n",
            "generator, epoch0 : tensor(2.2185, device='cuda:0')\n",
            "262144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/wandb/data_types.py:464: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  elif 'type' in data_or_path:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch1 : tensor(3.8706, device='cuda:0')\n",
            "generator, epoch1 : tensor(2.3298, device='cuda:0')\n",
            "discriminator, epoch2 : tensor(3.6886, device='cuda:0')\n",
            "generator, epoch2 : tensor(2.4172, device='cuda:0')\n",
            "discriminator, epoch3 : tensor(3.6619, device='cuda:0')\n",
            "generator, epoch3 : tensor(2.3622, device='cuda:0')\n",
            "discriminator, epoch4 : tensor(3.5923, device='cuda:0')\n",
            "generator, epoch4 : tensor(2.3665, device='cuda:0')\n",
            "discriminator, epoch5 : tensor(3.5442, device='cuda:0')\n",
            "generator, epoch5 : tensor(2.3538, device='cuda:0')\n",
            "discriminator, epoch6 : tensor(3.5716, device='cuda:0')\n",
            "generator, epoch6 : tensor(2.2785, device='cuda:0')\n",
            "discriminator, epoch7 : tensor(3.4713, device='cuda:0')\n",
            "generator, epoch7 : tensor(2.3325, device='cuda:0')\n",
            "discriminator, epoch8 : tensor(3.4674, device='cuda:0')\n",
            "generator, epoch8 : tensor(2.3069, device='cuda:0')\n",
            "discriminator, epoch9 : tensor(3.3652, device='cuda:0')\n",
            "generator, epoch9 : tensor(2.4023, device='cuda:0')\n",
            "discriminator, epoch10 : tensor(3.3686, device='cuda:0')\n",
            "generator, epoch10 : tensor(2.3492, device='cuda:0')\n",
            "discriminator, epoch11 : tensor(3.3114, device='cuda:0')\n",
            "generator, epoch11 : tensor(2.3783, device='cuda:0')\n",
            "discriminator, epoch12 : tensor(3.3125, device='cuda:0')\n",
            "generator, epoch12 : tensor(2.3550, device='cuda:0')\n",
            "discriminator, epoch13 : tensor(3.2368, device='cuda:0')\n",
            "generator, epoch13 : tensor(2.4127, device='cuda:0')\n",
            "discriminator, epoch14 : tensor(3.1196, device='cuda:0')\n",
            "generator, epoch14 : tensor(2.5279, device='cuda:0')\n",
            "discriminator, epoch15 : tensor(3.2508, device='cuda:0')\n",
            "generator, epoch15 : tensor(2.3662, device='cuda:0')\n",
            "discriminator, epoch16 : tensor(3.2410, device='cuda:0')\n",
            "generator, epoch16 : tensor(2.3687, device='cuda:0')\n",
            "discriminator, epoch17 : tensor(3.2172, device='cuda:0')\n",
            "generator, epoch17 : tensor(2.3766, device='cuda:0')\n",
            "discriminator, epoch18 : tensor(3.1363, device='cuda:0')\n",
            "generator, epoch18 : tensor(2.4531, device='cuda:0')\n",
            "discriminator, epoch19 : tensor(3.1949, device='cuda:0')\n",
            "generator, epoch19 : tensor(2.3752, device='cuda:0')\n",
            "discriminator, epoch20 : tensor(3.1734, device='cuda:0')\n",
            "generator, epoch20 : tensor(2.3893, device='cuda:0')\n",
            "discriminator, epoch21 : tensor(3.2559, device='cuda:0')\n",
            "generator, epoch21 : tensor(2.2972, device='cuda:0')\n",
            "discriminator, epoch22 : tensor(3.1534, device='cuda:0')\n",
            "generator, epoch22 : tensor(2.4015, device='cuda:0')\n",
            "discriminator, epoch23 : tensor(3.1690, device='cuda:0')\n",
            "generator, epoch23 : tensor(2.3746, device='cuda:0')\n",
            "discriminator, epoch24 : tensor(3.1751, device='cuda:0')\n",
            "generator, epoch24 : tensor(2.3625, device='cuda:0')\n",
            "discriminator, epoch25 : tensor(3.0919, device='cuda:0')\n",
            "generator, epoch25 : tensor(2.4378, device='cuda:0')\n",
            "discriminator, epoch26 : tensor(3.0211, device='cuda:0')\n",
            "generator, epoch26 : tensor(2.5031, device='cuda:0')\n",
            "discriminator, epoch27 : tensor(2.9606, device='cuda:0')\n",
            "generator, epoch27 : tensor(2.5737, device='cuda:0')\n",
            "discriminator, epoch28 : tensor(3.0470, device='cuda:0')\n",
            "generator, epoch28 : tensor(2.4565, device='cuda:0')\n",
            "discriminator, epoch29 : tensor(3.0055, device='cuda:0')\n",
            "generator, epoch29 : tensor(2.5048, device='cuda:0')\n",
            "discriminator, epoch30 : tensor(2.9210, device='cuda:0')\n",
            "generator, epoch30 : tensor(2.5947, device='cuda:0')\n",
            "discriminator, epoch31 : tensor(3.0210, device='cuda:0')\n",
            "generator, epoch31 : tensor(2.4706, device='cuda:0')\n",
            "discriminator, epoch32 : tensor(2.9557, device='cuda:0')\n",
            "generator, epoch32 : tensor(2.5333, device='cuda:0')\n",
            "discriminator, epoch33 : tensor(2.8868, device='cuda:0')\n",
            "generator, epoch33 : tensor(2.6165, device='cuda:0')\n",
            "discriminator, epoch34 : tensor(2.9444, device='cuda:0')\n",
            "generator, epoch34 : tensor(2.5403, device='cuda:0')\n",
            "discriminator, epoch35 : tensor(2.9813, device='cuda:0')\n",
            "generator, epoch35 : tensor(2.4867, device='cuda:0')\n",
            "discriminator, epoch36 : tensor(2.9759, device='cuda:0')\n",
            "generator, epoch36 : tensor(2.4865, device='cuda:0')\n",
            "discriminator, epoch37 : tensor(2.9219, device='cuda:0')\n",
            "generator, epoch37 : tensor(2.5425, device='cuda:0')\n",
            "discriminator, epoch38 : tensor(2.9476, device='cuda:0')\n",
            "generator, epoch38 : tensor(2.5055, device='cuda:0')\n",
            "discriminator, epoch39 : tensor(2.9384, device='cuda:0')\n",
            "generator, epoch39 : tensor(2.5177, device='cuda:0')\n",
            "discriminator, epoch40 : tensor(2.9101, device='cuda:0')\n",
            "generator, epoch40 : tensor(2.5386, device='cuda:0')\n",
            "discriminator, epoch41 : tensor(2.8970, device='cuda:0')\n",
            "generator, epoch41 : tensor(2.5486, device='cuda:0')\n",
            "discriminator, epoch42 : tensor(2.9488, device='cuda:0')\n",
            "generator, epoch42 : tensor(2.4812, device='cuda:0')\n",
            "discriminator, epoch43 : tensor(2.8996, device='cuda:0')\n",
            "generator, epoch43 : tensor(2.5367, device='cuda:0')\n",
            "discriminator, epoch44 : tensor(2.8146, device='cuda:0')\n",
            "generator, epoch44 : tensor(2.6326, device='cuda:0')\n",
            "discriminator, epoch45 : tensor(2.7845, device='cuda:0')\n",
            "generator, epoch45 : tensor(2.6755, device='cuda:0')\n",
            "discriminator, epoch46 : tensor(2.8177, device='cuda:0')\n",
            "generator, epoch46 : tensor(2.6255, device='cuda:0')\n",
            "discriminator, epoch47 : tensor(2.8128, device='cuda:0')\n",
            "generator, epoch47 : tensor(2.6472, device='cuda:0')\n",
            "discriminator, epoch48 : tensor(2.6709, device='cuda:0')\n",
            "generator, epoch48 : tensor(2.8262, device='cuda:0')\n",
            "discriminator, epoch49 : tensor(2.5482, device='cuda:0')\n",
            "generator, epoch49 : tensor(2.9919, device='cuda:0')\n",
            "discriminator, epoch50 : tensor(2.6537, device='cuda:0')\n",
            "generator, epoch50 : tensor(2.8517, device='cuda:0')\n",
            "discriminator, epoch51 : tensor(2.6134, device='cuda:0')\n",
            "generator, epoch51 : tensor(2.8911, device='cuda:0')\n",
            "discriminator, epoch52 : tensor(2.6004, device='cuda:0')\n",
            "generator, epoch52 : tensor(2.9175, device='cuda:0')\n",
            "discriminator, epoch53 : tensor(2.5582, device='cuda:0')\n",
            "generator, epoch53 : tensor(2.9581, device='cuda:0')\n",
            "discriminator, epoch54 : tensor(2.5065, device='cuda:0')\n",
            "generator, epoch54 : tensor(3.0319, device='cuda:0')\n",
            "discriminator, epoch55 : tensor(2.5272, device='cuda:0')\n",
            "generator, epoch55 : tensor(2.9903, device='cuda:0')\n",
            "discriminator, epoch56 : tensor(2.5232, device='cuda:0')\n",
            "generator, epoch56 : tensor(2.9895, device='cuda:0')\n",
            "discriminator, epoch57 : tensor(2.4730, device='cuda:0')\n",
            "generator, epoch57 : tensor(3.0668, device='cuda:0')\n",
            "discriminator, epoch58 : tensor(2.5477, device='cuda:0')\n",
            "generator, epoch58 : tensor(2.9349, device='cuda:0')\n",
            "discriminator, epoch59 : tensor(2.5720, device='cuda:0')\n",
            "generator, epoch59 : tensor(2.8944, device='cuda:0')\n",
            "discriminator, epoch60 : tensor(2.4676, device='cuda:0')\n",
            "generator, epoch60 : tensor(3.0522, device='cuda:0')\n",
            "discriminator, epoch61 : tensor(2.5954, device='cuda:0')\n",
            "generator, epoch61 : tensor(2.8495, device='cuda:0')\n",
            "discriminator, epoch62 : tensor(2.5478, device='cuda:0')\n",
            "generator, epoch62 : tensor(2.9149, device='cuda:0')\n",
            "discriminator, epoch63 : tensor(2.4920, device='cuda:0')\n",
            "generator, epoch63 : tensor(3.0061, device='cuda:0')\n",
            "discriminator, epoch64 : tensor(2.4974, device='cuda:0')\n",
            "generator, epoch64 : tensor(2.9866, device='cuda:0')\n",
            "discriminator, epoch65 : tensor(2.4548, device='cuda:0')\n",
            "generator, epoch65 : tensor(3.0753, device='cuda:0')\n",
            "discriminator, epoch66 : tensor(2.4649, device='cuda:0')\n",
            "generator, epoch66 : tensor(3.0402, device='cuda:0')\n",
            "discriminator, epoch67 : tensor(2.4048, device='cuda:0')\n",
            "generator, epoch67 : tensor(3.1220, device='cuda:0')\n",
            "discriminator, epoch68 : tensor(2.4405, device='cuda:0')\n",
            "generator, epoch68 : tensor(3.0584, device='cuda:0')\n",
            "discriminator, epoch69 : tensor(2.4575, device='cuda:0')\n",
            "generator, epoch69 : tensor(3.0264, device='cuda:0')\n",
            "discriminator, epoch70 : tensor(2.4087, device='cuda:0')\n",
            "generator, epoch70 : tensor(3.1036, device='cuda:0')\n",
            "discriminator, epoch71 : tensor(2.5021, device='cuda:0')\n",
            "generator, epoch71 : tensor(2.9472, device='cuda:0')\n",
            "discriminator, epoch72 : tensor(2.4593, device='cuda:0')\n",
            "generator, epoch72 : tensor(3.0222, device='cuda:0')\n",
            "discriminator, epoch73 : tensor(2.4872, device='cuda:0')\n",
            "generator, epoch73 : tensor(2.9745, device='cuda:0')\n",
            "discriminator, epoch74 : tensor(2.4253, device='cuda:0')\n",
            "generator, epoch74 : tensor(3.0732, device='cuda:0')\n",
            "discriminator, epoch75 : tensor(2.4778, device='cuda:0')\n",
            "generator, epoch75 : tensor(2.9732, device='cuda:0')\n",
            "discriminator, epoch76 : tensor(2.4066, device='cuda:0')\n",
            "generator, epoch76 : tensor(3.0939, device='cuda:0')\n",
            "discriminator, epoch77 : tensor(2.5082, device='cuda:0')\n",
            "generator, epoch77 : tensor(2.9253, device='cuda:0')\n",
            "discriminator, epoch78 : tensor(2.4227, device='cuda:0')\n",
            "generator, epoch78 : tensor(3.0613, device='cuda:0')\n",
            "discriminator, epoch79 : tensor(2.4023, device='cuda:0')\n",
            "generator, epoch79 : tensor(3.0932, device='cuda:0')\n",
            "discriminator, epoch80 : tensor(2.4722, device='cuda:0')\n",
            "generator, epoch80 : tensor(2.9748, device='cuda:0')\n",
            "discriminator, epoch81 : tensor(2.3999, device='cuda:0')\n",
            "generator, epoch81 : tensor(3.0993, device='cuda:0')\n",
            "discriminator, epoch82 : tensor(2.3594, device='cuda:0')\n",
            "generator, epoch82 : tensor(3.1505, device='cuda:0')\n",
            "discriminator, epoch83 : tensor(2.4498, device='cuda:0')\n",
            "generator, epoch83 : tensor(2.9916, device='cuda:0')\n",
            "discriminator, epoch84 : tensor(2.3672, device='cuda:0')\n",
            "generator, epoch84 : tensor(3.1295, device='cuda:0')\n",
            "discriminator, epoch85 : tensor(2.4169, device='cuda:0')\n",
            "generator, epoch85 : tensor(3.0424, device='cuda:0')\n",
            "discriminator, epoch86 : tensor(2.4088, device='cuda:0')\n",
            "generator, epoch86 : tensor(3.0425, device='cuda:0')\n",
            "discriminator, epoch87 : tensor(2.2686, device='cuda:0')\n",
            "generator, epoch87 : tensor(3.2921, device='cuda:0')\n",
            "discriminator, epoch88 : tensor(2.2493, device='cuda:0')\n",
            "generator, epoch88 : tensor(3.3209, device='cuda:0')\n",
            "discriminator, epoch89 : tensor(2.2550, device='cuda:0')\n",
            "generator, epoch89 : tensor(3.3134, device='cuda:0')\n",
            "discriminator, epoch90 : tensor(2.3161, device='cuda:0')\n",
            "generator, epoch90 : tensor(3.1999, device='cuda:0')\n",
            "discriminator, epoch91 : tensor(2.3048, device='cuda:0')\n",
            "generator, epoch91 : tensor(3.2103, device='cuda:0')\n",
            "discriminator, epoch92 : tensor(2.2708, device='cuda:0')\n",
            "generator, epoch92 : tensor(3.2669, device='cuda:0')\n",
            "discriminator, epoch93 : tensor(2.3460, device='cuda:0')\n",
            "generator, epoch93 : tensor(3.1316, device='cuda:0')\n",
            "discriminator, epoch94 : tensor(2.3587, device='cuda:0')\n",
            "generator, epoch94 : tensor(3.1065, device='cuda:0')\n",
            "discriminator, epoch95 : tensor(2.3978, device='cuda:0')\n",
            "generator, epoch95 : tensor(3.0246, device='cuda:0')\n",
            "discriminator, epoch96 : tensor(2.3605, device='cuda:0')\n",
            "generator, epoch96 : tensor(3.0891, device='cuda:0')\n",
            "discriminator, epoch97 : tensor(2.4274, device='cuda:0')\n",
            "generator, epoch97 : tensor(2.9724, device='cuda:0')\n",
            "discriminator, epoch98 : tensor(2.2835, device='cuda:0')\n",
            "generator, epoch98 : tensor(3.2198, device='cuda:0')\n",
            "discriminator, epoch99 : tensor(2.3222, device='cuda:0')\n",
            "generator, epoch99 : tensor(3.1437, device='cuda:0')\n",
            "discriminator, epoch100 : tensor(2.2142, device='cuda:0')\n",
            "generator, epoch100 : tensor(3.3466, device='cuda:0')\n",
            "discriminator, epoch101 : tensor(2.1973, device='cuda:0')\n",
            "generator, epoch101 : tensor(3.3767, device='cuda:0')\n",
            "discriminator, epoch102 : tensor(2.1986, device='cuda:0')\n",
            "generator, epoch102 : tensor(3.3854, device='cuda:0')\n",
            "discriminator, epoch103 : tensor(2.2025, device='cuda:0')\n",
            "generator, epoch103 : tensor(3.3844, device='cuda:0')\n",
            "discriminator, epoch104 : tensor(2.2160, device='cuda:0')\n",
            "generator, epoch104 : tensor(3.3347, device='cuda:0')\n",
            "discriminator, epoch105 : tensor(2.2626, device='cuda:0')\n",
            "generator, epoch105 : tensor(3.2712, device='cuda:0')\n",
            "discriminator, epoch106 : tensor(2.1636, device='cuda:0')\n",
            "generator, epoch106 : tensor(3.4362, device='cuda:0')\n",
            "discriminator, epoch107 : tensor(2.1490, device='cuda:0')\n",
            "generator, epoch107 : tensor(3.4634, device='cuda:0')\n",
            "discriminator, epoch108 : tensor(2.0912, device='cuda:0')\n",
            "generator, epoch108 : tensor(3.5854, device='cuda:0')\n",
            "discriminator, epoch109 : tensor(2.0475, device='cuda:0')\n",
            "generator, epoch109 : tensor(3.6900, device='cuda:0')\n",
            "discriminator, epoch110 : tensor(2.0359, device='cuda:0')\n",
            "generator, epoch110 : tensor(3.7148, device='cuda:0')\n",
            "discriminator, epoch111 : tensor(2.0243, device='cuda:0')\n",
            "generator, epoch111 : tensor(3.7658, device='cuda:0')\n",
            "discriminator, epoch112 : tensor(2.0679, device='cuda:0')\n",
            "generator, epoch112 : tensor(3.6304, device='cuda:0')\n",
            "discriminator, epoch113 : tensor(2.1011, device='cuda:0')\n",
            "generator, epoch113 : tensor(3.5741, device='cuda:0')\n",
            "discriminator, epoch114 : tensor(2.0026, device='cuda:0')\n",
            "generator, epoch114 : tensor(3.8135, device='cuda:0')\n",
            "discriminator, epoch115 : tensor(1.9922, device='cuda:0')\n",
            "generator, epoch115 : tensor(3.7984, device='cuda:0')\n",
            "discriminator, epoch116 : tensor(1.9991, device='cuda:0')\n",
            "generator, epoch116 : tensor(3.7749, device='cuda:0')\n",
            "discriminator, epoch117 : tensor(2.0128, device='cuda:0')\n",
            "generator, epoch117 : tensor(3.7467, device='cuda:0')\n",
            "discriminator, epoch118 : tensor(1.9848, device='cuda:0')\n",
            "generator, epoch118 : tensor(3.8173, device='cuda:0')\n",
            "discriminator, epoch119 : tensor(1.9630, device='cuda:0')\n",
            "generator, epoch119 : tensor(3.8451, device='cuda:0')\n",
            "discriminator, epoch120 : tensor(1.9937, device='cuda:0')\n",
            "generator, epoch120 : tensor(3.7547, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}