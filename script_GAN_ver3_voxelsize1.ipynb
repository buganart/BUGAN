{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script_GAN_ver3_voxelsize1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/script_GAN_ver3_voxelsize1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3d5bc2ce-8960-475e-b25b-35dadb9ab027"
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "91c1aff9-e111-4218-9698-a89f89423794"
      },
      "source": [
        "#right click shared folder IRCMS_GAN_collaborative_database and \"Add shortcut to Drive\" to My drive\n",
        "%cd drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj/generated_files/\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ylB2p6N0qQ-G4OsBuwcZ9C0tsqVu9ww4/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj/generated_files\n",
            "old_1_voxel_size1.ply  old_2_voxel_size1.ply  old_3_voxel_size1.ply  wandb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LzAiBuWu6pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install open3d\n",
        "!pip install wandb -q\n",
        "output.clear()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpnFurJt0Pu",
        "colab_type": "text"
      },
      "source": [
        "#add libraries, and login to wandb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_fQzoLaVP2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login\n",
        "output.clear()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f5c77918-d96b-4128-c786-0bf6aef834c7"
      },
      "source": [
        "wandb.init(project=\"tree-gan\")\n",
        "wandb.run.name = str(wandb.run.entity) +\" modelv3 AUG g0.05d0.01 \"+ str(wandb.run.id) # number N after g and d means lr are 0.0001 * N\n",
        "wandb.watch_called = False"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/bugan/tree-gan\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/bugan/tree-gan/runs/jdos4d8q\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan/runs/jdos4d8q</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gr3PMthXkdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keep track of hyperparams\n",
        "config = wandb.config\n",
        "config.batch_size = 3\n",
        "config.test_batch_size = 1\n",
        "config.epochs = 10000\n",
        "config.g_lr = 0.000005\n",
        "config.d_lr = 0.000001           \n",
        "config.seed = 1234\n",
        "config.log_interval = 200"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI",
        "colab_type": "text"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwCa8fUMRcZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def voxel2arrayCentered(voxel, tree_size_scale = 1):\n",
        "    array_size = np.array([64, 64, 64])\n",
        "    vox_array = np.zeros(array_size, dtype=int)  \n",
        "    tree_size = np.array(voxel.get_axis_aligned_bounding_box().get_extent())\n",
        "    tree_size = np.ceil(tree_size / tree_size_scale)    #voxel_size = tree_size_scale\n",
        "    tree_center = (np.ceil(tree_size / 2)).astype(int)\n",
        "\n",
        "    vox_list = voxel.get_voxels()\n",
        "    for vox in vox_list:\n",
        "        coord = vox.grid_index\n",
        "        #center the tree\n",
        "        coord = coord - tree_center + (array_size/2)\n",
        "        coord = tuple(coord.astype(int))\n",
        "\n",
        "        vox_array[coord] = 1.\n",
        "\n",
        "    return vox_array.astype(bool)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf2GIoAjLCCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3591903c-c1de-43d5-8876-d27a05f9a401"
      },
      "source": [
        "#process all files in the generated file folder to generate dataset \n",
        "import os\n",
        "\n",
        "dataset = []\n",
        "for file_name in os.listdir():\n",
        "    if file_name.endswith(\"voxel_size1.ply\"):\n",
        "        #note that the voxel_size of vox is 0.3, so we scale it back to one for indexing\n",
        "        print(file_name)\n",
        "        dataset.append(voxel2arrayCentered(o3d.io.read_voxel_grid(file_name), 1))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "old_1_voxel_size1.ply\n",
            "old_2_voxel_size1.ply\n",
            "old_3_voxel_size1.ply\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "059dc571-f8f3-4889-d444-129608469195"
      },
      "source": [
        "dataset = torch.tensor(dataset)\n",
        "print(torch.unsqueeze(dataset, -1).shape)\n",
        "tensor_dataset = TensorDataset(torch.unsqueeze(dataset, 1))\n",
        "\n",
        "#augment data\n",
        "\n",
        "dataloader = DataLoader(tensor_dataset, batch_size=config.batch_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 64, 64, 64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIaapsqSK5h2",
        "colab_type": "text"
      },
      "source": [
        "#model description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodI2E4ANdYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input: 128-d noise vector\n",
        "#output: (250,250,250) array with values in [0,1]\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.fc_channel = 8 #16\n",
        "        self.fc_size = 4\n",
        "\n",
        "        num_unit1 = self.fc_channel   \n",
        "        num_unit2 = 16   #32\n",
        "        num_unit3 = 32   #64\n",
        "        num_unit4 = 64   #128\n",
        "        num_unit5 = 128   #256\n",
        "        num_unit6 = 256   #512\n",
        "        self.gen_fc = nn.Linear(128, num_unit1 * self.fc_size * self.fc_size * self.fc_size)\n",
        "        self.gen = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit1, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit2, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            \n",
        "            nn.ConvTranspose3d(num_unit3, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit2, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit1, 1, 3, 1, padding = 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.gen_fc(x)\n",
        "        x = x.view(x.shape[0], self.fc_channel, self.fc_size, self.fc_size, self.fc_size)\n",
        "        x = self.gen(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        num_unit1 = 8   #16\n",
        "        num_unit2 = 16   #32\n",
        "        num_unit3 = 32   #64\n",
        "        num_unit4 = 64  #128\n",
        "        num_unit5 = 128   #256\n",
        "        num_unit6 = 256   #512\n",
        "        \n",
        "        self.dis = nn.Sequential(\n",
        "            nn.Conv3d(1, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit2, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit3, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit3, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit4, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit4, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),            \n",
        "            nn.Conv3d(num_unit3, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "\n",
        "            nn.Conv3d(num_unit2, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.dis_fc = nn.Sequential(\n",
        "            nn.Linear(num_unit1 * 4 * 4 * 4, 128),\n",
        "            nn.LeakyReLU(0.1, True),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dis(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dis_fc(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6CzSW9jATSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79df597a-2f23-4165-a6f9-9cfd9bc8a6df"
      },
      "source": [
        "G = Generator().to(device)\n",
        "summary(G, (128,))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 512]          66,048\n",
            "   ConvTranspose3d-2          [-1, 16, 4, 4, 4]           3,472\n",
            "       BatchNorm3d-3          [-1, 16, 4, 4, 4]              32\n",
            "              ReLU-4          [-1, 16, 4, 4, 4]               0\n",
            "   ConvTranspose3d-5          [-1, 32, 4, 4, 4]          13,856\n",
            "       BatchNorm3d-6          [-1, 32, 4, 4, 4]              64\n",
            "              ReLU-7          [-1, 32, 4, 4, 4]               0\n",
            "   ConvTranspose3d-8          [-1, 64, 4, 4, 4]          55,360\n",
            "       BatchNorm3d-9          [-1, 64, 4, 4, 4]             128\n",
            "             ReLU-10          [-1, 64, 4, 4, 4]               0\n",
            "         Upsample-11          [-1, 64, 8, 8, 8]               0\n",
            "  ConvTranspose3d-12          [-1, 64, 8, 8, 8]         110,656\n",
            "      BatchNorm3d-13          [-1, 64, 8, 8, 8]             128\n",
            "             ReLU-14          [-1, 64, 8, 8, 8]               0\n",
            "  ConvTranspose3d-15         [-1, 128, 8, 8, 8]         221,312\n",
            "      BatchNorm3d-16         [-1, 128, 8, 8, 8]             256\n",
            "             ReLU-17         [-1, 128, 8, 8, 8]               0\n",
            "  ConvTranspose3d-18         [-1, 256, 8, 8, 8]         884,992\n",
            "      BatchNorm3d-19         [-1, 256, 8, 8, 8]             512\n",
            "             ReLU-20         [-1, 256, 8, 8, 8]               0\n",
            "         Upsample-21      [-1, 256, 16, 16, 16]               0\n",
            "  ConvTranspose3d-22      [-1, 256, 16, 16, 16]       1,769,728\n",
            "      BatchNorm3d-23      [-1, 256, 16, 16, 16]             512\n",
            "             ReLU-24      [-1, 256, 16, 16, 16]               0\n",
            "  ConvTranspose3d-25      [-1, 128, 16, 16, 16]         884,864\n",
            "      BatchNorm3d-26      [-1, 128, 16, 16, 16]             256\n",
            "             ReLU-27      [-1, 128, 16, 16, 16]               0\n",
            "         Upsample-28      [-1, 128, 32, 32, 32]               0\n",
            "  ConvTranspose3d-29       [-1, 64, 32, 32, 32]         221,248\n",
            "      BatchNorm3d-30       [-1, 64, 32, 32, 32]             128\n",
            "             ReLU-31       [-1, 64, 32, 32, 32]               0\n",
            "  ConvTranspose3d-32       [-1, 32, 32, 32, 32]          55,328\n",
            "      BatchNorm3d-33       [-1, 32, 32, 32, 32]              64\n",
            "             ReLU-34       [-1, 32, 32, 32, 32]               0\n",
            "         Upsample-35       [-1, 32, 64, 64, 64]               0\n",
            "  ConvTranspose3d-36       [-1, 16, 64, 64, 64]          13,840\n",
            "      BatchNorm3d-37       [-1, 16, 64, 64, 64]              32\n",
            "             ReLU-38       [-1, 16, 64, 64, 64]               0\n",
            "  ConvTranspose3d-39        [-1, 8, 64, 64, 64]           3,464\n",
            "      BatchNorm3d-40        [-1, 8, 64, 64, 64]              16\n",
            "             ReLU-41        [-1, 8, 64, 64, 64]               0\n",
            "  ConvTranspose3d-42        [-1, 1, 64, 64, 64]             217\n",
            "          Sigmoid-43        [-1, 1, 64, 64, 64]               0\n",
            "================================================================\n",
            "Total params: 4,306,513\n",
            "Trainable params: 4,306,513\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 365.67\n",
            "Params size (MB): 16.43\n",
            "Estimated Total Size (MB): 382.10\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFZSVCCBIuPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "087ff411-0fb4-46b9-d865-7b497d6c4d6d"
      },
      "source": [
        "D = Discriminator().to(device)\n",
        "summary(D, (1, 64, 64, 64))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1        [-1, 8, 64, 64, 64]             224\n",
            "       BatchNorm3d-2        [-1, 8, 64, 64, 64]              16\n",
            "              ReLU-3        [-1, 8, 64, 64, 64]               0\n",
            "            Conv3d-4       [-1, 16, 64, 64, 64]           3,472\n",
            "       BatchNorm3d-5       [-1, 16, 64, 64, 64]              32\n",
            "              ReLU-6       [-1, 16, 64, 64, 64]               0\n",
            "            Conv3d-7       [-1, 32, 64, 64, 64]          13,856\n",
            "       BatchNorm3d-8       [-1, 32, 64, 64, 64]              64\n",
            "              ReLU-9       [-1, 32, 64, 64, 64]               0\n",
            "        MaxPool3d-10       [-1, 32, 32, 32, 32]               0\n",
            "           Conv3d-11       [-1, 32, 32, 32, 32]          27,680\n",
            "      BatchNorm3d-12       [-1, 32, 32, 32, 32]              64\n",
            "             ReLU-13       [-1, 32, 32, 32, 32]               0\n",
            "           Conv3d-14       [-1, 64, 32, 32, 32]          55,360\n",
            "      BatchNorm3d-15       [-1, 64, 32, 32, 32]             128\n",
            "             ReLU-16       [-1, 64, 32, 32, 32]               0\n",
            "        MaxPool3d-17       [-1, 64, 16, 16, 16]               0\n",
            "           Conv3d-18      [-1, 128, 16, 16, 16]         221,312\n",
            "      BatchNorm3d-19      [-1, 128, 16, 16, 16]             256\n",
            "             ReLU-20      [-1, 128, 16, 16, 16]               0\n",
            "           Conv3d-21      [-1, 128, 16, 16, 16]         442,496\n",
            "      BatchNorm3d-22      [-1, 128, 16, 16, 16]             256\n",
            "             ReLU-23      [-1, 128, 16, 16, 16]               0\n",
            "           Conv3d-24       [-1, 64, 16, 16, 16]         221,248\n",
            "      BatchNorm3d-25       [-1, 64, 16, 16, 16]             128\n",
            "             ReLU-26       [-1, 64, 16, 16, 16]               0\n",
            "        MaxPool3d-27          [-1, 64, 8, 8, 8]               0\n",
            "           Conv3d-28          [-1, 32, 8, 8, 8]          55,328\n",
            "      BatchNorm3d-29          [-1, 32, 8, 8, 8]              64\n",
            "             ReLU-30          [-1, 32, 8, 8, 8]               0\n",
            "           Conv3d-31          [-1, 16, 8, 8, 8]          13,840\n",
            "      BatchNorm3d-32          [-1, 16, 8, 8, 8]              32\n",
            "             ReLU-33          [-1, 16, 8, 8, 8]               0\n",
            "        MaxPool3d-34          [-1, 16, 4, 4, 4]               0\n",
            "           Conv3d-35           [-1, 8, 4, 4, 4]           3,464\n",
            "      BatchNorm3d-36           [-1, 8, 4, 4, 4]              16\n",
            "             ReLU-37           [-1, 8, 4, 4, 4]               0\n",
            "           Conv3d-38           [-1, 8, 4, 4, 4]           1,736\n",
            "      BatchNorm3d-39           [-1, 8, 4, 4, 4]              16\n",
            "             ReLU-40           [-1, 8, 4, 4, 4]               0\n",
            "           Linear-41                  [-1, 128]          65,664\n",
            "        LeakyReLU-42                  [-1, 128]               0\n",
            "           Linear-43                    [-1, 1]             129\n",
            "          Sigmoid-44                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 1,126,881\n",
            "Trainable params: 1,126,881\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.00\n",
            "Forward/backward pass size (MB): 448.85\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 454.14\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrRSqnqK20W",
        "colab_type": "text"
      },
      "source": [
        "#functions for pytorch network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHZ9sGFVspXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def array2voxel(array):\n",
        "    coord_list = []\n",
        "    if len(array.shape) == 5:\n",
        "        array = array[0][0]\n",
        "    x,y,z = array.shape\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            for k in range(z):\n",
        "                if array[i,j,k] > 0.5:\n",
        "                    coord_list.append([i,j,k])\n",
        "    print(len(coord_list))\n",
        "    if len(coord_list) == 0:\n",
        "        return np.array([[0,0,0]])  #return at least one point to prevent wandb 3dobject error\n",
        "    return np.array(coord_list)\n",
        "\n",
        "def train_model(generator, discriminator, dataloader):   \n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='sum')\n",
        "    #optimizer\n",
        "    # dis_optimizer = optim.SGD(discriminator.parameters(), lr=config.d_lr)\n",
        "    # gen_optimizer = optim.SGD(generator.parameters(), lr=config.g_lr)   \n",
        "    dis_optimizer = optim.Adam(discriminator.parameters(), lr=config.d_lr)\n",
        "    gen_optimizer = optim.Adam(generator.parameters(), lr=config.g_lr)\n",
        "\n",
        "    #log models\n",
        "    wandb.watch(generator, log=\"all\")\n",
        "    wandb.watch(discriminator, log=\"all\")\n",
        "\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "    for epoch in range(config.epochs):\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        d_ep_loss = 0.\n",
        "        g_ep_loss = 0.\n",
        "        for dataset_batch in dataloader:\n",
        "\n",
        "            dataset_batch = dataset_batch[0]\n",
        "            #add data augmentation (rotate 90/180/270)\n",
        "            #this modify the whole batch at the same time\n",
        "            rand_num = torch.randn(2)\n",
        "            if rand_num[0] > 0.5:\n",
        "                dataset_batch = dataset_batch.permute(0, 1, 3,2,4)\n",
        "            if rand_num[1] > 0.5: \n",
        "                dataset_batch = dataset_batch.flip([4])\n",
        "                \n",
        "            dataset_batch = dataset_batch.float().to(device)\n",
        "            dloss, gloss = compute_loss(generator, discriminator, dataset_batch)\n",
        "\n",
        "\n",
        "            #optimize generator\n",
        "            gen_optimizer.zero_grad()\n",
        "            gloss.backward()\n",
        "            gen_optimizer.step()\n",
        "\n",
        "            #optimize discriminator\n",
        "            dis_optimizer.zero_grad()\n",
        "            dloss.backward()\n",
        "            dis_optimizer.step()\n",
        "          \n",
        "\n",
        "            #record loss\n",
        "            d_ep_loss += dloss.detach()  \n",
        "            g_ep_loss += gloss.detach()\n",
        "\n",
        "        #after each epoch, record total loss and sample generated obj\n",
        "        d_losses.append(d_ep_loss)\n",
        "        g_losses.append(g_ep_loss)\n",
        "        print(\"discriminator, epoch\"+str(epoch)+\" : \"+str(d_ep_loss))\n",
        "        print(\"generator, epoch\"+str(epoch)+\" : \"+str(g_ep_loss))\n",
        "\n",
        "        #save model if necessary\n",
        "        if epoch % config.log_interval == 0:\n",
        "            sample_tree = array2voxel(generate_tree(generator))\n",
        "\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss,\n",
        "            \"sample_tree\": wandb.Object3D(sample_tree)})\n",
        "            torch.save(generator.state_dict(), os.path.join(wandb.run.dir, 'generator.pth'))\n",
        "            torch.save(discriminator.state_dict(), os.path.join(wandb.run.dir, 'discriminator.pth'))\n",
        "        else:\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"generator loss\": g_ep_loss})\n",
        "    \n",
        "    #training end, save model again\n",
        "    sample_tree = array2voxel(generate_tree(generator))\n",
        "\n",
        "    wandb.log({\n",
        "    \"discriminator loss\": d_ep_loss,\n",
        "    \"generator loss\": g_ep_loss,\n",
        "    \"sample_tree\": wandb.Object3D(sample_tree)})\n",
        "    torch.save(generator.state_dict(), os.path.join(wandb.run.dir, 'generator.pth'))\n",
        "    torch.save(discriminator.state_dict(), os.path.join(wandb.run.dir, 'discriminator.pth'))\n",
        "    \n",
        "    print(d_losses)\n",
        "    print(g_losses)\n",
        "\n",
        "# this function calculate loss of the model, \n",
        "def compute_loss(generator, discriminator, dataset_batch):\n",
        "    \n",
        "    #loss function\n",
        "    criterion = nn.BCELoss(reduction='sum')   \n",
        "\n",
        "    batch_size = dataset_batch.shape[0]\n",
        "        \n",
        "    #labels\n",
        "    real_label = torch.unsqueeze(torch.ones(batch_size),1).float().to(device)\n",
        "    fake_label = torch.unsqueeze(torch.zeros(batch_size),1).float().to(device)\n",
        "\n",
        "    ############\n",
        "    #   discriminator\n",
        "    ############\n",
        "    #generate fake trees\n",
        "    z = torch.randn(batch_size, 128).float().to(device) #128-d noise vector\n",
        "    tree_fake = generator(z)\n",
        "\n",
        "    #real data (data from dataloader)\n",
        "    dout_real = discriminator(dataset_batch)\n",
        "    dloss_real = criterion(dout_real, real_label)\n",
        "    score_real = dout_real\n",
        "    #fake data (data from generator)            \n",
        "    dout_fake = discriminator(tree_fake.clone().detach())   #detach so no double update on the same batch of tree_fake\n",
        "    dloss_fake = criterion(dout_fake, fake_label)\n",
        "    score_fake = dout_fake\n",
        "\n",
        "    #loss function (discriminator classify real data vs generated data)\n",
        "    dloss = dloss_real + dloss_fake\n",
        "\n",
        "    ############\n",
        "    #   generator\n",
        "    ############\n",
        "\n",
        "    #tree_fake is already computed above\n",
        "    dout_fake = discriminator(tree_fake)\n",
        "    #generator should generate trees that discriminator think they are real\n",
        "    gloss = criterion(dout_fake, real_label)    \n",
        "\n",
        "    return dloss, gloss\n",
        "\n",
        "\n",
        "def save_model(generator, discriminator, g_path = os.path.join(wandb.run.dir, 'generator.pth') , d_path = os.path.join(wandb.run.dir, 'discriminator.pth')):\n",
        "    torch.save(generator.state_dict(), g_path)\n",
        "    torch.save(discriminator.state_dict(), d_path)\n",
        "\n",
        "def load_model(g_path = os.path.join(wandb.run.dir, 'generator.pth'), d_path = os.path.join(wandb.run.dir, 'discriminator.pth')):\n",
        "    generator = Generator()\n",
        "    generator.load_state_dict(torch.load(g_path))\n",
        "    generator.eval()\n",
        "\n",
        "    discriminator = Discriminator()\n",
        "    discriminator.load_state_dict(torch.load(d_path))\n",
        "    discriminator.eval()\n",
        "    return generator, discriminator\n",
        "\n",
        "def generate_tree(generator, num_trees = 1):\n",
        "    \n",
        "    #generate noise vector\n",
        "    z = torch.randn(num_trees, 128).to(device)\n",
        "    generator.to(device).eval()\n",
        "    tree_fake = generator(z)\n",
        "    return tree_fake.detach().cpu().numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3",
        "colab_type": "text"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQWIWapYOsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b05fd38-4f5e-404e-f2ab-a8f1dfaa967c"
      },
      "source": [
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "train_model(G, D, dataloader)        #if dataloader has only 1 tree, the training time is 72s per epoch."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch0 : tensor(3.9215, device='cuda:0')\n",
            "generator, epoch0 : tensor(2.3877, device='cuda:0')\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/wandb/data_types.py:464: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  elif 'type' in data_or_path:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch1 : tensor(4.0577, device='cuda:0')\n",
            "generator, epoch1 : tensor(2.2979, device='cuda:0')\n",
            "discriminator, epoch2 : tensor(3.9657, device='cuda:0')\n",
            "generator, epoch2 : tensor(2.3923, device='cuda:0')\n",
            "discriminator, epoch3 : tensor(4.1879, device='cuda:0')\n",
            "generator, epoch3 : tensor(2.2806, device='cuda:0')\n",
            "discriminator, epoch4 : tensor(3.8914, device='cuda:0')\n",
            "generator, epoch4 : tensor(2.3577, device='cuda:0')\n",
            "discriminator, epoch5 : tensor(4.0257, device='cuda:0')\n",
            "generator, epoch5 : tensor(2.4557, device='cuda:0')\n",
            "discriminator, epoch6 : tensor(3.8058, device='cuda:0')\n",
            "generator, epoch6 : tensor(2.4418, device='cuda:0')\n",
            "discriminator, epoch7 : tensor(3.8089, device='cuda:0')\n",
            "generator, epoch7 : tensor(2.4209, device='cuda:0')\n",
            "discriminator, epoch8 : tensor(3.8015, device='cuda:0')\n",
            "generator, epoch8 : tensor(2.4144, device='cuda:0')\n",
            "discriminator, epoch9 : tensor(3.9274, device='cuda:0')\n",
            "generator, epoch9 : tensor(2.3534, device='cuda:0')\n",
            "discriminator, epoch10 : tensor(3.7611, device='cuda:0')\n",
            "generator, epoch10 : tensor(2.4370, device='cuda:0')\n",
            "discriminator, epoch11 : tensor(3.8378, device='cuda:0')\n",
            "generator, epoch11 : tensor(2.3280, device='cuda:0')\n",
            "discriminator, epoch12 : tensor(3.8241, device='cuda:0')\n",
            "generator, epoch12 : tensor(2.4577, device='cuda:0')\n",
            "discriminator, epoch13 : tensor(4.0028, device='cuda:0')\n",
            "generator, epoch13 : tensor(2.4764, device='cuda:0')\n",
            "discriminator, epoch14 : tensor(3.6918, device='cuda:0')\n",
            "generator, epoch14 : tensor(2.4644, device='cuda:0')\n",
            "discriminator, epoch15 : tensor(3.7773, device='cuda:0')\n",
            "generator, epoch15 : tensor(2.3452, device='cuda:0')\n",
            "discriminator, epoch16 : tensor(4.0064, device='cuda:0')\n",
            "generator, epoch16 : tensor(2.4005, device='cuda:0')\n",
            "discriminator, epoch17 : tensor(3.8976, device='cuda:0')\n",
            "generator, epoch17 : tensor(2.3318, device='cuda:0')\n",
            "discriminator, epoch18 : tensor(3.8349, device='cuda:0')\n",
            "generator, epoch18 : tensor(2.3948, device='cuda:0')\n",
            "discriminator, epoch19 : tensor(4.0588, device='cuda:0')\n",
            "generator, epoch19 : tensor(2.3804, device='cuda:0')\n",
            "discriminator, epoch20 : tensor(3.6199, device='cuda:0')\n",
            "generator, epoch20 : tensor(2.4858, device='cuda:0')\n",
            "discriminator, epoch21 : tensor(4.0009, device='cuda:0')\n",
            "generator, epoch21 : tensor(2.3700, device='cuda:0')\n",
            "discriminator, epoch22 : tensor(4.0483, device='cuda:0')\n",
            "generator, epoch22 : tensor(2.3700, device='cuda:0')\n",
            "discriminator, epoch23 : tensor(3.6850, device='cuda:0')\n",
            "generator, epoch23 : tensor(2.3817, device='cuda:0')\n",
            "discriminator, epoch24 : tensor(4.0152, device='cuda:0')\n",
            "generator, epoch24 : tensor(2.3963, device='cuda:0')\n",
            "discriminator, epoch25 : tensor(3.9570, device='cuda:0')\n",
            "generator, epoch25 : tensor(2.3898, device='cuda:0')\n",
            "discriminator, epoch26 : tensor(3.9373, device='cuda:0')\n",
            "generator, epoch26 : tensor(2.4814, device='cuda:0')\n",
            "discriminator, epoch27 : tensor(3.9790, device='cuda:0')\n",
            "generator, epoch27 : tensor(2.4190, device='cuda:0')\n",
            "discriminator, epoch28 : tensor(3.6212, device='cuda:0')\n",
            "generator, epoch28 : tensor(2.4264, device='cuda:0')\n",
            "discriminator, epoch29 : tensor(3.6795, device='cuda:0')\n",
            "generator, epoch29 : tensor(2.3451, device='cuda:0')\n",
            "discriminator, epoch30 : tensor(3.9887, device='cuda:0')\n",
            "generator, epoch30 : tensor(2.3707, device='cuda:0')\n",
            "discriminator, epoch31 : tensor(3.7013, device='cuda:0')\n",
            "generator, epoch31 : tensor(2.4983, device='cuda:0')\n",
            "discriminator, epoch32 : tensor(3.8844, device='cuda:0')\n",
            "generator, epoch32 : tensor(2.4267, device='cuda:0')\n",
            "discriminator, epoch33 : tensor(3.5436, device='cuda:0')\n",
            "generator, epoch33 : tensor(2.4857, device='cuda:0')\n",
            "discriminator, epoch34 : tensor(3.7648, device='cuda:0')\n",
            "generator, epoch34 : tensor(2.5687, device='cuda:0')\n",
            "discriminator, epoch35 : tensor(3.6147, device='cuda:0')\n",
            "generator, epoch35 : tensor(2.3852, device='cuda:0')\n",
            "discriminator, epoch36 : tensor(3.8387, device='cuda:0')\n",
            "generator, epoch36 : tensor(2.4464, device='cuda:0')\n",
            "discriminator, epoch37 : tensor(3.7712, device='cuda:0')\n",
            "generator, epoch37 : tensor(2.5201, device='cuda:0')\n",
            "discriminator, epoch38 : tensor(3.7789, device='cuda:0')\n",
            "generator, epoch38 : tensor(2.3723, device='cuda:0')\n",
            "discriminator, epoch39 : tensor(3.5864, device='cuda:0')\n",
            "generator, epoch39 : tensor(2.3939, device='cuda:0')\n",
            "discriminator, epoch40 : tensor(3.7070, device='cuda:0')\n",
            "generator, epoch40 : tensor(2.4516, device='cuda:0')\n",
            "discriminator, epoch41 : tensor(3.4545, device='cuda:0')\n",
            "generator, epoch41 : tensor(2.5524, device='cuda:0')\n",
            "discriminator, epoch42 : tensor(3.6126, device='cuda:0')\n",
            "generator, epoch42 : tensor(2.3470, device='cuda:0')\n",
            "discriminator, epoch43 : tensor(3.6612, device='cuda:0')\n",
            "generator, epoch43 : tensor(2.4929, device='cuda:0')\n",
            "discriminator, epoch44 : tensor(3.4256, device='cuda:0')\n",
            "generator, epoch44 : tensor(2.5654, device='cuda:0')\n",
            "discriminator, epoch45 : tensor(3.5310, device='cuda:0')\n",
            "generator, epoch45 : tensor(2.4223, device='cuda:0')\n",
            "discriminator, epoch46 : tensor(3.5502, device='cuda:0')\n",
            "generator, epoch46 : tensor(2.3895, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}