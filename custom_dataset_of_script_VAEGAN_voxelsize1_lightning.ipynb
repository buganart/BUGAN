{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_dataset_of_script_VAEGAN_voxelsize1_lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/custom_dataset_of_script_VAEGAN_voxelsize1_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form"
      },
      "source": [
        "#@markdown Install wandb and log in\n",
        "%pip install wandb\n",
        "output.clear()\n",
        "import wandb\n",
        "!wandb login\n",
        "output.clear()\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH"
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown - Leave empty if you want to start a new run\n",
        "#@markdown - Set `\"run_id\"` if you want to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "resume_id = \"\" #@param {type:\"string\"}\n",
        "#@markdown Enter project name (either `handtool-gan` or `tree-gan`)\n",
        "project_name = \"tree-gan\" #@param [\"tree-gan\", \"handtool-gan\"]\n",
        "#@markdown Enter dataset location.  \n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.)\n",
        "#@markdown - zipfile example: `/content/drive/My Drive/h/k/a.zip`\n",
        "#@markdown - file folder example: `/content/drive/My Drive/h/k` \n",
        "data_location = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj_auto_generated/sessions/simplified/tree-session-2020-09-14_23-23-Friedrich_2-target-face-num-1000.zip\" #@param {type:\"string\"}\n",
        "#@markdown - choose rotation augmentation on-the-fly \n",
        "#@markdown (augmentation only support file folder in data_location)\n",
        "data_augmentation = True    #@param {type:\"boolean\"}\n",
        "aug_rotation_type = \"random rotation\"  #@param [\"random rotation\", \"axis rotation\"]\n",
        "#@markdown - specify the rotation axis [x,y,z] (only for aug_rotation_type = \"axis rotation\")\n",
        "rotation_axis_x = 0    #@param {type:\"number\"}\n",
        "rotation_axis_y = 1    #@param {type:\"number\"}\n",
        "rotation_axis_z = 0    #@param {type:\"number\"}\n",
        "\n",
        "#@markdown - resolution of the voxelized array (shape resolution**3)\n",
        "resolution = \"32\"    #@param [32, 64]\n",
        "\n",
        "#@markdown Model\n",
        "#@markdown - select which model to train\n",
        "selected_model = \"VAEGAN\"    #@param [\"VAEGAN\", \"GAN\", \"VAE\"]\n",
        "\n",
        "#@markdown WANDB log\n",
        "#@markdown - how many epochs before logging images/3D objects\n",
        "log_interval = 5    #@param {type:\"integer\"}\n",
        "#@markdown - how many samples per log\n",
        "log_num_samples = 3    #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "colab_config = {\n",
        "    \"aug_rotation_type\": aug_rotation_type,\n",
        "    \"data_augmentation\": data_augmentation,\n",
        "    \"data_location\": data_location,\n",
        "    \"resume_id\": resume_id,\n",
        "    \"log_interval\": log_interval,\n",
        "    \"log_num_samples\": log_num_samples,\n",
        "    \"project_name\": project_name,\n",
        "    \"resolution\": resolution\n",
        "}\n",
        "\n",
        "for k, v in colab_config.items():\n",
        "    print(f\"=> {k:20}: {v}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%cd /content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\n",
        "if project_name == \"tree-gan\":\n",
        "    %cd colab-treegan/\n",
        "else:\n",
        "    %cd colab-handtool/\n",
        "\n",
        "dataset_path = Path(data_location)\n",
        "run_path = \"./\"\n",
        "\n",
        "if data_location.endswith(\".zip\"):\n",
        "    dataset_name = dataset_path.stem\n",
        "else:\n",
        "    dataset_name = \"dataset_array_custom\"\n",
        "\n",
        "!apt-get update\n",
        "\n",
        "%pip install pytorch-lightning\n",
        "%pip install trimesh\n",
        "!apt install -y xvfb\n",
        "%pip install trimesh xvfbwrapper\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo"
      },
      "source": [
        "import io\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import trimesh\n",
        "import numpy as np\n",
        "from argparse import Namespace\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "from xvfbwrapper import Xvfb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0"
      },
      "source": [
        "if not resume_id:\n",
        "    run_id = wandb.util.generate_id()\n",
        "    resume = False\n",
        "else:\n",
        "    run_id = resume_id\n",
        "    resume = True\n",
        "\n",
        "run = wandb.init(project=project_name, id=run_id, entity=\"bugan\", resume=True, dir=run_path, group=selected_model)\n",
        "\n",
        "print(\"run id: \" + str(wandb.run.id))\n",
        "print(\"run name: \" + str(wandb.run.name))\n",
        "wandb.watch_called = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww3zbHkxAw8B"
      },
      "source": [
        "#keep track of hyperparams\n",
        "config = Namespace(**colab_config)\n",
        "\n",
        "config.epochs = 3000\n",
        "config.batch_size = 32\n",
        "config.array_size = int(resolution)\n",
        "\n",
        "#model param\n",
        "config.z_size = 128\n",
        "if config.array_size == 32:\n",
        "    config.gen_num_layer_unit = [1024, 512, 256, 128]\n",
        "    config.dis_num_layer_unit = [32, 64, 128, 128]\n",
        "else:\n",
        "    config.gen_num_layer_unit = [1024, 512, 256, 128, 128]\n",
        "    config.dis_num_layer_unit = [32, 64, 64, 128, 128]\n",
        "\n",
        "if selected_model == \"VAEGAN\":\n",
        "    config.vae_recon_loss_factor = 1\n",
        "    config.vae_opt = \"Adam\"\n",
        "    config.dis_opt = \"Adam\"\n",
        "    config.vae_lr = 0.0025\n",
        "    config.vae_encoder_layer = 1\n",
        "    config.vae_decoder_layer = 2\n",
        "    config.d_lr = 0.00005            \n",
        "    config.d_layer = 1\n",
        "elif selected_model == \"GAN\":\n",
        "    config.gen_opt = \"Adam\"\n",
        "    config.dis_opt = \"Adam\"\n",
        "    config.g_lr = 0.0025\n",
        "    config.g_layer = 2\n",
        "    config.d_lr = 0.00005           \n",
        "    config.d_layer = 1\n",
        "else:\n",
        "    config.vae_opt = \"Adam\"\n",
        "    config.vae_lr = 0.0025\n",
        "    config.vae_encoder_layer = 1\n",
        "    config.vae_decoder_layer = 2\n",
        "\n",
        "config.seed = 1234\n",
        "config.aug_rotation_axis = (rotation_axis_x,rotation_axis_y,rotation_axis_z)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR"
      },
      "source": [
        "### load our package\n",
        "\n",
        "#directly install using pip\n",
        "%pip install git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "output.clear()\n",
        "\n",
        "from bugan.functionsPL import *\n",
        "from bugan.modelsPL import VAEGAN, VAE_train, GAN, VAE, Discriminator, Generator\n",
        "\n",
        "\n",
        "run.tags.append(selected_model)\n",
        "\n",
        "###     load dataset\n",
        "np.random.seed(config.seed)\n",
        "\n",
        "config.dataset = dataset_name\n",
        "dataModule = DataModule_process(config, run, dataset_path)\n",
        "config.num_data = dataModule.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzV_Mzfd_MZ"
      },
      "source": [
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "#render setup\n",
        "vdisplay = Xvfb()\n",
        "vdisplay.start()\n",
        "\n",
        "#wandb logger setup\n",
        "wandb_logger = WandbLogger(experiment=run, log_model=True)\n",
        "#log config\n",
        "wandb.config.update(config)\n",
        "\n",
        "checkpoint_path = str(Path(wandb.run.dir).absolute()/'checkpoint.ckpt')\n",
        "callbacks = [SaveWandbCallback(config.log_interval, checkpoint_path)]\n",
        "\n",
        "\n",
        "if resume:\n",
        "    # Download file from the wandb cloud.\n",
        "    load_checkpoint_from_cloud(checkpoint_path = 'checkpoint.ckpt')\n",
        "    extra_trainer_args = {'resume_from_checkpoint': checkpoint_path}\n",
        "else:\n",
        "    extra_trainer_args = {}\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = config.epochs, logger=wandb_logger, callbacks=callbacks, checkpoint_callback = None, **extra_trainer_args)\n",
        "\n",
        "#model\n",
        "if selected_model == \"VAEGAN\":\n",
        "    model = VAEGAN(config).to(device)\n",
        "elif selected_model == \"GAN\":\n",
        "    model = GAN(config).to(device)\n",
        "else:\n",
        "    model = VAE_train(config).to(device)\n",
        "wandb_logger.watch(model)\n",
        "\n",
        "\n",
        "#train\n",
        "trainer.fit(model, dataModule)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}