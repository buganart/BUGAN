{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_dataset_of_script_VAEGAN_voxelsize1_lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/custom_dataset_of_script_VAEGAN_voxelsize1_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form",
        "outputId": "18dfb461-57cd-427b-a6cd-9fd456ba70e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form",
        "outputId": "5c017953-2529-4f03-98a3-b68f6b25fb62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown Install wandb and log in\n",
        "!pip install wandb==0.9.7\n",
        "output.clear()\n",
        "import wandb\n",
        "!wandb login\n",
        "output.clear()\n",
        "print(\"ok!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH",
        "cellView": "both",
        "outputId": "e034eb28-f781-4e75-c96a-42a07bfc61b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown - set `None`if you want to start a new run\n",
        "#@markdown - set `\"run_id\"` if you want to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "id = \"172mqt5l\" #@param {type:\"string\"}\n",
        "#@markdown Enter project name (either `handtool-gan` or `tree-gan`)\n",
        "project_name = \"tree-gan\" #@param [\"tree-gan\", \"handtool-gan\"]\n",
        "#@markdown Enter dataset location.  \n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.)\n",
        "#@markdown - zipfile example: `/content/drive/My Drive/h/k/a.zip`\n",
        "#@markdown - file folder example: `/content/drive/My Drive/h/k` \n",
        "data_location = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Chairs_Princeton/chair_train.zip\" #@param {type:\"string\"}\n",
        "#@markdown - choose rotation augmentation on-the-fly \n",
        "#@markdown (augmentation only support file folder in data_location)\n",
        "data_augmentation = True    #@param {type:\"boolean\"}\n",
        "aug_rotation_type = \"random rotation\"  #@param [\"random rotation\", \"axis rotation\"]\n",
        "#@markdown - specify the rotation axis [x,y,z] (only for aug_rotation_type = \"axis rotation\")\n",
        "rotation_axis_x = 0    #@param {type:\"number\"}\n",
        "rotation_axis_y = 1    #@param {type:\"number\"}\n",
        "rotation_axis_z = 0    #@param {type:\"number\"}\n",
        "\n",
        "#@markdown - resolution of the voxelized array (shape resolution**3)\n",
        "resolution = \"32\"    #@param [32, 64]\n",
        "\n",
        "#@markdown WANDB log\n",
        "#@markdown - how many epochs before logging images/3D objects\n",
        "log_interval = 5    #@param {type:\"integer\"}\n",
        "#@markdown - how many samples per log\n",
        "log_num_samples = 3    #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#@markdown test: Generate Samples\n",
        "#@markdown - choose whether to train the model or generate samples\n",
        "isTraining = False    #@param {type:\"boolean\"}\n",
        "#@markdown - how many samples to generate in testing\n",
        "test_num_samples = 20    #@param {type:\"integer\"}\n",
        "#@markdown Enter export location (folder/directory).   \n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.)\n",
        "#@markdown - file folder example: `/content/drive/My Drive/h/k` \n",
        "export_location = f\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/{id}\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "print(\"id:\", id)\n",
        "print(\"project_name:\", project_name)\n",
        "print(\"data_location:\", data_location)\n",
        "print(\"data_augmentation:\", data_augmentation)\n",
        "print(\"resolution:\", resolution)\n",
        "print(\"log_interval:\", log_interval)\n",
        "print(\"log_num_samples:\", log_num_samples)\n",
        "\n",
        "print(\"isTraining:\", isTraining)\n",
        "print(\"test_num_samples:\", test_num_samples)\n",
        "print(\"export_location:\", export_location)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id: 172mqt5l\n",
            "project_name: tree-gan\n",
            "data_location: /content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Chairs_Princeton/chair_train.zip\n",
            "data_augmentation: True\n",
            "resolution: 32\n",
            "log_interval: 5\n",
            "log_num_samples: 3\n",
            "isTraining: False\n",
            "test_num_samples: 20\n",
            "export_location: /content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "outputId": "0fbaea76-984d-4992-faff-47332817b062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%cd /content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\n",
        "if project_name == \"tree-gan\":\n",
        "    %cd colab-treegan/\n",
        "else:\n",
        "    %cd colab-handtool/\n",
        "\n",
        "dataset_path = Path(data_location)\n",
        "run_path = \"./\"\n",
        "\n",
        "if data_location.endswith(\".zip\"):\n",
        "    dataset_name = dataset_path.stem\n",
        "else:\n",
        "    dataset_name = \"dataset_array_custom\"\n",
        "\n",
        "!apt-get update\n",
        "\n",
        "!pip install pytorch-lightning==0.9.0\n",
        "!pip install trimesh\n",
        "!apt install -y xvfb\n",
        "!pip install trimesh xvfbwrapper\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo"
      },
      "source": [
        "import io\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import trimesh\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "from xvfbwrapper import Xvfb"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0",
        "outputId": "ed27e8c9-0225-46ef-ae53-e08de9173db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "resume = False\n",
        "if id is None:\n",
        "    id = wandb.util.generate_id()\n",
        "else:\n",
        "    resume = True\n",
        "\n",
        "run = wandb.init(project=project_name, id=id, entity=\"bugan\", resume=True, dir=run_path)\n",
        "print(\"run id: \" + str(wandb.run.id))\n",
        "print(\"run name: \" + str(wandb.run.name))\n",
        "wandb.watch_called = False\n",
        "wandb.run.save_code = True"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/bugan/tree-gan\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/bugan/tree-gan/runs/172mqt5l\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan/runs/172mqt5l</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.8 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "run id: 172mqt5l\n",
            "run name: 172mqt5l\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Streaming file created twice in same run: ./wandb/run-20201103_162325-172mqt5l/wandb-events.jsonl\n",
            "Streaming file created twice in same run: ./wandb/run-20201103_162325-172mqt5l/wandb-history.jsonl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww3zbHkxAw8B",
        "outputId": "2ad01b89-6b9f-4f6d-b7f4-0b08e114cd2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#keep track of hyperparams\n",
        "config = wandb.config\n",
        "\n",
        "config.batch_size = 8\n",
        "config.array_size = int(resolution)\n",
        "\n",
        "config.z_size = 128\n",
        "if config.array_size == 32:\n",
        "    config.gen_num_layer_unit = [1024, 512, 256, 128]\n",
        "    config.dis_num_layer_unit = [32, 64, 128, 128]\n",
        "else:\n",
        "    config.gen_num_layer_unit = [1024, 512, 256, 128, 128]\n",
        "    config.dis_num_layer_unit = [32, 64, 64, 128, 128]\n",
        "\n",
        "config.leakyReLU = False    #leakyReLU implementation still not in modelPL\n",
        "config.balance_voxel_in_space = False\n",
        "\n",
        "config.epochs = 3000\n",
        "config.vae_lr = 0.0025\n",
        "config.vae_encoder_layer = 1\n",
        "config.vae_decoder_layer = 2\n",
        "config.d_lr = 0.00005            \n",
        "config.d_layer = 1\n",
        "config.vae_recon_loss_factor = 1\n",
        "config.seed = 1234\n",
        "config.log_interval = log_interval\n",
        "config.log_num_samples = log_num_samples\n",
        "config.data_augmentation = data_augmentation\n",
        "config.aug_rotation_type = aug_rotation_type\n",
        "config.aug_rotation_axis = (rotation_axis_x,rotation_axis_y,rotation_axis_z)\n",
        "\n",
        "config.vae_opt = \"Adam\"\n",
        "config.dis_opt = \"Adam\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.8 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR",
        "outputId": "2963c8bb-b262-4bb9-ab23-e8d2ce05e454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### load our package\n",
        "\n",
        "#clone then install\n",
        "# !git clone https://github.com/buganart/BUGAN repo\n",
        "# !pip install -e ./repo/\n",
        "# import site\n",
        "# site.main()\n",
        "\n",
        "#directly install using pip\n",
        "!pip install -U git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "output.clear()\n",
        "\n",
        "from bugan.functionsPL import *\n",
        "from bugan.modelsPL import VAEGAN, VAE, Discriminator, Generator\n",
        "\n",
        "# from functionsPL import *\n",
        "# from modelsPL import VAEGAN, VAE, Discriminator, Generator\n",
        "\n",
        "run.tags.append(\"VAEGAN\")\n",
        "run.group = \"VAEGAN\"\n",
        "\n",
        "###     load dataset\n",
        "np.random.seed(config.seed)\n",
        "# dataModule = DataModule(config, run)\n",
        "# config.num_data = dataModule.size\n",
        "\n",
        "config.dataset = dataset_name\n",
        "if config.data_augmentation:\n",
        "    dataModule = DataModule_augmentation(config, run, dataset_path)\n",
        "else:\n",
        "    dataModule = DataModule_process(config, run, dataset_path)\n",
        "config.num_data = dataModule.size"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.8 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzV_Mzfd_MZ",
        "outputId": "3e797723-6702-45bb-ebbd-8ee43859c904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "#render setup\n",
        "vdisplay = Xvfb()\n",
        "vdisplay.start()\n",
        "\n",
        "#wandb logger setup\n",
        "wandb_logger = WandbLogger(experiment=run, log_model=True)\n",
        "\n",
        "checkpoint_path = os.path.join(wandb.run.dir, 'checkpoint.ckpt')\n",
        "\n",
        "if resume:\n",
        "    #get file from the wandb cloud\n",
        "    load_checkpoint_from_cloud(checkpoint_path = 'checkpoint.ckpt')\n",
        "    #restore training state completely\n",
        "    trainer = pl.Trainer(max_epochs = config.epochs, logger=wandb_logger, checkpoint_callback = None, resume_from_checkpoint = checkpoint_path)\n",
        "else:\n",
        "    trainer = pl.Trainer(max_epochs = config.epochs, logger=wandb_logger, checkpoint_callback = None)\n",
        "\n",
        "#model\n",
        "vaegan = VAEGAN(config, trainer, save_model_path = checkpoint_path).to(device)\n",
        "wandb_logger.watch(vaegan)\n",
        "\n",
        "\n",
        "#train/test model\n",
        "if isTraining:\n",
        "    trainer.fit(vaegan, dataModule)\n",
        "else:\n",
        "    trainer.test(vaegan, ckpt_path=checkpoint_path)\n",
        "    vaegan = trainer.model.eval()\n",
        "\n",
        "    sample_trees = vaegan.generate_tree(num_trees=test_num_samples)\n",
        "\n",
        "    #create directory\n",
        "    export_location = Path(export_location)\n",
        "    print(export_location.exists())\n",
        "    if not export_location.exists():\n",
        "        export_location.mkdir(parents=True)\n",
        "\n",
        "    sample_meshes = []\n",
        "    for n in range(test_num_samples):\n",
        "        sample_tree_array = sample_trees[n]\n",
        "        voxelmesh = netarray2mesh(sample_tree_array)\n",
        "        export_path = export_location / f\"sample_{n}.obj\"\n",
        "        print(export_path)\n",
        "        voxelmesh.export(file_obj=export_path, file_type=\"obj\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.8 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_0.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_1.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_2.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_3.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_4.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_5.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_6.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_7.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_8.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_9.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_10.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_11.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_12.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_13.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_14.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_15.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_16.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_17.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_18.obj\n",
            "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/172mqt5l/sample_19.obj\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}