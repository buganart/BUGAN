{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_dataset_of_script_VAEGAN_voxelsize1_lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/custom_dataset_of_script_VAEGAN_voxelsize1_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form",
        "outputId": "69924a65-f349-4d8e-e6bb-3ceefcfe529a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form",
        "outputId": "69a86d02-b83a-4fb8-b97b-2646b12ecb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown Install wandb and log in\n",
        "!pip install wandb==0.9.7\n",
        "output.clear()\n",
        "import wandb\n",
        "!wandb login\n",
        "output.clear()\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH",
        "cellView": "both"
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown - set `None`if you want to start a new run\n",
        "#@markdown - set `\"run_id\"` if you want to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "id = None #@param {type:\"string\"}\n",
        "#@markdown Enter project name (either `handtool-gan` or `tree-gan`)\n",
        "project_name = \"tree-gan\" #@param [\"tree-gan\", \"handtool-gan\"]\n",
        "#@markdown Enter file location.  \n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.)\n",
        "#@markdown - zipfile example: `/content/drive/My Drive/h/k/a.zip`\n",
        "#@markdown - file folder example: `/content/drive/My Drive/h/k` \n",
        "file_location = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Chairs_Princeton/chair_train.zip\" #@param {type:\"string\"}\n",
        "#@markdown - choose rotation augmentation on-the-fly \n",
        "#@markdown (augmentation only support file folder in file_location)\n",
        "data_augmentation = True    #@param {type:\"boolean\"}\n",
        "#@markdown - specify the rotation axis (x,y,z)\n",
        "rotation_axis_x = 0    #@param {type:\"number\"}\n",
        "rotation_axis_y = 1    #@param {type:\"number\"}\n",
        "rotation_axis_z = 0    #@param {type:\"number\"}\n",
        "\n",
        "#@markdown - resolution of the voxelized array (shape resolution**3)\n",
        "resolution = \"64\"    #@param [32, 64]\n",
        "\n",
        "#@markdown WANDB log\n",
        "#@markdown - how many epochs before logging images/3D objects\n",
        "log_interval = 5    #@param {type:\"integer\"}\n",
        "#@markdown - how many samples per log\n",
        "log_num_samples = 3    #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "print(\"id:\", id)\n",
        "print(\"project_name:\", project_name)\n",
        "print(\"file_location:\", file_location)\n",
        "print(\"data_augmentation:\", data_augmentation)\n",
        "print(\"resolution:\", resolution)\n",
        "print(\"log_interval:\", log_interval)\n",
        "print(\"log_num_samples:\", log_num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%cd /content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\n",
        "if project_name == \"tree-gan\":\n",
        "    %cd colab-treegan/\n",
        "else:\n",
        "    %cd colab-handtool/\n",
        "\n",
        "dataset_path = Path(file_location)\n",
        "run_path = \"./\"\n",
        "\n",
        "if file_location.endswith(\".zip\"):\n",
        "    dataset_name = dataset_path.stem\n",
        "else:\n",
        "    dataset_name = \"dataset_array_custom\"\n",
        "\n",
        "!apt-get update\n",
        "\n",
        "!pip install pytorch-lightning==0.9.0\n",
        "!pip install trimesh\n",
        "!apt install -y xvfb\n",
        "!pip install trimesh xvfbwrapper\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo"
      },
      "source": [
        "import io\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "import trimesh\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "from xvfbwrapper import Xvfb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0"
      },
      "source": [
        "resume = False\n",
        "if id is None:\n",
        "    id = wandb.util.generate_id()\n",
        "else:\n",
        "    resume = True\n",
        "\n",
        "run = wandb.init(project=project_name, id=id, entity=\"bugan\", resume=True, dir=run_path)\n",
        "print(\"run id: \" + str(wandb.run.id))\n",
        "print(\"run name: \" + str(wandb.run.name))\n",
        "wandb.watch_called = False\n",
        "wandb.run.save_code = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww3zbHkxAw8B"
      },
      "source": [
        "#keep track of hyperparams\n",
        "config = wandb.config\n",
        "\n",
        "config.batch_size = 8\n",
        "config.array_size = int(resolution)\n",
        "\n",
        "config.z_size = 128\n",
        "if config.array_size == 32:\n",
        "    config.gen_num_layer_unit = [1024, 512, 256, 128]\n",
        "    config.dis_num_layer_unit = [32, 64, 128, 128]\n",
        "else:\n",
        "    config.gen_num_layer_unit = [1024, 512, 256, 128, 128]\n",
        "    config.dis_num_layer_unit = [32, 64, 64, 128, 128]\n",
        "\n",
        "config.leakyReLU = False    #leakyReLU implementation still not in modelPL\n",
        "config.balance_voxel_in_space = False\n",
        "\n",
        "config.epochs = 3000\n",
        "config.vae_lr = 0.0025\n",
        "config.vae_encoder_layer = 1\n",
        "config.vae_decoder_layer = 2\n",
        "config.d_lr = 0.00005            \n",
        "config.d_layer = 1\n",
        "config.vae_recon_loss_factor = 1\n",
        "config.seed = 1234\n",
        "config.log_interval = log_interval\n",
        "config.log_num_samples = log_num_samples\n",
        "config.data_augmentation = data_augmentation\n",
        "config.aug_rotation_axis = (rotation_axis_x,rotation_axis_y,rotation_axis_z)\n",
        "\n",
        "config.vae_opt = \"Adam\"\n",
        "config.dis_opt = \"Adam\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR"
      },
      "source": [
        "### load our package\n",
        "\n",
        "#clone then install\n",
        "# !git clone https://github.com/buganart/BUGAN repo\n",
        "# !pip install -e ./repo/\n",
        "# import site\n",
        "# site.main()\n",
        "\n",
        "#directly install using pip\n",
        "!pip install -U git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "output.clear()\n",
        "\n",
        "from bugan.functionsPL import *\n",
        "from bugan.modelsPL import VAEGAN, VAE, Discriminator, Generator\n",
        "\n",
        "# from functionsPL import *\n",
        "# from modelsPL import VAEGAN, VAE, Discriminator, Generator\n",
        "\n",
        "run.tags.append(\"VAEGAN\")\n",
        "run.group = \"VAEGAN\"\n",
        "\n",
        "###     load dataset\n",
        "np.random.seed(config.seed)\n",
        "# dataModule = DataModule(config, run)\n",
        "# config.num_data = dataModule.size\n",
        "\n",
        "config.dataset = dataset_name\n",
        "if config.data_augmentation:\n",
        "    dataModule = DataModule_augmentation(config, run, dataset_path)\n",
        "else:\n",
        "    dataModule = DataModule_process(config, run, dataset_path)\n",
        "config.num_data = dataModule.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzV_Mzfd_MZ"
      },
      "source": [
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "#render setup\n",
        "vdisplay = Xvfb()\n",
        "vdisplay.start()\n",
        "\n",
        "#wandb logger setup\n",
        "wandb_logger = WandbLogger(experiment=run, log_model=True)\n",
        "\n",
        "checkpoint_path = os.path.join(wandb.run.dir, 'checkpoint.ckpt')\n",
        "\n",
        "if resume:\n",
        "    #get file from the wandb cloud\n",
        "    load_checkpoint_from_cloud(checkpoint_path = 'checkpoint.ckpt')\n",
        "    #restore training state completely\n",
        "    trainer = pl.Trainer(max_epochs = config.epochs, logger=wandb_logger, checkpoint_callback = None, resume_from_checkpoint = checkpoint_path)\n",
        "else:\n",
        "    trainer = pl.Trainer(max_epochs = config.epochs, logger=wandb_logger, checkpoint_callback = None)\n",
        "\n",
        "#model\n",
        "vaegan = VAEGAN(config, trainer, save_model_path = checkpoint_path).to(device)\n",
        "wandb_logger.watch(vaegan)\n",
        "\n",
        "trainer.fit(vaegan, dataModule)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}