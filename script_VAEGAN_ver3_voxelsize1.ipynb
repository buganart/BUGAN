{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script_VAEGAN_ver3_voxelsize1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/script_VAEGAN_ver3_voxelsize1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4aa4fb58-0e16-4894-f291-30ce534fb71f"
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "453ec810-ffbc-4354-e12c-109b3b16c9de"
      },
      "source": [
        "#right click shared folder IRCMS_GAN_collaborative_database and \"Add shortcut to Drive\" to My drive\n",
        "%cd drive/My Drive/IRCMS_GAN_collaborative_database/\n",
        "\n",
        "#record paths to resources\n",
        "data_path = \"Research/Peter/Tree_3D_models_obj/obj_files/\"\n",
        "run_path = \"Experiments/colab-treegan/\"\n",
        "\n",
        "# !ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ylB2p6N0qQ-G4OsBuwcZ9C0tsqVu9ww4/IRCMS_GAN_collaborative_database\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LzAiBuWu6pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install trimesh\n",
        "!pip install wandb -q\n",
        "output.clear()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import os\n",
        "import trimesh\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stz1HHpxpwfK",
        "colab_type": "text"
      },
      "source": [
        "#wandb log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_fQzoLaVP2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login\n",
        "output.clear()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b95cfba6-0485-429b-9ae1-bb112ff91ea1"
      },
      "source": [
        "#id None to start a new run. For resuming run, put the id of the run below\n",
        "id = \"2zo0s38j\"\n",
        "resume = False\n",
        "if id is None:\n",
        "    id = wandb.util.generate_id()\n",
        "else:\n",
        "    resume = True\n",
        "\n",
        "run = wandb.init(project=\"tree-gan\", id=id, resume=\"allow\", dir=run_path)\n",
        "print(\"run id:\" + str(wandb.run.id))\n",
        "wandb.run.name = str(wandb.run.id)\n",
        "wandb.watch_called = False\n",
        "wandb.run.save_code = True\n",
        "\n",
        "#tag should be added from the panel\n",
        "# wandb.run.tags = [\"dev\"]\n",
        "# wandb.run.notes = \"test run VAEGAN with BCELoss on VAE\"\n",
        "wandb.run.group = \"VAEGAN\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/bugan/tree-gan\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/bugan/tree-gan/runs/2zo0s38j\" target=\"_blank\">https://app.wandb.ai/bugan/tree-gan/runs/2zo0s38j</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "run id:2zo0s38j\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Streaming file created twice in same run: Experiments/colab-treegan/wandb/run-20200811_041620-2zo0s38j/wandb-history.jsonl\n",
            "Streaming file created twice in same run: Experiments/colab-treegan/wandb/run-20200811_041620-2zo0s38j/wandb-events.jsonl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww3zbHkxAw8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keep track of hyperparams\n",
        "config = wandb.config\n",
        "config.batch_size = 4\n",
        "config.test_batch_size = 1\n",
        "config.epochs = 1000\n",
        "config.vae_lr = 0.0001\n",
        "config.d_lr = 0.00003           \n",
        "config.seed = 1234\n",
        "config.log_interval = 20"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI",
        "colab_type": "text"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qoPjcAGrimt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mesh2arrayCentered(mesh, voxel_size = 1, array_length = 64):\n",
        "    #given array length 64, voxel size 2, then output array size is [128,128,128]\n",
        "    array_size = np.ceil(np.array([array_length, array_length, array_length]) / voxel_size).astype(int)\n",
        "    vox_array = np.zeros(array_size, dtype=bool)    #tanh: voxel representation [-1,1], sigmoid: [0,1]\n",
        "    #scale mesh extent to fit array_length\n",
        "    max_length = np.max(np.array(mesh.extents))\n",
        "    mesh = mesh.apply_transform(trimesh.transformations.scale_matrix((array_length-1)/max_length))  #now the extent is [array_length**3]\n",
        "    v = mesh.voxelized(voxel_size)  #max voxel array length = array_length / voxel_size\n",
        "\n",
        "    #find indices in the v.matrix to center it in vox_array\n",
        "    indices = ((array_size - v.matrix.shape)/2).astype(int)\n",
        "    vox_array[indices[0]:indices[0]+v.matrix.shape[0], indices[1]:indices[1]+v.matrix.shape[1], indices[2]:indices[2]+v.matrix.shape[2]] = v.matrix\n",
        "\n",
        "    return vox_array"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTTG-zCl8kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b584fe78-c0e1-4cba-9c52-50aad76a9c41"
      },
      "source": [
        "dataset_artifact = run.use_artifact(\"dataset-tree:full\", type='dataset')\n",
        "dir_dict = dataset_artifact.metadata['dir_dict']\n",
        "artifact_dir = dataset_artifact.download()\n",
        "print(dir_dict)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dataset-tree:full, 566.02MB. 216 files... Done. 33.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'old': ['old_1.obj', 'old_2.obj', 'old_3.obj'], 'raft': ['raft_1_1.obj', 'raft_1_2.obj', 'raft_1_4.obj', 'raft_1_3.obj', 'raft_1_5.obj', 'raft_1_6.obj', 'raft_1_7.obj', 'raft_1_8.obj', 'raft_1_9.obj', 'raft_1_10.obj'], 'group': ['group_1_1.obj', 'group_1_2.obj', 'group_1_3.obj', 'group_1_4.obj', 'group_1_5.obj', 'group_1_6.obj', 'group_1_7.obj', 'group_1_8.obj', 'group_1_9.obj', 'group_1_10.obj'], 'leaning': ['leaning_1_1.obj', 'leaning_1_2.obj', 'leaning_1_3.obj', 'leaning_1_4.obj', 'leaning_1_5.obj', 'leaning_1_6.obj', 'leaning_1_7.obj', 'leaning_1_8.obj', 'leaning_1_9.obj', 'leaning_1_10.obj', 'leaning_2_1.obj', 'leaning_2_2.obj', 'leaning_2_3.obj', 'leaning_2_4.obj', 'leaning_2_5.obj', 'leaning_2_6.obj', 'leaning_2_8.obj', 'leaning_2_10.obj', 'leaning_2_7.obj', 'leaning_2_9.obj'], 'windswept': ['windswept_1_1.obj', 'windswept_1_2.obj', 'windswept_1_3.obj', 'windswept_1_4.obj', 'windswept_1_5.obj', 'windswept_1_6.obj', 'windswept_1_7.obj', 'windswept_1_8.obj', 'windswept_1_9.obj', 'windswept_1_10.obj', 'windswept_2_1.obj', 'windswept_2_2.obj', 'windswept_2_3.obj', 'windswept_2_4.obj', 'windswept_2_5.obj', 'windswept_2_6.obj', 'windswept_2_7.obj', 'windswept_2_8.obj', 'windswept_2_9.obj', 'windswept_2_10.obj'], 'double_trunk': ['double_trunk_1_1.obj', 'double_trunk_1_2.obj', 'double_trunk_1_3.obj', 'double_trunk_1_4.obj', 'double_trunk_1_5.obj', 'double_trunk_1_6.obj', 'double_trunk_1_7.obj', 'double_trunk_1_8.obj', 'double_trunk_1_9.obj', 'double_trunk_1_10.obj', 'double_trunk_2_1.obj', 'double_trunk_2_2.obj', 'double_trunk_2_3.obj', 'double_trunk_2_4.obj', 'double_trunk_2_5.obj', 'double_trunk_2_6.obj', 'double_trunk_2_7.obj', 'double_trunk_2_8.obj', 'double_trunk_2_9.obj', 'double_trunk_2_10.obj'], 'semi_cascade': ['semi_cascade_1_1.obj', 'semi_cascade_1_2.obj', 'semi_cascade_1_3.obj', 'semi_cascade_1_4.obj', 'semi_cascade_1_5.obj', 'semi_cascade_1_6.obj', 'semi_cascade_1_7.obj', 'semi_cascade_1_8.obj', 'semi_cascade_1_9.obj', 'semi_cascade_1_10.obj', 'semi_cascade_2_1.obj', 'semi_cascade_2_2.obj', 'semi_cascade_2_3.obj', 'semi_cascade_2_4.obj', 'semi_cascade_2_5.obj', 'semi_cascade_2_6.obj', 'semi_cascade_2_7.obj', 'semi_cascade_2_8.obj', 'semi_cascade_2_9.obj', 'semi_cascade_2_10.obj'], 'zan_gentlemen': ['zan_gentlemen_1_1.obj', 'zan_gentlemen_1_3.obj', 'zan_gentlemen_1_2.obj', 'zan_gentlemen_1_4.obj', 'zan_gentlemen_1_5.obj', 'zan_gentlemen_1_6.obj', 'zan_gentlemen_1_7.obj', 'zan_gentlemen_1_8.obj', 'zan_gentlemen_1_9.obj', 'zan_gentlemen_1_10.obj', 'zan_gentlemen_2_1.obj', 'zan_gentlemen_2_2.obj', 'zan_gentlemen_2_3.obj', 'zan_gentlemen_2_4.obj', 'zan_gentlemen_2_5.obj', 'zan_gentlemen_2_6.obj', 'zan_gentlemen_2_7.obj', 'zan_gentlemen_2_8.obj', 'zan_gentlemen_2_9.obj', 'zan_gentlemen_2_10.obj', 'zan_gentlemen_3_1.obj', 'zan_gentlemen_3_2.obj', 'zan_gentlemen_3_3.obj', 'zan_gentlemen_3_4.obj', 'zan_gentlemen_3_5.obj', 'zan_gentlemen_3_6.obj', 'zan_gentlemen_3_7.obj', 'zan_gentlemen_3_8.obj', 'zan_gentlemen_3_9.obj', 'zan_gentlemen_3_10.obj', 'zan_gentlemen_4_1.obj', 'zan_gentlemen_4_2.obj', 'zan_gentlemen_4_3.obj', 'zan_gentlemen_4_4.obj', 'zan_gentlemen_4_5.obj', 'zan_gentlemen_4_6.obj', 'zan_gentlemen_4_7.obj', 'zan_gentlemen_4_8.obj', 'zan_gentlemen_4_9.obj', 'zan_gentlemen_4_10.obj', 'zan_gentlemen_5_1.obj', 'zan_gentlemen_5_2.obj', 'zan_gentlemen_5_3.obj', 'zan_gentlemen_5_4.obj', 'zan_gentlemen_5_5.obj', 'zan_gentlemen_5_6.obj', 'zan_gentlemen_5_8.obj', 'zan_gentlemen_5_9.obj', 'zan_gentlemen_5_10.obj', 'zan_gentlemen_5_7.obj'], 'formal_upright': ['formal_upright_1_1.obj', 'formal_upright_1_2.obj', 'formal_upright_1_3.obj', 'formal_upright_1_4.obj', 'formal_upright_1_5.obj', 'formal_upright_1_6.obj', 'formal_upright_1_7.obj', 'formal_upright_1_9.obj', 'formal_upright_1_10.obj', 'formal_upright_1_8.obj', 'formal_upright_2_1.obj', 'formal_upright_2_2.obj', 'formal_upright_2_3.obj', 'formal_upright_2_4.obj', 'formal_upright_2_5.obj', 'formal_upright_2_6.obj', 'formal_upright_2_7.obj', 'formal_upright_2_8.obj', 'formal_upright_2_10.obj', 'formal_upright_2_9.obj'], 'mustard_sapling': ['mustard_sapling_2_1.obj', 'mustard_sapling_2_2.obj', 'mustard_sapling_2_3.obj', 'mustard_sapling_2_4.obj', 'mustard_sapling_2_5.obj', 'mustard_sapling_2_6.obj', 'mustard_sapling_2_7.obj', 'mustard_sapling_2_8.obj', 'mustard_sapling_2_9.obj', 'mustard_sapling_2_10.obj'], 'informal_upright': ['informal_upright_1_1.obj', 'informal_upright_1_2.obj', 'informal_upright_1_3.obj', 'informal_upright_1_4.obj', 'informal_upright_1_5.obj', 'informal_upright_1_6.obj', 'informal_upright_1_7.obj', 'informal_upright_1_8.obj', 'informal_upright_1_9.obj', 'informal_upright_1_10.obj', 'informal_upright_2_1.obj', 'informal_upright_2_2.obj', 'informal_upright_2_3.obj', 'informal_upright_2_4.obj', 'informal_upright_2_5.obj', 'informal_upright_2_6.obj', 'informal_upright_2_7.obj', 'informal_upright_2_8.obj', 'informal_upright_2_9.obj', 'informal_upright_2_10.obj'], 'mustard_reaching': ['mustard_reaching_1_1.obj', 'mustard_reaching_1_2.obj', 'mustard_reaching_1_3.obj', 'mustard_reaching_1_4.obj', 'mustard_reaching_1_5.obj', 'mustard_reaching_1_6.obj', 'mustard_reaching_1_7.obj', 'mustard_reaching_1_8.obj', 'mustard_reaching_1_9.obj', 'mustard_reaching_1_10.obj'], 'pn_tall_straight': ['pn_tall_straight_1.obj'], 'maple_example2.obj': ['maple_example2.obj'], 'pn_tall_straight_old': ['pn_tall_straight_old_1.obj']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh1RWa6qoVUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = []\n",
        "\n",
        "for data_cat in dir_dict:\n",
        "    filename_list = dir_dict[data_cat]\n",
        "    for filename in filename_list:\n",
        "        filename = artifact_dir + \"/\" + data_cat + \"/\" + filename\n",
        "        m = trimesh.load(filename, force='mesh')\n",
        "        array = mesh2arrayCentered(m)\n",
        "        dataset.append(array)\n",
        "dataset = np.array(dataset)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11222331-ef87-4739-93cc-754f066da4af"
      },
      "source": [
        "dataset = torch.tensor(dataset)\n",
        "print(torch.unsqueeze(dataset, -1).shape)\n",
        "tensor_dataset = TensorDataset(torch.unsqueeze(dataset, 1))\n",
        "\n",
        "#TODO: augment data\n",
        "\n",
        "dataloader = DataLoader(tensor_dataset, batch_size=config.batch_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([216, 64, 64, 64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIaapsqSK5h2",
        "colab_type": "text"
      },
      "source": [
        "#model description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodI2E4ANdYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input: 128-d noise vector\n",
        "#output: (64,64,64) array with values in [0,1]\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_channel=128):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.fc_channel = 8 #16\n",
        "        self.fc_size = 4\n",
        "\n",
        "        num_unit1 = self.fc_channel   \n",
        "        num_unit2 = 32   #32\n",
        "        num_unit3 = 32   #64\n",
        "        num_unit4 = 64   #128\n",
        "        num_unit5 = 128   #256\n",
        "        num_unit6 = 128   #512\n",
        "        self.gen_fc = nn.Linear(self.input_channel, num_unit1 * self.fc_size * self.fc_size * self.fc_size)\n",
        "        self.gen = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit1, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit2, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit6, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit6),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit6, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
        "\n",
        "            nn.ConvTranspose3d(num_unit5, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit4, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit3, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit2, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose3d(num_unit1, 1, 3, 1, padding = 1),\n",
        "            nn.Sigmoid()                #tanh: voxel representation [-1,1], sigmoid: [0,1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.gen_fc(x)\n",
        "        x = x.view(x.shape[0], self.fc_channel, self.fc_size, self.fc_size, self.fc_size)\n",
        "        x = self.gen(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, output_channel=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.output_channel = output_channel\n",
        "\n",
        "        num_unit1 = 8   #16\n",
        "        num_unit2 = 16   #32\n",
        "        num_unit3 = 32   #64\n",
        "        num_unit4 = 32  #128\n",
        "        num_unit5 = 64   #256\n",
        "        num_unit6 = 64   #512\n",
        "        \n",
        "        self.dis = nn.Sequential(\n",
        "            nn.Conv3d(1, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit2, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit3, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit3, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit4, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit5, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit5, num_unit4, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(num_unit4, num_unit3, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit3),\n",
        "            nn.ReLU(True),            \n",
        "            nn.Conv3d(num_unit3, num_unit2, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.MaxPool3d((2, 2, 2)),\n",
        "\n",
        "\n",
        "            nn.Conv3d(num_unit2, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv3d(num_unit1, num_unit1, 3, 1, padding = 1),\n",
        "            nn.BatchNorm3d(num_unit1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.dis_fc1 = nn.Sequential(\n",
        "            nn.Linear(num_unit1 * 4 * 4 * 4, 128),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.dis_fc2 = nn.Sequential(\n",
        "            nn.Linear(128, self.output_channel),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dis(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        fx = self.dis_fc1(x)\n",
        "        x = self.dis_fc2(fx)\n",
        "        return x, fx\n",
        "\n",
        "\n",
        "class VAEGAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAEGAN, self).__init__()\n",
        "        #VAE\n",
        "        self.vae_encoder = Discriminator()\n",
        "        self.encoder_mean = nn.Linear(128, 64)\n",
        "        self.encoder_logvar = nn.Linear(128, 64)\n",
        "        self.vae_decoder = Generator(input_channel=64)\n",
        "        #GAN\n",
        "        self.discriminator = Discriminator()\n",
        "\n",
        "    #reference: https://github.com/YixinChen-AI/CVAE-GAN-zoos-PyTorch-Beginner/blob/master/CVAE-GAN/CVAE-GAN.py\n",
        "    def noise_reparameterize(self,mean,logvar):\n",
        "        eps = torch.randn(mean.shape).to(device)\n",
        "        z = mean + eps * torch.exp(logvar)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\\\n",
        "        #VAE\n",
        "        _, f = self.vae_encoder(x)\n",
        "        x_mean = self.encoder_mean(f)\n",
        "        x_logvar = self.encoder_logvar(f)\n",
        "        x = self.noise_reparameterize(x_mean, x_logvar)\n",
        "        x = self.vae_decoder(x)\n",
        "        #classifier and discriminator\n",
        "        x = self.discriminator(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFZSVCCBIuPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d54edb76-d758-4a25-820e-6f6d7db947b4"
      },
      "source": [
        "V = VAEGAN().to(device)\n",
        "summary(V, (1, 64, 64, 64))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1        [-1, 8, 64, 64, 64]             224\n",
            "       BatchNorm3d-2        [-1, 8, 64, 64, 64]              16\n",
            "              ReLU-3        [-1, 8, 64, 64, 64]               0\n",
            "            Conv3d-4       [-1, 16, 64, 64, 64]           3,472\n",
            "       BatchNorm3d-5       [-1, 16, 64, 64, 64]              32\n",
            "              ReLU-6       [-1, 16, 64, 64, 64]               0\n",
            "            Conv3d-7       [-1, 32, 64, 64, 64]          13,856\n",
            "       BatchNorm3d-8       [-1, 32, 64, 64, 64]              64\n",
            "              ReLU-9       [-1, 32, 64, 64, 64]               0\n",
            "        MaxPool3d-10       [-1, 32, 32, 32, 32]               0\n",
            "           Conv3d-11       [-1, 32, 32, 32, 32]          27,680\n",
            "      BatchNorm3d-12       [-1, 32, 32, 32, 32]              64\n",
            "             ReLU-13       [-1, 32, 32, 32, 32]               0\n",
            "           Conv3d-14       [-1, 32, 32, 32, 32]          27,680\n",
            "      BatchNorm3d-15       [-1, 32, 32, 32, 32]              64\n",
            "             ReLU-16       [-1, 32, 32, 32, 32]               0\n",
            "        MaxPool3d-17       [-1, 32, 16, 16, 16]               0\n",
            "           Conv3d-18       [-1, 64, 16, 16, 16]          55,360\n",
            "      BatchNorm3d-19       [-1, 64, 16, 16, 16]             128\n",
            "             ReLU-20       [-1, 64, 16, 16, 16]               0\n",
            "           Conv3d-21       [-1, 64, 16, 16, 16]         110,656\n",
            "      BatchNorm3d-22       [-1, 64, 16, 16, 16]             128\n",
            "             ReLU-23       [-1, 64, 16, 16, 16]               0\n",
            "           Conv3d-24       [-1, 32, 16, 16, 16]          55,328\n",
            "      BatchNorm3d-25       [-1, 32, 16, 16, 16]              64\n",
            "             ReLU-26       [-1, 32, 16, 16, 16]               0\n",
            "        MaxPool3d-27          [-1, 32, 8, 8, 8]               0\n",
            "           Conv3d-28          [-1, 32, 8, 8, 8]          27,680\n",
            "      BatchNorm3d-29          [-1, 32, 8, 8, 8]              64\n",
            "             ReLU-30          [-1, 32, 8, 8, 8]               0\n",
            "           Conv3d-31          [-1, 16, 8, 8, 8]          13,840\n",
            "      BatchNorm3d-32          [-1, 16, 8, 8, 8]              32\n",
            "             ReLU-33          [-1, 16, 8, 8, 8]               0\n",
            "        MaxPool3d-34          [-1, 16, 4, 4, 4]               0\n",
            "           Conv3d-35           [-1, 8, 4, 4, 4]           3,464\n",
            "      BatchNorm3d-36           [-1, 8, 4, 4, 4]              16\n",
            "             ReLU-37           [-1, 8, 4, 4, 4]               0\n",
            "           Conv3d-38           [-1, 8, 4, 4, 4]           1,736\n",
            "      BatchNorm3d-39           [-1, 8, 4, 4, 4]              16\n",
            "             ReLU-40           [-1, 8, 4, 4, 4]               0\n",
            "           Linear-41                  [-1, 128]          65,664\n",
            "             ReLU-42                  [-1, 128]               0\n",
            "           Linear-43                    [-1, 1]             129\n",
            "          Sigmoid-44                    [-1, 1]               0\n",
            "    Discriminator-45       [[-1, 1], [-1, 128]]               0\n",
            "           Linear-46                   [-1, 64]           8,256\n",
            "           Linear-47                   [-1, 64]           8,256\n",
            "           Linear-48                  [-1, 512]          33,280\n",
            "  ConvTranspose3d-49          [-1, 32, 4, 4, 4]           6,944\n",
            "      BatchNorm3d-50          [-1, 32, 4, 4, 4]              64\n",
            "             ReLU-51          [-1, 32, 4, 4, 4]               0\n",
            "  ConvTranspose3d-52          [-1, 32, 4, 4, 4]          27,680\n",
            "      BatchNorm3d-53          [-1, 32, 4, 4, 4]              64\n",
            "             ReLU-54          [-1, 32, 4, 4, 4]               0\n",
            "  ConvTranspose3d-55          [-1, 32, 4, 4, 4]          27,680\n",
            "      BatchNorm3d-56          [-1, 32, 4, 4, 4]              64\n",
            "             ReLU-57          [-1, 32, 4, 4, 4]               0\n",
            "  ConvTranspose3d-58          [-1, 32, 4, 4, 4]          27,680\n",
            "      BatchNorm3d-59          [-1, 32, 4, 4, 4]              64\n",
            "             ReLU-60          [-1, 32, 4, 4, 4]               0\n",
            "         Upsample-61          [-1, 32, 8, 8, 8]               0\n",
            "  ConvTranspose3d-62          [-1, 64, 8, 8, 8]          55,360\n",
            "      BatchNorm3d-63          [-1, 64, 8, 8, 8]             128\n",
            "             ReLU-64          [-1, 64, 8, 8, 8]               0\n",
            "  ConvTranspose3d-65          [-1, 64, 8, 8, 8]         110,656\n",
            "      BatchNorm3d-66          [-1, 64, 8, 8, 8]             128\n",
            "             ReLU-67          [-1, 64, 8, 8, 8]               0\n",
            "  ConvTranspose3d-68          [-1, 64, 8, 8, 8]         110,656\n",
            "      BatchNorm3d-69          [-1, 64, 8, 8, 8]             128\n",
            "             ReLU-70          [-1, 64, 8, 8, 8]               0\n",
            "  ConvTranspose3d-71          [-1, 64, 8, 8, 8]         110,656\n",
            "      BatchNorm3d-72          [-1, 64, 8, 8, 8]             128\n",
            "             ReLU-73          [-1, 64, 8, 8, 8]               0\n",
            "         Upsample-74       [-1, 64, 16, 16, 16]               0\n",
            "  ConvTranspose3d-75      [-1, 128, 16, 16, 16]         221,312\n",
            "      BatchNorm3d-76      [-1, 128, 16, 16, 16]             256\n",
            "             ReLU-77      [-1, 128, 16, 16, 16]               0\n",
            "  ConvTranspose3d-78      [-1, 128, 16, 16, 16]         442,496\n",
            "      BatchNorm3d-79      [-1, 128, 16, 16, 16]             256\n",
            "             ReLU-80      [-1, 128, 16, 16, 16]               0\n",
            "  ConvTranspose3d-81      [-1, 128, 16, 16, 16]         442,496\n",
            "      BatchNorm3d-82      [-1, 128, 16, 16, 16]             256\n",
            "             ReLU-83      [-1, 128, 16, 16, 16]               0\n",
            "  ConvTranspose3d-84      [-1, 128, 16, 16, 16]         442,496\n",
            "      BatchNorm3d-85      [-1, 128, 16, 16, 16]             256\n",
            "             ReLU-86      [-1, 128, 16, 16, 16]               0\n",
            "         Upsample-87      [-1, 128, 32, 32, 32]               0\n",
            "  ConvTranspose3d-88      [-1, 128, 32, 32, 32]         442,496\n",
            "      BatchNorm3d-89      [-1, 128, 32, 32, 32]             256\n",
            "             ReLU-90      [-1, 128, 32, 32, 32]               0\n",
            "  ConvTranspose3d-91      [-1, 128, 32, 32, 32]         442,496\n",
            "      BatchNorm3d-92      [-1, 128, 32, 32, 32]             256\n",
            "             ReLU-93      [-1, 128, 32, 32, 32]               0\n",
            "  ConvTranspose3d-94      [-1, 128, 32, 32, 32]         442,496\n",
            "      BatchNorm3d-95      [-1, 128, 32, 32, 32]             256\n",
            "             ReLU-96      [-1, 128, 32, 32, 32]               0\n",
            "  ConvTranspose3d-97      [-1, 128, 32, 32, 32]         442,496\n",
            "      BatchNorm3d-98      [-1, 128, 32, 32, 32]             256\n",
            "             ReLU-99      [-1, 128, 32, 32, 32]               0\n",
            "        Upsample-100      [-1, 128, 64, 64, 64]               0\n",
            " ConvTranspose3d-101       [-1, 64, 64, 64, 64]         221,248\n",
            "     BatchNorm3d-102       [-1, 64, 64, 64, 64]             128\n",
            "            ReLU-103       [-1, 64, 64, 64, 64]               0\n",
            " ConvTranspose3d-104       [-1, 32, 64, 64, 64]          55,328\n",
            "     BatchNorm3d-105       [-1, 32, 64, 64, 64]              64\n",
            "            ReLU-106       [-1, 32, 64, 64, 64]               0\n",
            " ConvTranspose3d-107       [-1, 32, 64, 64, 64]          27,680\n",
            "     BatchNorm3d-108       [-1, 32, 64, 64, 64]              64\n",
            "            ReLU-109       [-1, 32, 64, 64, 64]               0\n",
            " ConvTranspose3d-110        [-1, 8, 64, 64, 64]           6,920\n",
            "     BatchNorm3d-111        [-1, 8, 64, 64, 64]              16\n",
            "            ReLU-112        [-1, 8, 64, 64, 64]               0\n",
            " ConvTranspose3d-113        [-1, 1, 64, 64, 64]             217\n",
            "         Sigmoid-114        [-1, 1, 64, 64, 64]               0\n",
            "       Generator-115        [-1, 1, 64, 64, 64]               0\n",
            "          Conv3d-116        [-1, 8, 64, 64, 64]             224\n",
            "     BatchNorm3d-117        [-1, 8, 64, 64, 64]              16\n",
            "            ReLU-118        [-1, 8, 64, 64, 64]               0\n",
            "          Conv3d-119       [-1, 16, 64, 64, 64]           3,472\n",
            "     BatchNorm3d-120       [-1, 16, 64, 64, 64]              32\n",
            "            ReLU-121       [-1, 16, 64, 64, 64]               0\n",
            "          Conv3d-122       [-1, 32, 64, 64, 64]          13,856\n",
            "     BatchNorm3d-123       [-1, 32, 64, 64, 64]              64\n",
            "            ReLU-124       [-1, 32, 64, 64, 64]               0\n",
            "       MaxPool3d-125       [-1, 32, 32, 32, 32]               0\n",
            "          Conv3d-126       [-1, 32, 32, 32, 32]          27,680\n",
            "     BatchNorm3d-127       [-1, 32, 32, 32, 32]              64\n",
            "            ReLU-128       [-1, 32, 32, 32, 32]               0\n",
            "          Conv3d-129       [-1, 32, 32, 32, 32]          27,680\n",
            "     BatchNorm3d-130       [-1, 32, 32, 32, 32]              64\n",
            "            ReLU-131       [-1, 32, 32, 32, 32]               0\n",
            "       MaxPool3d-132       [-1, 32, 16, 16, 16]               0\n",
            "          Conv3d-133       [-1, 64, 16, 16, 16]          55,360\n",
            "     BatchNorm3d-134       [-1, 64, 16, 16, 16]             128\n",
            "            ReLU-135       [-1, 64, 16, 16, 16]               0\n",
            "          Conv3d-136       [-1, 64, 16, 16, 16]         110,656\n",
            "     BatchNorm3d-137       [-1, 64, 16, 16, 16]             128\n",
            "            ReLU-138       [-1, 64, 16, 16, 16]               0\n",
            "          Conv3d-139       [-1, 32, 16, 16, 16]          55,328\n",
            "     BatchNorm3d-140       [-1, 32, 16, 16, 16]              64\n",
            "            ReLU-141       [-1, 32, 16, 16, 16]               0\n",
            "       MaxPool3d-142          [-1, 32, 8, 8, 8]               0\n",
            "          Conv3d-143          [-1, 32, 8, 8, 8]          27,680\n",
            "     BatchNorm3d-144          [-1, 32, 8, 8, 8]              64\n",
            "            ReLU-145          [-1, 32, 8, 8, 8]               0\n",
            "          Conv3d-146          [-1, 16, 8, 8, 8]          13,840\n",
            "     BatchNorm3d-147          [-1, 16, 8, 8, 8]              32\n",
            "            ReLU-148          [-1, 16, 8, 8, 8]               0\n",
            "       MaxPool3d-149          [-1, 16, 4, 4, 4]               0\n",
            "          Conv3d-150           [-1, 8, 4, 4, 4]           3,464\n",
            "     BatchNorm3d-151           [-1, 8, 4, 4, 4]              16\n",
            "            ReLU-152           [-1, 8, 4, 4, 4]               0\n",
            "          Conv3d-153           [-1, 8, 4, 4, 4]           1,736\n",
            "     BatchNorm3d-154           [-1, 8, 4, 4, 4]              16\n",
            "            ReLU-155           [-1, 8, 4, 4, 4]               0\n",
            "          Linear-156                  [-1, 128]          65,664\n",
            "            ReLU-157                  [-1, 128]               0\n",
            "          Linear-158                    [-1, 1]             129\n",
            "         Sigmoid-159                    [-1, 1]               0\n",
            "   Discriminator-160       [[-1, 1], [-1, 128]]               0\n",
            "================================================================\n",
            "Total params: 4,975,283\n",
            "Trainable params: 4,975,283\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.00\n",
            "Forward/backward pass size (MB): 2364.76\n",
            "Params size (MB): 18.98\n",
            "Estimated Total Size (MB): 2384.74\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrRSqnqK20W",
        "colab_type": "text"
      },
      "source": [
        "#functions for pytorch network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHZ9sGFVspXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def netarray2indices(array):\n",
        "    coord_list = []\n",
        "    if len(array.shape) == 5:\n",
        "        array = array[0][0]\n",
        "    x,y,z = array.shape\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            for k in range(z):\n",
        "                if array[i,j,k] > 0.5:        #tanh: voxel representation [-1,1], sigmoid: [0,1]\n",
        "                    coord_list.append([i,j,k])\n",
        "    print(len(coord_list))\n",
        "    if len(coord_list) == 0:\n",
        "        return np.array([[0,0,0]])  #return at least one point to prevent wandb 3dobject error\n",
        "    return np.array(coord_list)\n",
        "\n",
        "# array should be 3d\n",
        "def netarray2mesh(array):\n",
        "    if len(array.shape) != 3:\n",
        "        raise Exception(\"netarray2mesh: input array should be 3d\")\n",
        "\n",
        "    #convert to bool dtype\n",
        "    array = array > 0.5\n",
        "    #array all zero gives error\n",
        "    if np.sum(array) == 0:\n",
        "        array[0,0,0] = True\n",
        "    voxelmesh = trimesh.voxel.base.VoxelGrid(trimesh.voxel.encoding.DenseEncoding(array)).marching_cubes\n",
        "    voxelmeshfile = voxelmesh.export(file_type='obj')\n",
        "    voxelmeshfile = wandb.Object3D(io.StringIO(voxelmeshfile),file_type='obj')\n",
        "\n",
        "    return voxelmesh, voxelmeshfile\n",
        "\n",
        "def train_vaegan_model(VAEGAN, dataloader):\n",
        "    #\n",
        "    num_data = len(dataloader.dataset)\n",
        "    \n",
        "    torch.save(VAEGAN, os.path.join(wandb.run.dir, 'VAEGAN_model.pth'))\n",
        "    wandb.save(os.path.join(wandb.run.dir, 'VAEGAN_model.pth'))\n",
        "\n",
        "    #start training\n",
        "    VAEGAN.to(device)\n",
        "\n",
        "    vae_encoder = VAEGAN.vae_encoder.to(device)\n",
        "    encoder_mean = VAEGAN.encoder_mean.to(device)\n",
        "    encoder_logvar = VAEGAN.encoder_logvar.to(device)\n",
        "    vae_decoder = VAEGAN.vae_decoder.to(device)\n",
        "    discriminator = VAEGAN.discriminator.to(device)\n",
        "    components = [VAEGAN, vae_encoder, encoder_mean, encoder_logvar, vae_decoder, discriminator]\n",
        "\n",
        "    #optimizer   \n",
        "    vae_encoder_optimizer = optim.Adam(vae_encoder.parameters(), lr=config.vae_lr)\n",
        "    encoder_mean_optimizer = optim.Adam(encoder_mean.parameters(), lr=config.vae_lr)\n",
        "    encoder_logvar_optimizer = optim.Adam(encoder_logvar.parameters(), lr=config.vae_lr)\n",
        "    vae_decoder_optimizer = optim.Adam(vae_decoder.parameters(), lr=config.vae_lr)\n",
        "    discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=config.d_lr)\n",
        "\n",
        "\n",
        "    #log models\n",
        "    wandb.watch(VAEGAN, log=\"all\")\n",
        "\n",
        "    d_losses = []\n",
        "    vae_losses = []\n",
        "    for epoch in range(config.epochs):\n",
        "        for c in components:\n",
        "            c.train()\n",
        "\n",
        "        d_ep_loss = 0.\n",
        "        vae_ep_loss = 0.\n",
        "\n",
        "        for dataset_batch in dataloader:\n",
        "            dataset_batch = dataset_batch[0]    #dataset_batch was a list: [array], so just take the array inside\n",
        "            dataset_batch = dataset_batch.float().to(device)\n",
        "            #####TODO\n",
        "            dloss, vaeloss = compute_loss(components, dataset_batch)\n",
        "            \n",
        "            #optimize\n",
        "            \n",
        "            #optimize\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            vae_encoder_optimizer.zero_grad()\n",
        "            encoder_mean_optimizer.zero_grad()\n",
        "            encoder_logvar_optimizer.zero_grad()\n",
        "            vae_decoder_optimizer.zero_grad()\n",
        "\n",
        "            dloss.backward(retain_graph=True)\n",
        "            vaeloss.backward(retain_graph=True)\n",
        "            \n",
        "            discriminator_optimizer.step()\n",
        "            vae_encoder_optimizer.step()\n",
        "            encoder_mean_optimizer.step()\n",
        "            encoder_logvar_optimizer.step()\n",
        "            vae_decoder_optimizer.step()\n",
        "\n",
        "            \n",
        "          \n",
        "\n",
        "            #record loss\n",
        "            d_ep_loss += dloss.detach()  \n",
        "            vae_ep_loss += vaeloss.detach()\n",
        "\n",
        "        #after each epoch, average ep_loss, and thenrecord total loss and sample generated obj\n",
        "        d_ep_loss = d_ep_loss / num_data\n",
        "        vae_ep_loss = vae_ep_loss / num_data\n",
        "        d_losses.append(d_ep_loss)\n",
        "        vae_losses.append(vae_ep_loss)\n",
        "        print(\"discriminator, epoch\"+str(epoch)+\" : \"+str(d_ep_loss))\n",
        "        print(\"VAE, epoch\"+str(epoch)+\" : \"+str(vae_ep_loss))\n",
        "\n",
        "        #save model if necessary\n",
        "        if epoch % config.log_interval == 0:\n",
        "\n",
        "            sample_tree_array = generate_tree(vae_decoder)[0][0]  #only 1 tree\n",
        "            sample_tree_indices = netarray2indices(sample_tree_array)\n",
        "            _, voxelmeshfile = netarray2mesh(sample_tree_array)\n",
        "\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"VAE loss\": vae_ep_loss,\n",
        "            \"sample_tree_indices\": sample_tree_indices,\n",
        "            \"sample_tree_voxelmesh\": voxelmeshfile})\n",
        "\n",
        "            save_model(VAEGAN)\n",
        "\n",
        "\n",
        "        else:\n",
        "            wandb.log({\n",
        "            \"discriminator loss\": d_ep_loss,\n",
        "            \"VAE loss\": vae_ep_loss})\n",
        "    \n",
        "    #training end, save model again\n",
        "    sample_tree_array = generate_tree(vae_decoder)[0][0] #only 1 tree\n",
        "    sample_tree_indices = netarray2indices(sample_tree_array)\n",
        "    _, voxelmeshfile = netarray2mesh(sample_tree_array)\n",
        "\n",
        "    wandb.log({\n",
        "    \"discriminator loss\": d_ep_loss,\n",
        "    \"VAE loss\": vae_ep_loss,\n",
        "    \"sample_tree_indices\": sample_tree_indices,\n",
        "    \"sample_tree_voxelmesh\": voxelmeshfile})\n",
        "    save_model(VAEGAN)\n",
        "    \n",
        "    print(d_losses)\n",
        "    print(vae_losses)\n",
        "\n",
        "# this function calculate loss of the model, \n",
        "def compute_loss(components, dataset_batch):\n",
        "\n",
        "    VAEGAN, vae_encoder, encoder_mean, encoder_logvar, vae_decoder, discriminator = components\n",
        "    batch_size = dataset_batch.shape[0]\n",
        "\n",
        "    #loss function\n",
        "    criterion_label = nn.BCELoss(reduction='sum')\n",
        "    criterion_reconstruct = lambda input,target : nn.BCELoss(reduction='none')(input,target).mean() * batch_size    #mean per element in each data, sum over batch   \n",
        "        \n",
        "    #labels\n",
        "    real_label = torch.unsqueeze(torch.ones(batch_size),1).float().to(device) * 0.9     # one side label smoothing\n",
        "    fake_label = torch.unsqueeze(torch.zeros(batch_size),1).float().to(device)\n",
        "\n",
        "    ############\n",
        "    #   discriminator (and classifier if necessary)\n",
        "    ############\n",
        "    \n",
        "    #generate fake trees\n",
        "    latent_size = vae_decoder.input_channel\n",
        "    z = torch.randn(batch_size, latent_size).float().to(device) #noise vector\n",
        "    tree_fake = vae_decoder(z)\n",
        "\n",
        "    #fake data (data from generator) \n",
        "    dout_fake, _ = discriminator(tree_fake.clone().detach())   #detach so no update to generator\n",
        "    dloss_fake = criterion_label(dout_fake, fake_label)\n",
        "    #real data (data from dataloader)\n",
        "    dout_real, _ = discriminator(dataset_batch)\n",
        "    dloss_real = criterion_label(dout_real, real_label)\n",
        "\n",
        "    ############\n",
        "    #   VAE\n",
        "    ############\n",
        "    _, z = vae_encoder(dataset_batch)\n",
        "    z_mean = encoder_mean(z)\n",
        "    z_logvar = encoder_logvar(z)\n",
        "    z = VAEGAN.noise_reparameterize(z_mean, z_logvar)\n",
        "\n",
        "    reconstructed_data = vae_decoder(z)\n",
        "    #!!!check if we need more than MSELoss\n",
        "    vae_rec_loss = criterion_reconstruct(reconstructed_data, dataset_batch)    #loss is scaled to one\n",
        "\n",
        "    #output of the vae should fool discriminator\n",
        "    vae_out_d, _ = discriminator(reconstructed_data)\n",
        "    vae_d_loss = criterion_label(vae_out_d, real_label)\n",
        "\n",
        "    dloss = (dloss_fake + dloss_real) / 2   #scale the loss to one\n",
        "    vae_loss = (vae_rec_loss + vae_d_loss) / 2   #scale the loss to one\n",
        "    return dloss, vae_loss\n",
        "\n",
        "\n",
        "def save_model(model, model_path = os.path.join(wandb.run.dir, 'model_dict.pth')):\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    wandb.save(model_path)\n",
        "\n",
        "def load_model(model_path = 'model_dict.pth'):\n",
        "    model = VAEGAN()\n",
        "\n",
        "    model_file = wandb.restore(model_path)\n",
        "    model.load_state_dict(torch.load(model_file.name))\n",
        "\n",
        "    return model\n",
        "\n",
        "def generate_tree(vae_decoder, num_trees = 1):\n",
        "    \n",
        "    #generate noise vector\n",
        "    latent_size = vae_decoder.input_channel\n",
        "    z = torch.randn(num_trees, latent_size).to(device) \n",
        "    tree_fake = vae_decoder(z)\n",
        "\n",
        "    return tree_fake.detach().cpu().numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3",
        "colab_type": "text"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQWIWapYOsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0ef6f06-70b6-4953-d389-eeb3bd322356"
      },
      "source": [
        "# check if resume\n",
        "\n",
        "if resume:\n",
        "    vaegan = load_model()\n",
        "else:\n",
        "    vaegan = VAEGAN()\n",
        "\n",
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "train_vaegan_model(vaegan, dataloader)        #if dataloader has only 1 tree, the training time is 72s per epoch."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator, epoch0 : tensor(0.2106, device='cuda:0')\n",
            "VAE, epoch0 : tensor(0.2663, device='cuda:0')\n",
            "15\n",
            "discriminator, epoch1 : tensor(0.1645, device='cuda:0')\n",
            "VAE, epoch1 : tensor(0.1949, device='cuda:0')\n",
            "discriminator, epoch2 : tensor(0.1656, device='cuda:0')\n",
            "VAE, epoch2 : tensor(0.1943, device='cuda:0')\n",
            "discriminator, epoch3 : tensor(0.1639, device='cuda:0')\n",
            "VAE, epoch3 : tensor(0.1932, device='cuda:0')\n",
            "discriminator, epoch4 : tensor(0.1677, device='cuda:0')\n",
            "VAE, epoch4 : tensor(0.1957, device='cuda:0')\n",
            "discriminator, epoch5 : tensor(0.1713, device='cuda:0')\n",
            "VAE, epoch5 : tensor(0.1963, device='cuda:0')\n",
            "discriminator, epoch6 : tensor(0.1828, device='cuda:0')\n",
            "VAE, epoch6 : tensor(0.2038, device='cuda:0')\n",
            "discriminator, epoch7 : tensor(0.1662, device='cuda:0')\n",
            "VAE, epoch7 : tensor(0.1957, device='cuda:0')\n",
            "discriminator, epoch8 : tensor(0.2080, device='cuda:0')\n",
            "VAE, epoch8 : tensor(0.2100, device='cuda:0')\n",
            "discriminator, epoch9 : tensor(0.1767, device='cuda:0')\n",
            "VAE, epoch9 : tensor(0.1983, device='cuda:0')\n",
            "discriminator, epoch10 : tensor(0.1638, device='cuda:0')\n",
            "VAE, epoch10 : tensor(0.1957, device='cuda:0')\n",
            "discriminator, epoch11 : tensor(0.1635, device='cuda:0')\n",
            "VAE, epoch11 : tensor(0.1951, device='cuda:0')\n",
            "discriminator, epoch12 : tensor(0.1636, device='cuda:0')\n",
            "VAE, epoch12 : tensor(0.1948, device='cuda:0')\n",
            "discriminator, epoch13 : tensor(0.1635, device='cuda:0')\n",
            "VAE, epoch13 : tensor(0.1945, device='cuda:0')\n",
            "discriminator, epoch14 : tensor(0.1634, device='cuda:0')\n",
            "VAE, epoch14 : tensor(0.1941, device='cuda:0')\n",
            "discriminator, epoch15 : tensor(0.1636, device='cuda:0')\n",
            "VAE, epoch15 : tensor(0.1942, device='cuda:0')\n",
            "discriminator, epoch16 : tensor(0.1685, device='cuda:0')\n",
            "VAE, epoch16 : tensor(0.1966, device='cuda:0')\n",
            "discriminator, epoch17 : tensor(0.1640, device='cuda:0')\n",
            "VAE, epoch17 : tensor(0.1955, device='cuda:0')\n",
            "discriminator, epoch18 : tensor(0.1634, device='cuda:0')\n",
            "VAE, epoch18 : tensor(0.1947, device='cuda:0')\n",
            "discriminator, epoch19 : tensor(0.1634, device='cuda:0')\n",
            "VAE, epoch19 : tensor(0.1941, device='cuda:0')\n",
            "discriminator, epoch20 : tensor(0.1631, device='cuda:0')\n",
            "VAE, epoch20 : tensor(0.1936, device='cuda:0')\n",
            "43\n",
            "discriminator, epoch21 : tensor(0.1630, device='cuda:0')\n",
            "VAE, epoch21 : tensor(0.1931, device='cuda:0')\n",
            "discriminator, epoch22 : tensor(0.1630, device='cuda:0')\n",
            "VAE, epoch22 : tensor(0.1928, device='cuda:0')\n",
            "discriminator, epoch23 : tensor(0.1629, device='cuda:0')\n",
            "VAE, epoch23 : tensor(0.1923, device='cuda:0')\n",
            "discriminator, epoch24 : tensor(0.1654, device='cuda:0')\n",
            "VAE, epoch24 : tensor(0.1952, device='cuda:0')\n",
            "discriminator, epoch25 : tensor(0.1640, device='cuda:0')\n",
            "VAE, epoch25 : tensor(0.1968, device='cuda:0')\n",
            "discriminator, epoch26 : tensor(0.1633, device='cuda:0')\n",
            "VAE, epoch26 : tensor(0.1951, device='cuda:0')\n",
            "discriminator, epoch27 : tensor(0.1778, device='cuda:0')\n",
            "VAE, epoch27 : tensor(0.1990, device='cuda:0')\n",
            "discriminator, epoch28 : tensor(0.1977, device='cuda:0')\n",
            "VAE, epoch28 : tensor(0.2066, device='cuda:0')\n",
            "discriminator, epoch29 : tensor(0.1720, device='cuda:0')\n",
            "VAE, epoch29 : tensor(0.1991, device='cuda:0')\n",
            "discriminator, epoch30 : tensor(0.1671, device='cuda:0')\n",
            "VAE, epoch30 : tensor(0.1970, device='cuda:0')\n",
            "discriminator, epoch31 : tensor(0.1638, device='cuda:0')\n",
            "VAE, epoch31 : tensor(0.1951, device='cuda:0')\n",
            "discriminator, epoch32 : tensor(0.1675, device='cuda:0')\n",
            "VAE, epoch32 : tensor(0.1951, device='cuda:0')\n",
            "discriminator, epoch33 : tensor(0.1636, device='cuda:0')\n",
            "VAE, epoch33 : tensor(0.1944, device='cuda:0')\n",
            "discriminator, epoch34 : tensor(0.1635, device='cuda:0')\n",
            "VAE, epoch34 : tensor(0.1933, device='cuda:0')\n",
            "discriminator, epoch35 : tensor(0.1645, device='cuda:0')\n",
            "VAE, epoch35 : tensor(0.1930, device='cuda:0')\n",
            "discriminator, epoch36 : tensor(0.1634, device='cuda:0')\n",
            "VAE, epoch36 : tensor(0.1925, device='cuda:0')\n",
            "discriminator, epoch37 : tensor(0.1632, device='cuda:0')\n",
            "VAE, epoch37 : tensor(0.1918, device='cuda:0')\n",
            "discriminator, epoch38 : tensor(0.1630, device='cuda:0')\n",
            "VAE, epoch38 : tensor(0.1914, device='cuda:0')\n",
            "discriminator, epoch39 : tensor(0.1856, device='cuda:0')\n",
            "VAE, epoch39 : tensor(0.2473, device='cuda:0')\n",
            "discriminator, epoch40 : tensor(0.1690, device='cuda:0')\n",
            "VAE, epoch40 : tensor(0.2024, device='cuda:0')\n",
            "387\n",
            "discriminator, epoch41 : tensor(0.1681, device='cuda:0')\n",
            "VAE, epoch41 : tensor(0.1973, device='cuda:0')\n",
            "discriminator, epoch42 : tensor(0.1650, device='cuda:0')\n",
            "VAE, epoch42 : tensor(0.1956, device='cuda:0')\n",
            "discriminator, epoch43 : tensor(0.1662, device='cuda:0')\n",
            "VAE, epoch43 : tensor(0.1945, device='cuda:0')\n",
            "discriminator, epoch44 : tensor(0.1640, device='cuda:0')\n",
            "VAE, epoch44 : tensor(0.1935, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}