{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form"
      },
      "source": [
        "#@markdown Install wandb and log in\n",
        "%pip install wandb\n",
        "output.clear()\n",
        "import wandb\n",
        "wandb_drive_netrc_path = Path(\"drive/My Drive/colab/.netrc\")\n",
        "wandb_local_netrc_path = Path(\"/root/.netrc\")\n",
        "if wandb_drive_netrc_path.exists():\n",
        "    import shutil\n",
        "\n",
        "    print(\"Wandb .netrc file found, will use that to log in.\")\n",
        "    shutil.copy(wandb_drive_netrc_path, wandb_local_netrc_path)\n",
        "else:\n",
        "    print(\n",
        "        f\"Wandb config not found at {wandb_drive_netrc_path}.\\n\"\n",
        "        f\"Using manual login.\\n\\n\"\n",
        "        f\"To use auto login in the future, finish the manual login first and then run:\\n\\n\"\n",
        "        f\"\\t!mkdir -p '{wandb_drive_netrc_path.parent}'\\n\"\n",
        "        f\"\\t!cp {wandb_local_netrc_path} '{wandb_drive_netrc_path}'\\n\\n\"\n",
        "        f\"Then that file will be used to login next time.\\n\"\n",
        "    )\n",
        "\n",
        "!wandb login\n",
        "output.clear()\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH"
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown - Leave empty if you want to start a new run\n",
        "#@markdown - Set `\"run_id\"` if you want to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "resume_id = \"\" #@param {type:\"string\"}\n",
        "#@markdown Enter project name (either `handtool-gan` or `tree-gan`)\n",
        "project_name = \"tree-gan\" #@param [\"tree-gan\", \"handtool-gan\"]\n",
        "#@markdown Enter dataset location.  \n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.)\n",
        "#@markdown - zipfile example: `/content/drive/My Drive/h/k/a.zip`\n",
        "#@markdown - file folder example: `/content/drive/My Drive/h/k` \n",
        "data_location = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj_auto_generated/sessions/simplified/tree-session-2020-09-14_23-23-Friedrich_2-target-face-num-1000.zip\" #@param {type:\"string\"}\n",
        "#@markdown - choose rotation augmentation on-the-fly \n",
        "#@markdown (augmentation only support file folder in data_location)\n",
        "data_augmentation = True    #@param {type:\"boolean\"}\n",
        "aug_rotation_type = \"random rotation\"  #@param [\"random rotation\", \"axis rotation\"]\n",
        "#@markdown - specify the rotation axis [x,y,z] (only for aug_rotation_type = \"axis rotation\")\n",
        "rotation_axis_x = 0    #@param {type:\"number\"}\n",
        "rotation_axis_y = 1    #@param {type:\"number\"}\n",
        "rotation_axis_z = 0    #@param {type:\"number\"}\n",
        "\n",
        "#@markdown - resolution of the voxelized array (shape resolution**3)\n",
        "resolution = \"32\"    #@param [32, 64]\n",
        "\n",
        "#@markdown Model\n",
        "#@markdown - select which model to train\n",
        "selected_model = \"VAEGAN\"    #@param [\"VAEGAN\", \"GAN\", \"VAE\"]\n",
        "\n",
        "#@markdown WANDB log\n",
        "#@markdown - how many epochs before logging images/3D objects\n",
        "log_interval = 10    #@param {type:\"integer\"}\n",
        "#@markdown - how many samples per log\n",
        "log_num_samples = 1    #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#adjust parameter datatype\n",
        "resolution = int(resolution)\n",
        "\n",
        "colab_config = {\n",
        "    \"aug_rotation_type\": aug_rotation_type,\n",
        "    \"data_augmentation\": data_augmentation,\n",
        "    \"aug_rotation_axis\": (rotation_axis_x,rotation_axis_y,rotation_axis_z),\n",
        "    \"data_location\": data_location,\n",
        "    \"resume_id\": resume_id,\n",
        "    \"selected_model\": selected_model,\n",
        "    \"log_interval\": log_interval,\n",
        "    \"log_num_samples\": log_num_samples,\n",
        "    \"project_name\": project_name,\n",
        "    \"resolution\": resolution\n",
        "}\n",
        "\n",
        "for k, v in colab_config.items():\n",
        "    print(f\"=> {k:20}: {v}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%cd /content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\n",
        "if project_name == \"tree-gan\":\n",
        "    %cd colab-treegan/\n",
        "else:\n",
        "    %cd colab-handtool/\n",
        "\n",
        "dataset_path = Path(data_location)\n",
        "run_path = \"./\"\n",
        "\n",
        "!apt-get update\n",
        "\n",
        "%pip install pytorch-lightning\n",
        "%pip install trimesh\n",
        "!apt install -y xvfb\n",
        "%pip install trimesh xvfbwrapper\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo"
      },
      "source": [
        "import io\n",
        "from io import BytesIO\n",
        "import sys\n",
        "import zipfile\n",
        "import trimesh\n",
        "import numpy as np\n",
        "from argparse import Namespace, ArgumentParser\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "from xvfbwrapper import Xvfb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww3zbHkxAw8B"
      },
      "source": [
        "entity=\"bugan\"\n",
        "if not resume_id:\n",
        "    #keep track of hyperparams\n",
        "    config = Namespace(**colab_config)\n",
        "\n",
        "    config.seed = 1234\n",
        "    config.epochs = 3000\n",
        "    #datamodule config\n",
        "    config.batch_size = 32\n",
        "else:\n",
        "    #all config will be replaced by the stored one in wandb\n",
        "    api = wandb.Api()\n",
        "    previous_run = api.run(f\"{entity}/{project_name}/{resume_id}\")\n",
        "    config = Namespace(**previous_run.config)\n",
        "        #selected_model may be not in config\n",
        "    if hasattr(config,\"selected_model\"):\n",
        "        selected_model = config.selected_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0"
      },
      "source": [
        "\n",
        "if not resume_id:\n",
        "    run_id = wandb.util.generate_id()\n",
        "else:\n",
        "    run_id = resume_id\n",
        "\n",
        "run = wandb.init(project=project_name, id=run_id, entity=entity, resume=True, dir=run_path, group=selected_model)\n",
        "\n",
        "print(\"run id: \" + str(wandb.run.id))\n",
        "print(\"run name: \" + str(wandb.run.name))\n",
        "wandb.watch_called = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR"
      },
      "source": [
        "### load our package\n",
        "\n",
        "#directly install using pip\n",
        "if hasattr(config,\"rev_number\"):\n",
        "    %pip install --upgrade git+https://github.com/buganart/BUGAN.git@{rev_number}#egg=bugan\n",
        "else:\n",
        "    %pip install --upgrade git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "\n",
        "import bugan\n",
        "#EXTRACT package version\n",
        "    #switch stdout to temperary stringIO\n",
        "old_stdout = sys.stdout\n",
        "temp_stdout = io.StringIO()\n",
        "sys.stdout = temp_stdout\n",
        "    #get version\n",
        "%pip freeze | grep bugan\n",
        "version = temp_stdout.getvalue()\n",
        "rev_number = version.split(\"+g\")[1].rstrip()\n",
        "    #switch back stdout\n",
        "sys.stdout = old_stdout\n",
        "output.clear()\n",
        "\n",
        "print(\"bugan package version: \",version)\n",
        "print(\"bugan package revision number: \",rev_number)\n",
        "config.rev_number = rev_number\n",
        "\n",
        "\n",
        "from bugan.functionsPL import *\n",
        "from bugan.modelsPL import *\n",
        "\n",
        "\n",
        "run.tags.append(selected_model)\n",
        "\n",
        "###     load dataset\n",
        "np.random.seed(config.seed)\n",
        "\n",
        "dataset_path = Path(config.data_location)\n",
        "if config.data_location.endswith(\".zip\"):\n",
        "    config.dataset = dataset_path.stem\n",
        "else:\n",
        "    config.dataset = \"dataset_array_custom\"\n",
        "\n",
        "dataModule = DataModule_process(config, run, dataset_path)\n",
        "config.num_data = dataModule.size\n",
        "\n",
        "print(\"dataset name: \",config.dataset)\n",
        "print(\"dataset path: \",dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzV_Mzfd_MZ"
      },
      "source": [
        "#set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "#render setup\n",
        "vdisplay = Xvfb()\n",
        "vdisplay.start()\n",
        "\n",
        "#wandb logger setup\n",
        "wandb_logger = WandbLogger(experiment=run, log_model=True)\n",
        "#log config\n",
        "wandb.config.update(config)\n",
        "wandb.jupyter.Notebook(Namespace(save_code=True)).save_history()\n",
        "wandb.save(os.path.join(wandb.run.dir, \"code\", \"_session_history.ipynb\"), base_path=wandb.run.dir)\n",
        "\n",
        "checkpoint_path = str(Path(wandb.run.dir).absolute()/'checkpoint.ckpt')\n",
        "callbacks = [SaveWandbCallback(config.log_interval, checkpoint_path)]\n",
        "\n",
        "\n",
        "#model\n",
        "if selected_model == \"VAEGAN\":\n",
        "    MODEL_CLASS = VAEGAN\n",
        "elif selected_model == \"GAN\":\n",
        "    MODEL_CLASS = GAN\n",
        "else:\n",
        "    MODEL_CLASS = VAE_train\n",
        "\n",
        "if resume_id:\n",
        "    # Download file from the wandb cloud.\n",
        "    load_checkpoint_from_cloud(checkpoint_path = 'checkpoint.ckpt')\n",
        "    extra_trainer_args = {'resume_from_checkpoint': checkpoint_path}\n",
        "    model = MODEL_CLASS.load_from_checkpoint(checkpoint_path)\n",
        "else:\n",
        "    extra_trainer_args = {}\n",
        "    model = MODEL_CLASS(config)\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, max_epochs = config.epochs, logger=wandb_logger, callbacks=callbacks,\\\n",
        "                     default_root_dir=wandb.run.dir, checkpoint_callback = None, **extra_trainer_args)\n",
        "\n",
        "\n",
        "#train\n",
        "trainer.fit(model, dataModule)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}