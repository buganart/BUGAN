{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2 Train Custom Data",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pacnpacn/BUGAN/blob/master/StyleGAN2_Train_Custom_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc",
        "colab_type": "text"
      },
      "source": [
        "# StyleGAN2\n",
        "\n",
        "This notebook demonstrates how to run NVIDIA's StyleGAN2 on Google Colab.\n",
        "Make sure to specify a GPU runtime.\n",
        "\n",
        "This notebook mainly adds a few convenience functions for training and visualization. \n",
        "\n",
        "For information on StyleGAN2, see:\n",
        "\n",
        "Paper: https://arxiv.org/abs/1812.04948\n",
        "\n",
        "Video: https://youtu.be/kSLJriaOumA\n",
        "\n",
        "Code: https://github.com/NVlabs/stylegan\n",
        "\n",
        "FFHQ: https://github.com/NVlabs/ffhq-dataset\n",
        "\n",
        "/Parth Suresh, 2020 + Mikael Christensen, 2019\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzDuIoMcqfBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "89275586-b4e0-49d0-cfde-6297e679e3e1"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "%cd /content/\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "/content\n",
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93\u001b[K\n",
            "Unpacking objects: 100% (93/93), done.\n",
            "/content/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n",
            "Tensorflow version: 1.15.2\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-27c27eae-88f8-8890-2942-2800b9bf4d53)\n",
            "GPU Identified at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A9Hvw_b4PnJ",
        "colab_type": "text"
      },
      "source": [
        "We need to upload our data to this runtime. I found copying individual files from the drive is very slow, copying a zip file from my computer is also slow but copying a big zip file from drive is very fast, so let's do that.\n",
        "\n",
        "To find the folder the first time we need to **have a shortcut of our shared folder to the personal google drive**.\n",
        "\n",
        "Go to google drive → \"Shared with me\" → \"IRCMS_GAN_collaborative_database\" → Right click → \"Add shortcut to drive\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MBLJJm9meIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHWX_bVqmn8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "c85e8c4b-a6ca-45c5-e605-1b56cd13b68e"
      },
      "source": [
        "!rsync -avP /content/drive/My\\ Drive/IRCMS_GAN_collaborative_database/Research/Daniel/ALL\\ CROP.zip /content/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "ALL CROP.zip\n",
            "    214,122,378 100%   87.10MB/s    0:00:02 (xfr#1, to-chk=0/1)\n",
            "\n",
            "sent 214,174,739 bytes  received 35 bytes  47,594,394.22 bytes/sec\n",
            "total size is 214,122,378  speedup is 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umKaTRK4dlL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8a150de-9064-46d0-e8df-d13ab4a6c518"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf ALL\\ CROP\n",
        "!unzip -q ALL\\ CROP.zip\n",
        "!mv ALL\\ CROP train_set"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM6ouE_z-93V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a8365775-5822-4719-ca51-993bc42bf382"
      },
      "source": [
        "# This is to use the pre-trained model. We don't really need it right now.\n",
        "%cd /content\n",
        "!wget http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2020-07-15 10:23:34--  http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n",
            "Resolving d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)... 52.84.18.3, 52.84.18.99, 52.84.18.129, ...\n",
            "Connecting to d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)|52.84.18.3|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381673535 (364M) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘stylegan2-ffhq-config-f.pkl’\n",
            "\n",
            "stylegan2-ffhq-conf 100%[===================>] 363.99M   173MB/s    in 2.1s    \n",
            "\n",
            "2020-07-15 10:23:36 (173 MB/s) - ‘stylegan2-ffhq-config-f.pkl’ saved [381673535/381673535]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWMPNER11Z_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4ddf662d-242e-48b8-91cc-236fdcd46cc3"
      },
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/train_set/\"\n",
        "\n",
        "from fastai.vision import verify_images\n",
        "verify_images(path, delete=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBbkV2Fq_CUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a28e5b64-1428-4635-83cb-855fe723e2d8"
      },
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "%cd /content\n",
        "!mkdir -p /content/custom/\n",
        "path = \"/content/train_set/\"\n",
        "files = os.listdir(path)\n",
        "\n",
        "# Note: later code needs square images, maybe we should crop instead of pad\n",
        "\n",
        "def resize():\n",
        "    files = list(os.listdir(path))\n",
        "    for i, f in tqdm(list(enumerate(files))):\n",
        "      im = Image.open(path + f)\n",
        "      # imResize = im.thumbnail((256,256), Image.ANTIALIAS)\n",
        "      # imResize.save(\"/content/custom/\" + f , 'JPEG')\n",
        "      # im.thumbnail((256,256), Image.ANTIALIAS)\n",
        "      # im.save(\"/content/custom/\" + f , 'JPEG')\n",
        "\n",
        "      desired_size = 256\n",
        "      old_size = im.size \n",
        "      ratio = float(desired_size)/max(old_size)\n",
        "      new_size = tuple([int(x*ratio) for x in old_size])\n",
        "      im = im.resize(new_size, Image.ANTIALIAS)\n",
        "      # create a new image and paste the resized on it\n",
        "\n",
        "      imResize = Image.new(\"RGB\", (desired_size, desired_size), color=(255, 255, 255, 255))\n",
        "      imResize.paste(im, ((desired_size-new_size[0])//2, (desired_size-new_size[1])//2))\n",
        "      imResize.save(\"/content/custom/\" + f , 'JPEG')\n",
        "\n",
        "resize()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2862/2862 [00:20<00:00, 141.71it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bBs1Ixb6IBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "8edb7d43-ea1d-4b75-b745-f4ebd2c5f504"
      },
      "source": [
        "# Check a few images to make sure we didn't mess them up.\n",
        "\n",
        "from IPython.display import Image\n",
        "import glob\n",
        "for img in list(glob.glob(\"/content/custom/*\"))[:3]:\n",
        "    print(img)\n",
        "    display(Image(img))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/custom/guangzhou-china-jan-31-2016man-260nw-370016618.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/custom/bangkok-thailandjul30head-coach-dragan-talajic-260nw-209314246.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/custom/business-people-rush-hour-walking-260nw-246902116.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mQczlTg_DP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8441d521-21cc-480d-d4b2-73d60a386811"
      },
      "source": [
        "%cd /content/stylegan2/\n",
        "!python dataset_tool.py create_from_images /content/datasets/custom /content/custom/\n",
        "#!rm -r /content/custom/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan2\n",
            "Loading images from \"/content/custom/\"\n",
            "Creating dataset \"/content/datasets/custom\"\n",
            "Added 2862 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdnBhgrwblt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9df21306-cfb4-41e1-87b2-61aaa4d70663"
      },
      "source": [
        "%cd /content/stylegan2/training"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan2/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSVoMnq1jNE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2aa9ff7c-21c5-48c4-e12d-8680d745c667"
      },
      "source": [
        "%%writefile training_loop.py\n",
        "# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n",
        "#\n",
        "# This work is made available under the Nvidia Source Code License-NC.\n",
        "# To view a copy of this license, visit\n",
        "# https://nvlabs.github.io/stylegan2/license.html\n",
        "\n",
        "\"\"\"Main training script.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from dnnlib.tflib.autosummary import autosummary\n",
        "\n",
        "from training import dataset\n",
        "from training import misc\n",
        "from metrics import metric_base\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Just-in-time processing of training images before feeding them to the networks.\n",
        "\n",
        "def process_reals(x, labels, lod, mirror_augment, drange_data, drange_net):\n",
        "    with tf.name_scope('DynamicRange'):\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        x = misc.adjust_dynamic_range(x, drange_data, drange_net)\n",
        "    if mirror_augment:\n",
        "        with tf.name_scope('MirrorAugment'):\n",
        "            x = tf.where(tf.random_uniform([tf.shape(x)[0]]) < 0.5, x, tf.reverse(x, [3]))\n",
        "    with tf.name_scope('FadeLOD'): # Smooth crossfade between consecutive levels-of-detail.\n",
        "        s = tf.shape(x)\n",
        "        y = tf.reshape(x, [-1, s[1], s[2]//2, 2, s[3]//2, 2])\n",
        "        y = tf.reduce_mean(y, axis=[3, 5], keepdims=True)\n",
        "        y = tf.tile(y, [1, 1, 1, 2, 1, 2])\n",
        "        y = tf.reshape(y, [-1, s[1], s[2], s[3]])\n",
        "        x = tflib.lerp(x, y, lod - tf.floor(lod))\n",
        "    with tf.name_scope('UpscaleLOD'): # Upscale to match the expected input/output size of the networks.\n",
        "        s = tf.shape(x)\n",
        "        factor = tf.cast(2 ** tf.floor(lod), tf.int32)\n",
        "        x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "        x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "        x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x, labels\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Evaluate time-varying training parameters.\n",
        "\n",
        "def training_schedule(\n",
        "    cur_nimg,\n",
        "    training_set,\n",
        "    lod_initial_resolution  = None,     # Image resolution used at the beginning.\n",
        "    lod_training_kimg       = 600,      # Thousands of real images to show before doubling the resolution.\n",
        "    lod_transition_kimg     = 600,      # Thousands of real images to show when fading in new layers.\n",
        "    minibatch_size_base     = 16,       # Global minibatch size.\n",
        "    minibatch_size_dict     = {},       # Resolution-specific overrides.\n",
        "    minibatch_gpu_base      = 4,        # Number of samples processed at a time by one GPU.\n",
        "    minibatch_gpu_dict      = {},       # Resolution-specific overrides.\n",
        "    G_lrate_base            = 0.002,    # Learning rate for the generator.\n",
        "    G_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    D_lrate_base            = 0.002,    # Learning rate for the discriminator.\n",
        "    D_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    lrate_rampup_kimg       = 0,        # Duration of learning rate ramp-up.\n",
        "    tick_kimg_base          = 160,        # Default interval of progress snapshots.\n",
        "    tick_kimg_dict          = {8:28, 16:24, 32:20, 64:16, 128:12, 256:8, 512:6, 1024:4}): # Resolution-specific overrides.\n",
        "\n",
        "    # Initialize result dict.\n",
        "    s = dnnlib.EasyDict()\n",
        "    s.kimg = cur_nimg / 1000.0\n",
        "\n",
        "    # Training phase.\n",
        "    phase_dur = lod_training_kimg + lod_transition_kimg\n",
        "    phase_idx = int(np.floor(s.kimg / phase_dur)) if phase_dur > 0 else 0\n",
        "    phase_kimg = s.kimg - phase_idx * phase_dur\n",
        "\n",
        "    # Level-of-detail and resolution.\n",
        "    if lod_initial_resolution is None:\n",
        "        s.lod = 0.0\n",
        "    else:\n",
        "        s.lod = training_set.resolution_log2\n",
        "        s.lod -= np.floor(np.log2(lod_initial_resolution))\n",
        "        s.lod -= phase_idx\n",
        "        if lod_transition_kimg > 0:\n",
        "            s.lod -= max(phase_kimg - lod_training_kimg, 0.0) / lod_transition_kimg\n",
        "        s.lod = max(s.lod, 0.0)\n",
        "    s.resolution = 2 ** (training_set.resolution_log2 - int(np.floor(s.lod)))\n",
        "\n",
        "    # Minibatch size.\n",
        "    s.minibatch_size = minibatch_size_dict.get(s.resolution, minibatch_size_base)\n",
        "    s.minibatch_gpu = minibatch_gpu_dict.get(s.resolution, minibatch_gpu_base)\n",
        "\n",
        "    # Learning rate.\n",
        "    s.G_lrate = G_lrate_dict.get(s.resolution, G_lrate_base)\n",
        "    s.D_lrate = D_lrate_dict.get(s.resolution, D_lrate_base)\n",
        "    if lrate_rampup_kimg > 0:\n",
        "        rampup = min(s.kimg / lrate_rampup_kimg, 1.0)\n",
        "        s.G_lrate *= rampup\n",
        "        s.D_lrate *= rampup\n",
        "\n",
        "    # Other parameters.\n",
        "    s.tick_kimg = tick_kimg_dict.get(s.resolution, tick_kimg_base)\n",
        "    return s\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main training script.\n",
        "\n",
        "def training_loop(\n",
        "    G_args                  = {},       # Options for generator network.\n",
        "    D_args                  = {},       # Options for discriminator network.\n",
        "    G_opt_args              = {},       # Options for generator optimizer.\n",
        "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
        "    G_loss_args             = {},       # Options for generator loss.\n",
        "    D_loss_args             = {},       # Options for discriminator loss.\n",
        "    dataset_args            = {},       # Options for dataset.load_dataset().\n",
        "    sched_args              = {},       # Options for train.TrainingSchedule.\n",
        "    grid_args               = {},       # Options for train.setup_snapshot_image_grid().\n",
        "    metric_arg_list         = [],       # Options for MetricGroup.\n",
        "    tf_config               = {},       # Options for tflib.init_tf().\n",
        "    data_dir                = None,     # Directory to load datasets from.\n",
        "    G_smoothing_kimg        = 10.0,     # Half-life of the running average of generator weights.\n",
        "    minibatch_repeats       = 4,        # Number of minibatches to run before adjusting training parameters.\n",
        "    lazy_regularization     = True,     # Perform regularization as a separate training step?\n",
        "    G_reg_interval          = 4,        # How often the perform regularization for G? Ignored if lazy_regularization=False.\n",
        "    D_reg_interval          = 16,       # How often the perform regularization for D? Ignored if lazy_regularization=False.\n",
        "    reset_opt_for_new_lod   = True,     # Reset optimizer internal state (e.g. Adam moments) when new layers are introduced?\n",
        "    total_kimg              = 25000,    # Total length of the training, measured in thousands of real images.\n",
        "    mirror_augment          = False,    # Enable mirror augment?\n",
        "    drange_net              = [-1,1],   # Dynamic range used when feeding image data to the networks.\n",
        "    image_snapshot_ticks    = 1,       # How often to save image snapshots? None = only save 'reals.png' and 'fakes-init.png'.\n",
        "    network_snapshot_ticks  = 1,       # How often to save network snapshots? None = only save 'networks-final.pkl'.\n",
        "    save_tf_graph           = False,    # Include full TensorFlow computation graph in the tfevents file?\n",
        "    save_weight_histograms  = False,    # Include weight histograms in the tfevents file?\n",
        "    resume_pkl              = None,     # Network pickle to resume training from, None = train from scratch.\n",
        "    resume_kimg             = 15000,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
        "    resume_time             = 0.0,      # Assumed wallclock time at the beginning. Affects reporting.\n",
        "    resume_with_new_nets    = False):   # Construct new networks according to G_args and D_args before resuming training?\n",
        "\n",
        "    # Initialize dnnlib and TensorFlow.\n",
        "    tflib.init_tf(tf_config)\n",
        "    num_gpus = dnnlib.submit_config.num_gpus\n",
        "\n",
        "    # Load training set.\n",
        "    training_set = dataset.load_dataset(data_dir=dnnlib.convert_path(data_dir), verbose=True, **dataset_args)\n",
        "    grid_size, grid_reals, grid_labels = misc.setup_snapshot_image_grid(training_set, **grid_args)\n",
        "    misc.save_image_grid(grid_reals, dnnlib.make_run_dir_path('reals.png'), drange=training_set.dynamic_range, grid_size=grid_size)\n",
        "\n",
        "    # Construct or load networks.\n",
        "    with tf.device('/gpu:0'):\n",
        "        if resume_pkl is None or resume_with_new_nets:\n",
        "            print('Constructing networks...')\n",
        "            G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
        "            D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
        "            Gs = G.clone('Gs')\n",
        "        if resume_pkl is not None:\n",
        "            print('Loading networks from \"%s\"...' % resume_pkl)\n",
        "            rG, rD, rGs = misc.load_pkl(resume_pkl)\n",
        "            if resume_with_new_nets: G.copy_vars_from(rG); D.copy_vars_from(rD); Gs.copy_vars_from(rGs)\n",
        "            else: G = rG; D = rD; Gs = rGs\n",
        "\n",
        "    # Print layers and generate initial image snapshot.\n",
        "    G.print_layers(); D.print_layers()\n",
        "    sched = training_schedule(cur_nimg=total_kimg*1000, training_set=training_set, **sched_args)\n",
        "    grid_latents = np.random.randn(np.prod(grid_size), *G.input_shape[1:])\n",
        "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "    misc.save_image_grid(grid_fakes, dnnlib.make_run_dir_path('fakes_init.png'), drange=drange_net, grid_size=grid_size)\n",
        "\n",
        "    # Setup training inputs.\n",
        "    print('Building TensorFlow graph...')\n",
        "    with tf.name_scope('Inputs'), tf.device('/cpu:0'):\n",
        "        lod_in               = tf.placeholder(tf.float32, name='lod_in', shape=[])\n",
        "        lrate_in             = tf.placeholder(tf.float32, name='lrate_in', shape=[])\n",
        "        minibatch_size_in    = tf.placeholder(tf.int32, name='minibatch_size_in', shape=[])\n",
        "        minibatch_gpu_in     = tf.placeholder(tf.int32, name='minibatch_gpu_in', shape=[])\n",
        "        minibatch_multiplier = minibatch_size_in // (minibatch_gpu_in * num_gpus)\n",
        "        Gs_beta              = 0.5 ** tf.div(tf.cast(minibatch_size_in, tf.float32), G_smoothing_kimg * 1000.0) if G_smoothing_kimg > 0.0 else 0.0\n",
        "\n",
        "    # Setup optimizers.\n",
        "    G_opt_args = dict(G_opt_args)\n",
        "    D_opt_args = dict(D_opt_args)\n",
        "    for args, reg_interval in [(G_opt_args, G_reg_interval), (D_opt_args, D_reg_interval)]:\n",
        "        args['minibatch_multiplier'] = minibatch_multiplier\n",
        "        args['learning_rate'] = lrate_in\n",
        "        if lazy_regularization:\n",
        "            mb_ratio = reg_interval / (reg_interval + 1)\n",
        "            args['learning_rate'] *= mb_ratio\n",
        "            if 'beta1' in args: args['beta1'] **= mb_ratio\n",
        "            if 'beta2' in args: args['beta2'] **= mb_ratio\n",
        "    G_opt = tflib.Optimizer(name='TrainG', **G_opt_args)\n",
        "    D_opt = tflib.Optimizer(name='TrainD', **D_opt_args)\n",
        "    G_reg_opt = tflib.Optimizer(name='RegG', share=G_opt, **G_opt_args)\n",
        "    D_reg_opt = tflib.Optimizer(name='RegD', share=D_opt, **D_opt_args)\n",
        "\n",
        "    # Build training graph for each GPU.\n",
        "    data_fetch_ops = []\n",
        "    for gpu in range(num_gpus):\n",
        "        with tf.name_scope('GPU%d' % gpu), tf.device('/gpu:%d' % gpu):\n",
        "\n",
        "            # Create GPU-specific shadow copies of G and D.\n",
        "            G_gpu = G if gpu == 0 else G.clone(G.name + '_shadow')\n",
        "            D_gpu = D if gpu == 0 else D.clone(D.name + '_shadow')\n",
        "\n",
        "            # Fetch training data via temporary variables.\n",
        "            with tf.name_scope('DataFetch'):\n",
        "                sched = training_schedule(cur_nimg=int(resume_kimg*1000), training_set=training_set, **sched_args)\n",
        "                reals_var = tf.Variable(name='reals', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu] + training_set.shape))\n",
        "                labels_var = tf.Variable(name='labels', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu, training_set.label_size]))\n",
        "                reals_write, labels_write = training_set.get_minibatch_tf()\n",
        "                reals_write, labels_write = process_reals(reals_write, labels_write, lod_in, mirror_augment, training_set.dynamic_range, drange_net)\n",
        "                reals_write = tf.concat([reals_write, reals_var[minibatch_gpu_in:]], axis=0)\n",
        "                labels_write = tf.concat([labels_write, labels_var[minibatch_gpu_in:]], axis=0)\n",
        "                data_fetch_ops += [tf.assign(reals_var, reals_write)]\n",
        "                data_fetch_ops += [tf.assign(labels_var, labels_write)]\n",
        "                reals_read = reals_var[:minibatch_gpu_in]\n",
        "                labels_read = labels_var[:minibatch_gpu_in]\n",
        "\n",
        "            # Evaluate loss functions.\n",
        "            lod_assign_ops = []\n",
        "            if 'lod' in G_gpu.vars: lod_assign_ops += [tf.assign(G_gpu.vars['lod'], lod_in)]\n",
        "            if 'lod' in D_gpu.vars: lod_assign_ops += [tf.assign(D_gpu.vars['lod'], lod_in)]\n",
        "            with tf.control_dependencies(lod_assign_ops):\n",
        "                with tf.name_scope('G_loss'):\n",
        "                    G_loss, G_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, **G_loss_args)\n",
        "                with tf.name_scope('D_loss'):\n",
        "                    D_loss, D_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=D_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, reals=reals_read, labels=labels_read, **D_loss_args)\n",
        "\n",
        "            # Register gradients.\n",
        "            if not lazy_regularization:\n",
        "                if G_reg is not None: G_loss += G_reg\n",
        "                if D_reg is not None: D_loss += D_reg\n",
        "            else:\n",
        "                if G_reg is not None: G_reg_opt.register_gradients(tf.reduce_mean(G_reg * G_reg_interval), G_gpu.trainables)\n",
        "                if D_reg is not None: D_reg_opt.register_gradients(tf.reduce_mean(D_reg * D_reg_interval), D_gpu.trainables)\n",
        "            G_opt.register_gradients(tf.reduce_mean(G_loss), G_gpu.trainables)\n",
        "            D_opt.register_gradients(tf.reduce_mean(D_loss), D_gpu.trainables)\n",
        "\n",
        "    # Setup training ops.\n",
        "    data_fetch_op = tf.group(*data_fetch_ops)\n",
        "    G_train_op = G_opt.apply_updates()\n",
        "    D_train_op = D_opt.apply_updates()\n",
        "    G_reg_op = G_reg_opt.apply_updates(allow_no_op=True)\n",
        "    D_reg_op = D_reg_opt.apply_updates(allow_no_op=True)\n",
        "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta)\n",
        "\n",
        "    # Finalize graph.\n",
        "    with tf.device('/gpu:0'):\n",
        "        try:\n",
        "            peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
        "        except tf.errors.NotFoundError:\n",
        "            peak_gpu_mem_op = tf.constant(0)\n",
        "    tflib.init_uninitialized_vars()\n",
        "\n",
        "    print('Initializing logs...')\n",
        "    summary_log = tf.summary.FileWriter(dnnlib.make_run_dir_path())\n",
        "    if save_tf_graph:\n",
        "        summary_log.add_graph(tf.get_default_graph())\n",
        "    if save_weight_histograms:\n",
        "        G.setup_weight_histograms(); D.setup_weight_histograms()\n",
        "    metrics = metric_base.MetricGroup(metric_arg_list)\n",
        "\n",
        "    print('Training for %d kimg...\\n' % total_kimg)\n",
        "    dnnlib.RunContext.get().update('', cur_epoch=resume_kimg, max_epoch=total_kimg)\n",
        "    maintenance_time = dnnlib.RunContext.get().get_last_update_interval()\n",
        "    cur_nimg = int(resume_kimg * 1000)\n",
        "    cur_tick = -1\n",
        "    tick_start_nimg = cur_nimg\n",
        "    prev_lod = -1.0\n",
        "    running_mb_counter = 0\n",
        "    while cur_nimg < total_kimg * 1000:\n",
        "        if dnnlib.RunContext.get().should_stop(): break\n",
        "\n",
        "        # Choose training parameters and configure training ops.\n",
        "        sched = training_schedule(cur_nimg=cur_nimg, training_set=training_set, **sched_args)\n",
        "        assert sched.minibatch_size % (sched.minibatch_gpu * num_gpus) == 0\n",
        "        training_set.configure(sched.minibatch_gpu, sched.lod)\n",
        "        if reset_opt_for_new_lod:\n",
        "            if np.floor(sched.lod) != np.floor(prev_lod) or np.ceil(sched.lod) != np.ceil(prev_lod):\n",
        "                G_opt.reset_optimizer_state(); D_opt.reset_optimizer_state()\n",
        "        prev_lod = sched.lod\n",
        "\n",
        "        # Run training ops.\n",
        "        feed_dict = {lod_in: sched.lod, lrate_in: sched.G_lrate, minibatch_size_in: sched.minibatch_size, minibatch_gpu_in: sched.minibatch_gpu}\n",
        "        for _repeat in range(minibatch_repeats):\n",
        "            rounds = range(0, sched.minibatch_size, sched.minibatch_gpu * num_gpus)\n",
        "            run_G_reg = (lazy_regularization and running_mb_counter % G_reg_interval == 0)\n",
        "            run_D_reg = (lazy_regularization and running_mb_counter % D_reg_interval == 0)\n",
        "            cur_nimg += sched.minibatch_size\n",
        "            running_mb_counter += 1\n",
        "\n",
        "            # Fast path without gradient accumulation.\n",
        "            if len(rounds) == 1:\n",
        "                tflib.run([G_train_op, data_fetch_op], feed_dict)\n",
        "                if run_G_reg:\n",
        "                    tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run([D_train_op, Gs_update_op], feed_dict)\n",
        "                if run_D_reg:\n",
        "                    tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "            # Slow path with gradient accumulation.\n",
        "            else:\n",
        "                for _round in rounds:\n",
        "                    tflib.run(G_train_op, feed_dict)\n",
        "                if run_G_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run(Gs_update_op, feed_dict)\n",
        "                for _round in rounds:\n",
        "                    tflib.run(data_fetch_op, feed_dict)\n",
        "                    tflib.run(D_train_op, feed_dict)\n",
        "                if run_D_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "        # Perform maintenance tasks once per tick.\n",
        "        done = (cur_nimg >= total_kimg * 1000)\n",
        "        if cur_tick < 0 or cur_nimg >= tick_start_nimg + sched.tick_kimg * 1000 or done:\n",
        "            cur_tick += 1\n",
        "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
        "            tick_start_nimg = cur_nimg\n",
        "            tick_time = dnnlib.RunContext.get().get_time_since_last_update()\n",
        "            total_time = dnnlib.RunContext.get().get_time_since_start() + resume_time\n",
        "\n",
        "            # Report progress.\n",
        "            print('tick %-5d kimg %-8.1f lod %-5.2f minibatch %-4d time %-12s sec/tick %-7.1f sec/kimg %-7.2f maintenance %-6.1f gpumem %.1f' % (\n",
        "                autosummary('Progress/tick', cur_tick),\n",
        "                autosummary('Progress/kimg', cur_nimg / 1000.0),\n",
        "                autosummary('Progress/lod', sched.lod),\n",
        "                autosummary('Progress/minibatch', sched.minibatch_size),\n",
        "                dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)),\n",
        "                autosummary('Timing/sec_per_tick', tick_time),\n",
        "                autosummary('Timing/sec_per_kimg', tick_time / tick_kimg),\n",
        "                autosummary('Timing/maintenance_sec', maintenance_time),\n",
        "                autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30)))\n",
        "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
        "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
        "\n",
        "            # Save snapshots.\n",
        "            if image_snapshot_ticks is not None and (cur_tick % image_snapshot_ticks == 0 or done):\n",
        "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "                misc.save_image_grid(grid_fakes, dnnlib.make_run_dir_path('fakes%06d.png' % (cur_nimg // 1000)), drange=drange_net, grid_size=grid_size)\n",
        "            if network_snapshot_ticks is not None and (cur_tick % network_snapshot_ticks == 0 or done):\n",
        "                pkl = dnnlib.make_run_dir_path('network-snapshot-%06d.pkl' % (cur_nimg // 1000))\n",
        "                misc.save_pkl((G, D, Gs), pkl)\n",
        "                metrics.run(pkl, run_dir=dnnlib.make_run_dir_path(), data_dir=dnnlib.convert_path(data_dir), num_gpus=num_gpus, tf_config=tf_config)\n",
        "\n",
        "            # Update summaries and RunContext.\n",
        "            metrics.update_autosummaries()\n",
        "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
        "            dnnlib.RunContext.get().update('%.2f' % sched.lod, cur_epoch=cur_nimg // 1000, max_epoch=total_kimg)\n",
        "            maintenance_time = dnnlib.RunContext.get().get_last_update_interval() - tick_time\n",
        "\n",
        "    # Save final snapshot.\n",
        "    misc.save_pkl((G, D, Gs), dnnlib.make_run_dir_path('network-final.pkl'))\n",
        "\n",
        "    # All done.\n",
        "    summary_log.close()\n",
        "    training_set.close()\n",
        "\n",
        "#----------------------------------------------------------------------------\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting training_loop.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8qcPk0sPMln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "560c612a-bbe5-4daf-92d0-73f2a4bec8cb"
      },
      "source": [
        "%cd /content/stylegan2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUES7ATGIWCI",
        "colab_type": "text"
      },
      "source": [
        "## Customize Training Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW6Qw8EDIT8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = 'custom'\n",
        "data_dir = '/content/datasets/'\n",
        "config_id = 'config-f'\n",
        "num_gpus = 1\n",
        "total_kimg = 100000\n",
        "mirror_augment = True\n",
        "metrics = []\n",
        "gamma = None\n",
        "result_dir = '/content/saves/'\n",
        "#resume_pkl = 'stylegan2-cat-config-f.pkl'\n",
        "resume_pkl = None   # don't load pretrained weights\n",
        "resume_kimg = 0     # start counting number of trained images at zero because we are training from scratch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZn4maEsAgyC",
        "colab_type": "text"
      },
      "source": [
        "The cell below actually trains the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pufC7hNgpA_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "d6bd5fc9-8a6a-45a3-fe27-3f0ccbb57429"
      },
      "source": [
        "# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n",
        "#\n",
        "# This work is made available under the Nvidia Source Code License-NC.\n",
        "# To view a copy of this license, visit\n",
        "# https://nvlabs.github.io/stylegan2/license.html\n",
        "\n",
        "import argparse\n",
        "import copy\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import dnnlib\n",
        "from dnnlib import EasyDict\n",
        "\n",
        "from metrics.metric_defaults import metric_defaults\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "_valid_configs = [\n",
        "    # Table 1\n",
        "    'config-a', # Baseline StyleGAN\n",
        "    'config-b', # + Weight demodulation\n",
        "    'config-c', # + Lazy regularization\n",
        "    'config-d', # + Path length regularization\n",
        "    'config-e', # + No growing, new G & D arch.\n",
        "    'config-f', # + Large networks (default)\n",
        "\n",
        "    # Table 2\n",
        "    'config-e-Gorig-Dorig',   'config-e-Gorig-Dresnet',   'config-e-Gorig-Dskip',\n",
        "    'config-e-Gresnet-Dorig', 'config-e-Gresnet-Dresnet', 'config-e-Gresnet-Dskip',\n",
        "    'config-e-Gskip-Dorig',   'config-e-Gskip-Dresnet',   'config-e-Gskip-Dskip',\n",
        "]\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "train     = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
        "G         = EasyDict(func_name='training.networks_stylegan2.G_main')       # Options for generator network.\n",
        "D         = EasyDict(func_name='training.networks_stylegan2.D_stylegan2')  # Options for discriminator network.\n",
        "G_opt     = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "D_opt     = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "G_loss    = EasyDict(func_name='training.loss.G_logistic_ns_pathreg')      # Options for generator loss.\n",
        "D_loss    = EasyDict(func_name='training.loss.D_logistic_r1')              # Options for discriminator loss.\n",
        "sched     = EasyDict()                                                     # Options for TrainingSchedule.\n",
        "grid      = EasyDict(size='8k', layout='random')                           # Options for setup_snapshot_image_grid().\n",
        "sc        = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
        "tf_config = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
        "\n",
        "train.data_dir = data_dir\n",
        "train.total_kimg = total_kimg\n",
        "train.mirror_augment = mirror_augment\n",
        "train.image_snapshot_ticks = train.network_snapshot_ticks = 1\n",
        "sched.G_lrate_base = sched.D_lrate_base = 0.002\n",
        "sched.minibatch_size_base = 32\n",
        "sched.minibatch_gpu_base = 4\n",
        "D_loss.gamma = 10\n",
        "metrics = [metric_defaults[x] for x in metrics]\n",
        "desc = 'stylegan2'\n",
        "\n",
        "desc += '-' + dataset\n",
        "dataset_args = EasyDict(tfrecord_dir=dataset)\n",
        "\n",
        "assert num_gpus in [1, 2, 4, 8]\n",
        "sc.num_gpus = num_gpus\n",
        "desc += '-%dgpu' % num_gpus\n",
        "\n",
        "assert config_id in _valid_configs\n",
        "desc += '-' + config_id\n",
        "\n",
        "# Configs A-E: Shrink networks to match original StyleGAN.\n",
        "if config_id != 'config-f':\n",
        "    G.fmap_base = D.fmap_base = 8 << 10\n",
        "\n",
        "# Config E: Set gamma to 100 and override G & D architecture.\n",
        "if config_id.startswith('config-e'):\n",
        "    D_loss.gamma = 100\n",
        "    if 'Gorig'   in config_id: G.architecture = 'orig'\n",
        "    if 'Gskip'   in config_id: G.architecture = 'skip' # (default)\n",
        "    if 'Gresnet' in config_id: G.architecture = 'resnet'\n",
        "    if 'Dorig'   in config_id: D.architecture = 'orig'\n",
        "    if 'Dskip'   in config_id: D.architecture = 'skip'\n",
        "    if 'Dresnet' in config_id: D.architecture = 'resnet' # (default)\n",
        "\n",
        "# Configs A-D: Enable progressive growing and switch to networks that support it.\n",
        "if config_id in ['config-a', 'config-b', 'config-c', 'config-d']:\n",
        "    sched.lod_initial_resolution = 8\n",
        "    sched.G_lrate_base = sched.D_lrate_base = 0.001\n",
        "    sched.G_lrate_dict = sched.D_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
        "    sched.minibatch_size_base = 32 # (default)\n",
        "    sched.minibatch_size_dict = {8: 256, 16: 128, 32: 64, 64: 32}\n",
        "    sched.minibatch_gpu_base = 4 # (default)\n",
        "    sched.minibatch_gpu_dict = {8: 32, 16: 16, 32: 8, 64: 4}\n",
        "    G.synthesis_func = 'G_synthesis_stylegan_revised'\n",
        "    D.func_name = 'training.networks_stylegan2.D_stylegan'\n",
        "\n",
        "# Configs A-C: Disable path length regularization.\n",
        "if config_id in ['config-a', 'config-b', 'config-c']:\n",
        "    G_loss = EasyDict(func_name='training.loss.G_logistic_ns')\n",
        "\n",
        "# Configs A-B: Disable lazy regularization.\n",
        "if config_id in ['config-a', 'config-b']:\n",
        "    train.lazy_regularization = False\n",
        "\n",
        "# Config A: Switch to original StyleGAN networks.\n",
        "if config_id == 'config-a':\n",
        "    G = EasyDict(func_name='training.networks_stylegan.G_style')\n",
        "    D = EasyDict(func_name='training.networks_stylegan.D_basic')\n",
        "\n",
        "if gamma is not None:\n",
        "    D_loss.gamma = gamma\n",
        "\n",
        "sc.submit_target = dnnlib.SubmitTarget.LOCAL\n",
        "sc.local.do_not_copy_source_files = True\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    kwargs = EasyDict(train)\n",
        "    kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
        "    kwargs.update(dataset_args=dataset_args, sched_args=sched, grid_args=grid, metric_arg_list=metrics, tf_config=tf_config, resume_pkl=resume_pkl, resume_kimg=resume_kimg)\n",
        "    kwargs.submit_config = copy.deepcopy(sc)\n",
        "    kwargs.submit_config.run_dir_root = result_dir\n",
        "    kwargs.submit_config.run_desc = desc\n",
        "    dnnlib.submit_run(**kwargs)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local submit - run_dir: /content/saves/00000-stylegan2-custom-1gpu-config-f\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "WARNING: Entity <function TFRecordDataset.parse_tfrecord_tf at 0x7f7134d1fb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Dataset shape = [3, 256, 256]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycVz1W0qPgrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the model of choice\n",
        "import argparse\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "\n",
        "import pretrained_networks\n",
        "\n",
        "# Choose between these pretrained models - I think 'f' is the best choice:\n",
        "\n",
        "# 1024×1024 faces\n",
        "# stylegan2-ffhq-config-a.pkl\n",
        "# stylegan2-ffhq-config-b.pkl\n",
        "# stylegan2-ffhq-config-c.pkl\n",
        "# stylegan2-ffhq-config-d.pkl\n",
        "# stylegan2-ffhq-config-e.pkl\n",
        "# stylegan2-ffhq-config-f.pkl\n",
        "\n",
        "# 512×384 cars\n",
        "# stylegan2-car-config-a.pkl\n",
        "# stylegan2-car-config-b.pkl\n",
        "# stylegan2-car-config-c.pkl\n",
        "# stylegan2-car-config-d.pkl\n",
        "# stylegan2-car-config-e.pkl\n",
        "# stylegan2-car-config-f.pkl\n",
        "\n",
        "# 256x256 horses\n",
        "# stylegan2-horse-config-a.pkl\n",
        "# stylegan2-horse-config-f.pkl\n",
        "\n",
        "# 256x256 churches\n",
        "# stylegan2-church-config-a.pkl\n",
        "# stylegan2-church-config-f.pkl\n",
        "\n",
        "# 256x256 cats\n",
        "# stylegan2-cat-config-f.pkl\n",
        "# stylegan2-cat-config-a.pkl\n",
        "#network_pkl = \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "network_pkl = \"/content/network-snapshot-015008.pkl\"\n",
        "\n",
        "# If downloads fails, due to 'Google Drive download quota exceeded' you can try downloading manually from your own Google Drive account\n",
        "# network_pkl = \"/content/drive/My Drive/GAN/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxbhe4uLvF_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful utility functions...\n",
        "\n",
        "# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_in_w_space(dlatents, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    Gs_kwargs.truncation_psi = truncation_psi\n",
        "    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "\n",
        "    imgs = []\n",
        "    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n",
        "        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n",
        "        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n",
        "        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n",
        "        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n",
        "    return imgs       \n",
        "\n",
        "def generate_images(zs, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    if not isinstance(truncation_psi, list):\n",
        "        truncation_psi = [truncation_psi] * len(zs)\n",
        "        \n",
        "    imgs = []\n",
        "    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n",
        "        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n",
        "        noise_rnd = np.random.RandomState(1) # fix noise\n",
        "        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n",
        "    return imgs\n",
        "\n",
        "def generate_zs_from_seeds(seeds):\n",
        "    zs = []\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n",
        "        zs.append(z)\n",
        "    return zs\n",
        "\n",
        "# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_from_seeds(seeds, truncation_psi):\n",
        "    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n",
        "\n",
        "def saveImgs(imgs, location):\n",
        "  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n",
        "    file = location+ str(idx) + \".png\"\n",
        "    img.save(file)\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  str_file = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  im_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "def showarray(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "\n",
        "        \n",
        "def clamp(x, minimum, maximum):\n",
        "    return max(minimum, min(x, maximum))\n",
        "    \n",
        "def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n",
        "  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n",
        "   \n",
        "  draw = ImageDraw.Draw(buffer)\n",
        "  cy = (y+y2)/2\n",
        "  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n",
        "  for i in range(len(latents)):\n",
        "    mx = x + (x2-x)*(float(i)/len(latents))\n",
        "    h = (y2-y)*latents[i]*0.1\n",
        "    h = clamp(h,cy-y2,y2-cy)\n",
        "    draw.line((mx,cy,mx,cy+h),fill=color)\n",
        "  return PIL.Image.alpha_composite(image,buffer)\n",
        "             \n",
        "  \n",
        "def createImageGrid(images, scale=0.25, rows=1):\n",
        "   w,h = images[0].size\n",
        "   w = int(w*scale)\n",
        "   h = int(h*scale)\n",
        "   height = rows*h\n",
        "   cols = ceil(len(images) / rows)\n",
        "   width = cols*w\n",
        "   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n",
        "   for i,img in enumerate(images):\n",
        "     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n",
        "     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n",
        "   return canvas\n",
        "\n",
        "def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n",
        "  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n",
        "  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "  for i in range(truncation_cutoff):\n",
        "    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n",
        "    \n",
        "  return dlatent\n",
        "\n",
        "def interpolate(zs, steps):\n",
        "   out = []\n",
        "   for i in range(len(zs)-1):\n",
        "    for index in range(steps):\n",
        "     fraction = index/float(steps) \n",
        "     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
        "   return out\n",
        "\n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VnyjDhiBQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQIhdSRcXC-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate some random seeds\n",
        "seeds = np.random.randint(10000000, size=9)\n",
        "print(seeds)\n",
        "\n",
        "# show the seeds\n",
        "imshow(createImageGrid(generate_images_from_seeds(seeds, 0.7), 0.7 , 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aZvophLZQOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple (Z) interpolation\n",
        "zs = generate_zs_from_seeds([5015289 , 9148088 ])\n",
        "\n",
        "latent1 = zs[0]\n",
        "latent2 = zs[1]\n",
        "\n",
        "number_of_steps = 9\n",
        "\n",
        "imgs = generate_images(interpolate([latent1,latent2],number_of_steps), 1.0)\n",
        "number_of_images = len(imgs)\n",
        "imshow(createImageGrid(imgs, 0.4 , 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwXUbkVJXckp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generating a MP4 movie\n",
        "\n",
        "zs = generate_zs_from_seeds([421645,6149575,3487643,3766864 ,3857159,5360657,3720613])\n",
        "\n",
        "number_of_steps = 10\n",
        "imgs = generate_images(interpolate(zs,number_of_steps), 1.0)\n",
        "\n",
        "# Example of reading a generated set of images, and storing as MP4.\n",
        "%mkdir out\n",
        "movieName = 'out/mov.mp4'\n",
        "\n",
        "with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
        "        writer.append_data(np.array(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po7eQSxav8qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In order to download files, you can use the snippet below - this often fails for me, though, so I prefer the 'Files' browser in the sidepanel.\n",
        "\n",
        "from google.colab import files\n",
        "files.download(movieName) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F252sUipCOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you want to store files to your Google drive, run this cell...\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "print( os.getcwd() )\n",
        "location = \"/content/gdrive/My Drive/PythonTests\"\n",
        "print( os.listdir(location) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GofpNwi5aLl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# more complex example, interpolating in W instead of Z space.\n",
        "zs = generate_zs_from_seeds([421645,6149575,3487643,3766864 ,3857159,5360657,3720613 ])\n",
        "\n",
        "# It seems my truncation_psi is slightly less efficient in W space - I probably introduced an error somewhere...\n",
        "\n",
        "dls = []\n",
        "for z in zs:\n",
        "  dls.append(convertZtoW(z ,truncation_psi=1.0))\n",
        "\n",
        "number_of_steps = 100\n",
        "\n",
        "imgs = generate_images_in_w_space(interpolate(dls,number_of_steps), 1.0)\n",
        "\n",
        "%mkdir out\n",
        "movieName = 'out/mov.mp4'\n",
        "\n",
        "with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
        "        writer.append_data(np.array(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYdsgv4i6YPl",
        "colab_type": "text"
      },
      "source": [
        "# Projecting images onto the generatable manifold\n",
        "\n",
        "StyleGAN2 comes with a projector that finds the closest generatable image based on any input image. This allows you to get a feeling for the diversity of the portrait manifold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urzy8lw76j_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir projection\n",
        "!mkdir projection/imgs\n",
        "!mkdir projection/out\n",
        "\n",
        "# Now upload a single image to 'stylegan2/projection/imgs' (use the Files side panel). Image should be color PNG, with a size of 1024x1024."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDLJBbpz6n4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert uploaded images to TFRecords\n",
        "import dataset_tool\n",
        "from sys import exit\n",
        "dataset_tool.create_from_images(\"./projection/records/\", \"./projection/imgs/\", True)\n",
        "\n",
        "# Run the projector\n",
        "import run_projector\n",
        "import projector\n",
        "import training.dataset\n",
        "import training.misc\n",
        "import os \n",
        "\n",
        "def project_real_images(dataset_name, data_dir, num_images, num_snapshots):\n",
        "    proj = projector.Projector()\n",
        "    proj.set_network(Gs)\n",
        "\n",
        "    print('Loading images from \"%s\"...' % dataset_name)\n",
        "    dataset_obj = training.dataset.load_dataset(data_dir=data_dir, tfrecord_dir=dataset_name, max_label_size=0, verbose=True, repeat=False, shuffle_mb=0)\n",
        "    assert dataset_obj.shape == Gs.output_shape[1:]\n",
        "\n",
        "    for image_idx in range(num_images):\n",
        "        print('Projecting image %d/%d ...' % (image_idx, num_images))\n",
        "        images, _labels = dataset_obj.get_minibatch_np(1)\n",
        "        images = training.misc.adjust_dynamic_range(images, [0, 255], [-1, 1])\n",
        "        run_projector.project_image(proj, targets=images, png_prefix=dnnlib.make_run_dir_path('projection/out/image%04d-' % image_idx), num_snapshots=num_snapshots)\n",
        "\n",
        "project_real_images(\"records\",\"./projection\",1,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmjPpjFU6yq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create video \n",
        "\n",
        "import glob\n",
        "\n",
        "imgs = sorted(glob.glob(\"projection/out/*step*.png\"))\n",
        "\n",
        "target_imgs = sorted(glob.glob(\"projection/out/*target*.png\"))\n",
        "assert len(target_imgs) == 1, \"More than one target found?\"\n",
        "target_img = imageio.imread(target_imgs[0])\n",
        "\n",
        "movieName = \"projection/movie.mp4\"\n",
        "with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for filename in log_progress(imgs, name = \"Creating animation\"):\n",
        "        image = imageio.imread(filename)\n",
        "\n",
        "        # Concatenate images with original target image\n",
        "        w,h = image.shape[0:2]\n",
        "        canvas = PIL.Image.new('RGBA', (w*2,h), 'white')\n",
        "        canvas.paste(Image.fromarray(target_img), (0, 0))\n",
        "        canvas.paste(Image.fromarray(image), (w, 0))\n",
        "\n",
        "        writer.append_data(np.array(canvas))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGVarLre63dL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now you can download the video (find it in the Files side panel under 'stylegan2/projection')\n",
        "\n",
        "# To cleanup\n",
        "!rm projection/out/*.*\n",
        "!rm projection/records/*.*\n",
        "!rm projection/imgs/*.*"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}