{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/notebook_util/generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "c21c7232-f3b6-4c1d-ca2b-23bbf24029ae"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "a55f6939-955a-454f-b870-e9257be8e74e"
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown - choose whether to use wandb id or use checkpoint_path to select checkpoint file\n",
        "\n",
        "#@markdown Choice 1: wandb id to select checkpoint file\n",
        "#@markdown - set `\"run_id\"` to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "id = \"2pohik1y\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Choice 2: file path and model type to select saved checkpoint .ckpt file\n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.\n",
        "#@markdown - file path example: `/content/drive/My Drive/h/k/checkpoint.ckpt` \n",
        "ckpt_file_location = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Enter trained neural network model type\n",
        "#@markdown - (may be necessary for wandb_id if selected_model is not saved in config)\n",
        "selected_model = \"VAEGAN\"    #@param [\"VAEGAN\", \"GAN\", \"VAE\", \"WGAN\", \"WGAN_GP\"]\n",
        "\n",
        "#@markdown In case the model is conditional, specify class index here.\n",
        "class_index =  1#@param {type:\"integer\"}\n",
        "#@markdown Enter how many samples to generate\n",
        "test_num_samples =     100#@param {type:\"integer\"}\n",
        "#@markdown OPTIONAL: boolean to choose whether to generate from list of history checkpoints or just the latest checkpoint.\n",
        "generateMeshHistory = False #@param {type:\"boolean\"}\n",
        "#@markdown OPTIONAL: If generateMeshHistory enabled, select \"num_selected_checkpoint\" checkpoints in the saved history checkpoint list.\n",
        "num_selected_checkpoint =  0 #@param {type:\"integer\"}\n",
        "#@markdown whether to zip file and download with browser\n",
        "browser_download = False #@param {type:\"boolean\"}\n",
        "#@markdown Enter export location for generated mesh (folder/directory).    \n",
        "export_location = f\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/{id}\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Post process generated mesh\n",
        "#@markdown whether to post process meshes\n",
        "post_process = True #@param {type:\"boolean\"}\n",
        "#@markdown remove clusters that has no points in the unit sphere of radius.\n",
        "#@markdown - casting sphere of radius in the center of the cube voxel space.\n",
        "#@markdown - keep cluster that has at least 1 point in the sphere, those has no points in the sphere will be discarded.\n",
        "#@markdown - For resolution=64, radius of the sphere that fit the cube voxel space is 32.\n",
        "radius=28 #@param {type:\"number\"}\n",
        "#@markdown remove clusters that has less than point_threshold points.\n",
        "point_threshold = 50 #@param {type:\"integer\"}\n",
        "#@markdown Enter export location for post-processed generated mesh (folder/directory).\n",
        "#@markdown - After the mesh is generated, they are in array format. Post-processing algorithms will be used to remove outliers / floating voxels.\n",
        "export_location_processed = f\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/{id}_postprocessed\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "if id and ckpt_file_location:\n",
        "    raise Exception(\"Only one of id / ckpt_file_location can be set!\")\n",
        "if (not id) and (not ckpt_file_location):\n",
        "    raise Exception(\"Please set id / ckpt_file_location!\")\n",
        "\n",
        "if id:\n",
        "    print(\"id:\", id)\n",
        "else:\n",
        "    print(\"selected_model:\", selected_model)\n",
        "    print(\"ckpt_file_location:\", ckpt_file_location)\n",
        "print(\"test_num_samples:\", test_num_samples)\n",
        "print(\"export_location:\", export_location)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id: 2pohik1y\n",
            "test_num_samples: 100\n",
            "export_location: /content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/2pohik1y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "a75da5f3-6ef4-47ce-ccfb-ed984997cff5"
      },
      "source": [
        "from argparse import Namespace, ArgumentParser\n",
        "#@markdown Install wandb and log in\n",
        "entity=\"bugan\"\n",
        "rev_number = None\n",
        "if id:\n",
        "    !pip install wandb\n",
        "    output.clear()\n",
        "    #find wandb API key file to auto login\n",
        "    import wandb\n",
        "    wandb_drive_netrc_path = Path(\"drive/My Drive/colab/.netrc\")\n",
        "    wandb_local_netrc_path = Path(\"/root/.netrc\")\n",
        "    if wandb_drive_netrc_path.exists():\n",
        "        import shutil\n",
        "\n",
        "        print(\"Wandb .netrc file found, will use that to log in.\")\n",
        "        shutil.copy(wandb_drive_netrc_path, wandb_local_netrc_path)\n",
        "    else:\n",
        "        print(\n",
        "            f\"Wandb config not found at {wandb_drive_netrc_path}.\\n\"\n",
        "            f\"Using manual login.\\n\\n\"\n",
        "            f\"To use auto login in the future, finish the manual login first and then run:\\n\\n\"\n",
        "            f\"\\t!mkdir -p '{wandb_drive_netrc_path.parent}'\\n\"\n",
        "            f\"\\t!cp {wandb_local_netrc_path} '{wandb_drive_netrc_path}'\\n\\n\"\n",
        "            f\"Then that file will be used to login next time.\\n\"\n",
        "        )\n",
        "\n",
        "    !wandb login\n",
        "\n",
        "    #read information (run config, etc) stored online\n",
        "        #all config will be replaced by the stored one in wandb\n",
        "    api = wandb.Api()\n",
        "    try:\n",
        "        project_name = \"tree-gan\"\n",
        "        run = api.run(f\"bugan/{project_name}/{id}\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"set project_name to tree-gan Failed. Try handtool-gan\")\n",
        "        try:\n",
        "            project_name = \"handtool-gan\"\n",
        "            run = api.run(f\"bugan/{project_name}/{id}\")\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"set project_name to handtool-gan Failed. Try chair-gan\")\n",
        "            project_name = \"chair-gan\"\n",
        "            run = api.run(f\"bugan/{project_name}/{id}\")\n",
        "    config = Namespace(**run.config)\n",
        "        #load selected_model, rev_number in the config\n",
        "    if hasattr(config, \"selected_model\"):\n",
        "        selected_model = config.selected_model\n",
        "    if hasattr(config, \"rev_number\"):\n",
        "        rev_number = config.rev_number\n",
        "\n",
        "    output.clear()\n",
        "    print(\"run id: \" + str(run.id))\n",
        "    print(\"run name: \" + str(run.name))\n",
        "    print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run id: 2pohik1y\n",
            "run name: colorful-elevator-1054\n",
            "ok!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "d5965af4-9939-4951-80d5-6c8a078bac1b"
      },
      "source": [
        "#@markdown package and functions\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "from pathlib import Path\n",
        "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%pip install --upgrade git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "\n",
        "run_path = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\"\n",
        "\n",
        "from bugan.trainPL import _get_models\n",
        "from bugan.functionsPL import netarray2mesh, eval_cluster\n",
        "\n",
        "def install_bugan_package(rev_number=None):\n",
        "    if rev_number:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                f\"git+https://github.com/buganart/BUGAN.git@{rev_number}#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                \"git+https://github.com/buganart/BUGAN.git#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "# load model\n",
        "def generateFromCheckpoint(selected_model, ckpt_filePath, class_index=None, num_samples=1, package_rev_number=None, output_file_name_dict = {}):\n",
        "    # in case loading model failure can be fixed by modifying config params, modify here.\n",
        "    try:\n",
        "        # try newest bugan version\n",
        "        install_bugan_package(rev_number=package_rev_number)\n",
        "        from bugan.trainPL import _get_models\n",
        "        MODEL_CLASS = _get_models(selected_model)\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath, config=config)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        # restore bugan version\n",
        "        install_bugan_package()\n",
        "        from bugan.trainPL import _get_models\n",
        "        MODEL_CLASS = _get_models(selected_model)\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath, config=config)\n",
        "\n",
        "    model = model.eval()#.to(device)\n",
        "    try:\n",
        "        #assume conditional model\n",
        "        sample_trees = model.generate_tree(c=class_index, num_trees=num_samples)\n",
        "        output_file_name_dict[\"class\"] = class_index\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"generate with class label does not work. Now generate without label\")\n",
        "        #assume unconditional model\n",
        "        sample_trees = model.generate_tree(num_trees=num_samples)\n",
        "    \n",
        "    save_filename_header = \"\"\n",
        "    for k,v in output_file_name_dict.items():\n",
        "        save_filename_header = save_filename_header + f\"_{str(k)}_{str(v)}\"\n",
        "\n",
        "    for n in range(num_samples):\n",
        "        sample_tree_array = sample_trees[n]\n",
        "        voxelmesh = netarray2mesh(sample_tree_array)\n",
        "        save_filename = f\"sample_{n}{save_filename_header}.obj\"\n",
        "        if export_location:\n",
        "            export_path = export_location / save_filename\n",
        "            voxelmesh.export(file_obj=export_path, file_type=\"obj\")\n",
        "        #if zip, save also to temp_location \n",
        "        if browser_download:\n",
        "            temp_path = temp_location / save_filename\n",
        "            voxelmesh.export(file_obj=temp_path, file_type=\"obj\")\n",
        "        \n",
        "        # post processing\n",
        "        if post_process and export_location_processed:\n",
        "            # post process array\n",
        "            processed_tree_array = post_process_array(sample_tree_array)\n",
        "            processed_voxelmesh = netarray2mesh(processed_tree_array)\n",
        "            processed_save_filename = f\"sample_{n}{save_filename_header}_processed.obj\"\n",
        "            # save\n",
        "            export_path = export_location_processed / processed_save_filename\n",
        "            processed_voxelmesh.export(file_obj=export_path, file_type=\"obj\")\n",
        "\n",
        "            if browser_download:\n",
        "                temp_path = temp_location / processed_save_filename\n",
        "                processed_voxelmesh.export(file_obj=temp_path, file_type=\"obj\")\n",
        "\n",
        "    return sample_trees\n",
        "\n",
        "\n",
        "# post processing array\n",
        "def cluster_in_sphere(voxel_index_list, center, radius):\n",
        "    center = np.array(center)\n",
        "    for v in voxel_index_list:\n",
        "        v = np.array(v)\n",
        "        dist = np.linalg.norm(v-center)\n",
        "        if dist < radius:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def post_process_array(boolarray):\n",
        "    boolarray = boolarray > 0\n",
        "    cluster = eval_cluster(boolarray)\n",
        "\n",
        "    #post process\n",
        "    process_cluster = []\n",
        "    for l in cluster:\n",
        "        l = list(l)\n",
        "        if len(l) < point_threshold:\n",
        "            continue\n",
        "        if not cluster_in_sphere(l, np.array(boolarray.shape) / 2, radius):\n",
        "            continue\n",
        "        process_cluster.append(l)\n",
        "\n",
        "    #point form back to array form\n",
        "    processed_tree = np.zeros_like(boolarray)\n",
        "    for c in process_cluster:\n",
        "        for index in c:\n",
        "            i,j,k = index\n",
        "            processed_tree[i,j,k] = 1\n",
        "    return processed_tree\n",
        "\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ04363JY9Yt"
      },
      "source": [
        "#generate samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5H_WnkNY_aE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "cellView": "form",
        "outputId": "5cdbda5d-860e-4828-a66c-9c762c94efba"
      },
      "source": [
        "#@markdown generate samples\n",
        "temp_location = Path(\"/tmp/generated/\")\n",
        "temp_location.mkdir(parents=True, exist_ok=True)\n",
        "# copy files to export location\n",
        "if export_location:\n",
        "    # create directory\n",
        "    export_location = Path(export_location)\n",
        "    export_location.mkdir(parents=True, exist_ok=True)\n",
        "if post_process and export_location_processed:\n",
        "    # create directory\n",
        "    export_location_processed = Path(export_location_processed)\n",
        "    export_location_processed.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if generateMeshHistory:\n",
        "    # find necessary checkpoint file\n",
        "    epoch_list = []\n",
        "    epoch_file_dict = {}\n",
        "    for file in run.files():\n",
        "        filename = file.name\n",
        "        if not \".ckpt\" in filename:\n",
        "            continue\n",
        "        if (filename == \"checkpoint.ckpt\") or (filename == \"checkpoint_prev.ckpt\"):\n",
        "            continue\n",
        "        file_epoch = str((filename.split(\"_\")[1]).split(\".\")[0])\n",
        "        epoch_list.append(int(file_epoch))\n",
        "        epoch_file_dict[file_epoch] = file\n",
        "\n",
        "    epoch_list = sorted(epoch_list)\n",
        "    # # quick fix index if generate mesh history crash.\n",
        "    # epoch_list = epoch_list[22:]\n",
        "    if len(epoch_list) < num_selected_checkpoint:\n",
        "        num_selected_checkpoint = len(epoch_list)\n",
        "    print(f\"select {num_selected_checkpoint} out of {len(epoch_list)} checkpoints......\")\n",
        "    selected_epoch_index = [\n",
        "        int(i / (num_selected_checkpoint - 1) * (len(epoch_list) - 1) + 0.5)\n",
        "        for i in range(num_selected_checkpoint)\n",
        "    ]\n",
        "\n",
        "    #download checkpoint and generate mesh\n",
        "    for checkpoint_epoch_index in selected_epoch_index:\n",
        "        file_epoch = str(epoch_list[checkpoint_epoch_index])\n",
        "        print(f\"generate mesh for epoch {file_epoch}......\")\n",
        "        try:\n",
        "            ckpt_file = epoch_file_dict[file_epoch]\n",
        "            ckpt_file.download(replace=True)\n",
        "            generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {\"epoch\":file_epoch})\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"generate mesh for epoch {file_epoch} FAILED !!!\")\n",
        "else:\n",
        "    try:\n",
        "        ckpt_file = run.file(\"checkpoint.ckpt\").download(replace=True)\n",
        "        generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {})\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"loading from checkpoint.ckpt failed. Try checkpoint_prev.ckpt\")\n",
        "        ckpt_file = run.file(\"checkpoint_prev.ckpt\").download(replace=True)\n",
        "        generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {})\n",
        "\n",
        "#zip files in the directory\n",
        "if not browser_download:\n",
        "    raise Exception(\"will not download files from the browser. Terminate here.\")\n",
        "\n",
        "!zip -r /tmp/file.zip /tmp/generated/\n",
        "from google.colab import files\n",
        "files.download(\"/tmp/file.zip\")\n",
        "\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generate_tree() got an unexpected keyword argument 'c'\n",
            "generate with class label does not work. Now generate without label\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4c8f2d7ab401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#zip files in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbrowser_download\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"will not download files from the browser. Terminate here.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zip -r /tmp/file.zip /tmp/generated/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: will not download files from the browser. Terminate here."
          ]
        }
      ]
    }
  ]
}