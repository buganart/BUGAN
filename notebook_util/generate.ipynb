{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/notebook_util/generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "U7vZdhtZBgTM"
      },
      "source": [
        "#@markdown Check GPU, should be a Tesla V100\n",
        "!nvidia-smi -L\n",
        "import os\n",
        "print(f\"We have {os.cpu_count()} CPU cores.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH",
        "cellView": "form"
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown - choose whether to use wandb id or use checkpoint_path to select checkpoint file\n",
        "\n",
        "#@markdown Choice 1: wandb id to select checkpoint file\n",
        "#@markdown Enter project name\n",
        "#@markdown - the name of the wandb project in the format of {entity}/{project_name}\n",
        "#@markdown - \"bugan/tree-gan\", \"bugan/handtool-gan\", \"bugan/chair-gan\" are private project reserved for bugan.\n",
        "#@markdown - \"bugan/stylegan2-open\" is a open project, which act as a testing ground for the public.\n",
        "#@markdown - In case you want the experiment results upload to your project, fill it in project_name_option.\n",
        "#@markdown - if project_name_option is not empty, project_name_option will overwrite project_name\n",
        "project_name = \"bugan/tree-gan\" #@param [\"bugan/tree-gan\", \"bugan/handtool-gan\", \"bugan/chair-gan\", \"bugan/bu-3dgan-open\"]\n",
        "project_name_option = \"\" #@param {type:\"string\"}\n",
        "#@markdown - set `\"run_id\"` to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "id = \"1xqvp1q4\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Choice 2: file path and model type to select saved checkpoint .ckpt file\n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.\n",
        "#@markdown - file path example: `/content/drive/My Drive/h/k/checkpoint.ckpt` \n",
        "ckpt_file_location = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Enter trained neural network model type\n",
        "#@markdown - (may be necessary for wandb_id if selected_model is not saved in config)\n",
        "selected_model = \"CVAEGAN\"    #@param [\"VAEGAN\", \"GAN\", \"VAE\", \"WGAN\", \"WGAN_GP\", \"CGAN\", \"CVAEGAN\"]\n",
        "\n",
        "#@markdown In case the model is conditional, specify class index here.\n",
        "class_index =  12#@param {type:\"integer\"}\n",
        "#@markdown Enter how many samples to generate\n",
        "test_num_samples =     100#@param {type:\"integer\"}\n",
        "#@markdown OPTIONAL: boolean to choose whether to generate from list of history checkpoints or just the latest checkpoint.\n",
        "generateMeshHistory = False #@param {type:\"boolean\"}\n",
        "#@markdown OPTIONAL: If generateMeshHistory enabled, select \"num_selected_checkpoint\" checkpoints in the saved history checkpoint list.\n",
        "num_selected_checkpoint =  0 #@param {type:\"integer\"}\n",
        "#@markdown whether to zip file and download with browser\n",
        "browser_download = False #@param {type:\"boolean\"}\n",
        "#@markdown Enter export location for generated mesh (folder/directory).    \n",
        "export_location = f\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/{id}\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Post process generated mesh\n",
        "#@markdown whether to post process meshes\n",
        "post_process = True #@param {type:\"boolean\"}\n",
        "#@markdown remove clusters that has no points in the unit sphere of radius.\n",
        "#@markdown - casting sphere of radius in the center of the cube voxel space.\n",
        "#@markdown - keep cluster that has at least 1 point in the sphere, those has no points in the sphere will be discarded.\n",
        "#@markdown - For resolution=64, radius of the sphere that fit the cube voxel space is 32.\n",
        "radius=28 #@param {type:\"number\"}\n",
        "#@markdown remove clusters that has less than point_threshold points.\n",
        "point_threshold = 50 #@param {type:\"integer\"}\n",
        "#@markdown Enter export location for post-processed generated mesh (folder/directory).\n",
        "#@markdown - After the mesh is generated, they are in array format. Post-processing algorithms will be used to remove outliers / floating voxels.\n",
        "export_location_processed = f\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/{id}_postprocessed\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "##project_name_option\n",
        "if project_name_option:\n",
        "    project_name = project_name_option\n",
        "    if \"/\" in project_name:\n",
        "        #validate\n",
        "        project_list = project_name.split(\"/\")\n",
        "        if len(project_list[0]) < 1:\n",
        "            print(\"\\\"/\\\" exists, but entity is empty.\")\n",
        "            print(f\"set entity as login entity, and set project_name: {project_list[1]}\")\n",
        "            project_name = project_list[1]\n",
        "        if len(project_list[1]) < 1:\n",
        "            raise Exception(\"\\\"/\\\" exists, but project_name is empty.\")\n",
        "\n",
        "\n",
        "if id and ckpt_file_location:\n",
        "    raise Exception(\"Only one of id / ckpt_file_location can be set!\")\n",
        "if (not id) and (not ckpt_file_location):\n",
        "    raise Exception(\"Please set id / ckpt_file_location!\")\n",
        "\n",
        "if id:\n",
        "    print(\"id:\", id)\n",
        "else:\n",
        "    print(\"selected_model:\", selected_model)\n",
        "    print(\"ckpt_file_location:\", ckpt_file_location)\n",
        "print(\"test_num_samples:\", test_num_samples)\n",
        "print(\"export_location:\", export_location)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form"
      },
      "source": [
        "from argparse import Namespace, ArgumentParser\n",
        "#@markdown Install wandb and log in\n",
        "rev_number = None\n",
        "if id:\n",
        "    !pip install wandb\n",
        "    output.clear()\n",
        "    #find wandb API key file to auto login\n",
        "    import wandb\n",
        "    wandb_drive_netrc_path = Path(\"drive/My Drive/colab/.netrc\")\n",
        "    wandb_local_netrc_path = Path(\"/root/.netrc\")\n",
        "    if wandb_drive_netrc_path.exists():\n",
        "        import shutil\n",
        "\n",
        "        print(\"Wandb .netrc file found, will use that to log in.\")\n",
        "        shutil.copy(wandb_drive_netrc_path, wandb_local_netrc_path)\n",
        "    else:\n",
        "        print(\n",
        "            f\"Wandb config not found at {wandb_drive_netrc_path}.\\n\"\n",
        "            f\"Using manual login.\\n\\n\"\n",
        "            f\"To use auto login in the future, finish the manual login first and then run:\\n\\n\"\n",
        "            f\"\\t!mkdir -p '{wandb_drive_netrc_path.parent}'\\n\"\n",
        "            f\"\\t!cp {wandb_local_netrc_path} '{wandb_drive_netrc_path}'\\n\\n\"\n",
        "            f\"Then that file will be used to login next time.\\n\"\n",
        "        )\n",
        "\n",
        "    !wandb login\n",
        "\n",
        "    #read information (run config, etc) stored online\n",
        "        #all config will be replaced by the stored one in wandb\n",
        "    # extract entity from project_name if in format \"{entity}/{project_name}\"\n",
        "    if \"/\" in project_name:\n",
        "        project_list = project_name.split(\"/\")\n",
        "        entity = project_list[0]\n",
        "        project_name = project_list[1]\n",
        "    else:\n",
        "        # use default login entity\n",
        "        entity = None\n",
        "\n",
        "    run_string = f\"{project_name}/{id}\"\n",
        "    if entity:\n",
        "        run_string = f\"{entity}/\" + run_string\n",
        "\n",
        "    # all config will be replaced by the stored one in wandb\n",
        "    api = wandb.Api()\n",
        "    run = api.run(run_string)\n",
        "    config = Namespace(**run.config)\n",
        "        #load selected_model, rev_number in the config\n",
        "    if hasattr(config, \"selected_model\"):\n",
        "        selected_model = config.selected_model\n",
        "    if hasattr(config, \"rev_number\"):\n",
        "        rev_number = config.rev_number\n",
        "\n",
        "    output.clear()\n",
        "    print(\"run id: \" + str(run.id))\n",
        "    print(\"run name: \" + str(run.name))\n",
        "    print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "cellView": "form"
      },
      "source": [
        "#@markdown package and functions\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "from pathlib import Path\n",
        "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%pip install --upgrade git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "\n",
        "run_path = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\"\n",
        "\n",
        "from bugan.trainPL import _get_models\n",
        "from bugan.functionsPL import netarray2mesh, eval_cluster\n",
        "\n",
        "def install_bugan_package(rev_number=None):\n",
        "    if rev_number:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                f\"git+https://github.com/buganart/BUGAN.git@{rev_number}#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                \"git+https://github.com/buganart/BUGAN.git#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "# load model\n",
        "def generateFromCheckpoint(selected_model, ckpt_filePath, class_index=None, num_samples=1, package_rev_number=None, output_file_name_dict = {}):\n",
        "    # in case loading model failure can be fixed by modifying config params, modify here.\n",
        "    try:\n",
        "        # try newest bugan version\n",
        "        install_bugan_package(rev_number=package_rev_number)\n",
        "        from bugan.trainPL import _get_models\n",
        "        MODEL_CLASS = _get_models(selected_model)\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath, config=config)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        # restore bugan version\n",
        "        install_bugan_package()\n",
        "        from bugan.trainPL import _get_models\n",
        "        MODEL_CLASS = _get_models(selected_model)\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath, config=config)\n",
        "\n",
        "    model = model.eval()#.to(device)\n",
        "    try:\n",
        "        #assume conditional model\n",
        "        sample_trees = model.generate_tree(c=class_index, num_trees=num_samples)\n",
        "        output_file_name_dict[\"class\"] = class_index\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"generate with class label does not work. Now generate without label\")\n",
        "        #assume unconditional model\n",
        "        sample_trees = model.generate_tree(num_trees=num_samples)\n",
        "    \n",
        "    save_filename_header = \"\"\n",
        "    for k,v in output_file_name_dict.items():\n",
        "        save_filename_header = save_filename_header + f\"_{str(k)}_{str(v)}\"\n",
        "\n",
        "    for n in range(num_samples):\n",
        "        sample_tree_array = sample_trees[n]\n",
        "        voxelmesh = netarray2mesh(sample_tree_array)\n",
        "        save_filename = f\"sample_{n}{save_filename_header}.obj\"\n",
        "        if export_location:\n",
        "            export_path = export_location / save_filename\n",
        "            voxelmesh.export(file_obj=export_path, file_type=\"obj\")\n",
        "        #if zip, save also to temp_location \n",
        "        if browser_download:\n",
        "            temp_path = temp_location / save_filename\n",
        "            voxelmesh.export(file_obj=temp_path, file_type=\"obj\")\n",
        "        \n",
        "        # post processing\n",
        "        if post_process and export_location_processed:\n",
        "            # post process array\n",
        "            processed_tree_array = post_process_array(sample_tree_array)\n",
        "            processed_voxelmesh = netarray2mesh(processed_tree_array)\n",
        "            processed_save_filename = f\"sample_{n}{save_filename_header}_processed.obj\"\n",
        "            # save\n",
        "            export_path = export_location_processed / processed_save_filename\n",
        "            processed_voxelmesh.export(file_obj=export_path, file_type=\"obj\")\n",
        "\n",
        "            if browser_download:\n",
        "                temp_path = temp_location / processed_save_filename\n",
        "                processed_voxelmesh.export(file_obj=temp_path, file_type=\"obj\")\n",
        "\n",
        "    return sample_trees\n",
        "\n",
        "\n",
        "# post processing array\n",
        "def cluster_in_sphere(voxel_index_list, center, radius):\n",
        "    center = np.array(center)\n",
        "    for v in voxel_index_list:\n",
        "        v = np.array(v)\n",
        "        dist = np.linalg.norm(v-center)\n",
        "        if dist < radius:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def post_process_array(boolarray):\n",
        "    boolarray = boolarray > 0\n",
        "    cluster = eval_cluster(boolarray)\n",
        "\n",
        "    #post process\n",
        "    process_cluster = []\n",
        "    for l in cluster:\n",
        "        l = list(l)\n",
        "        if len(l) < point_threshold:\n",
        "            continue\n",
        "        if not cluster_in_sphere(l, np.array(boolarray.shape) / 2, radius):\n",
        "            continue\n",
        "        process_cluster.append(l)\n",
        "\n",
        "    #point form back to array form\n",
        "    processed_tree = np.zeros_like(boolarray)\n",
        "    for c in process_cluster:\n",
        "        for index in c:\n",
        "            i,j,k = index\n",
        "            processed_tree[i,j,k] = 1\n",
        "    return processed_tree\n",
        "\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ04363JY9Yt"
      },
      "source": [
        "#generate samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5H_WnkNY_aE",
        "cellView": "form"
      },
      "source": [
        "#@markdown generate samples\n",
        "temp_location = Path(\"/tmp/generated/\")\n",
        "temp_location.mkdir(parents=True, exist_ok=True)\n",
        "# copy files to export location\n",
        "if export_location:\n",
        "    # create directory\n",
        "    export_location = Path(export_location)\n",
        "    export_location.mkdir(parents=True, exist_ok=True)\n",
        "if post_process and export_location_processed:\n",
        "    # create directory\n",
        "    export_location_processed = Path(export_location_processed)\n",
        "    export_location_processed.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if generateMeshHistory:\n",
        "    # find necessary checkpoint file\n",
        "    epoch_list = []\n",
        "    epoch_file_dict = {}\n",
        "    for file in run.files():\n",
        "        filename = file.name\n",
        "        if not \".ckpt\" in filename:\n",
        "            continue\n",
        "        if (filename == \"checkpoint.ckpt\") or (filename == \"checkpoint_prev.ckpt\"):\n",
        "            continue\n",
        "        file_epoch = str((filename.split(\"_\")[1]).split(\".\")[0])\n",
        "        epoch_list.append(int(file_epoch))\n",
        "        epoch_file_dict[file_epoch] = file\n",
        "\n",
        "    epoch_list = sorted(epoch_list)\n",
        "    # # quick fix index if generate mesh history crash.\n",
        "    # epoch_list = epoch_list[22:]\n",
        "    if len(epoch_list) < num_selected_checkpoint:\n",
        "        num_selected_checkpoint = len(epoch_list)\n",
        "    print(f\"select {num_selected_checkpoint} out of {len(epoch_list)} checkpoints......\")\n",
        "    selected_epoch_index = [\n",
        "        int(i / (num_selected_checkpoint - 1) * (len(epoch_list) - 1) + 0.5)\n",
        "        for i in range(num_selected_checkpoint)\n",
        "    ]\n",
        "\n",
        "    #download checkpoint and generate mesh\n",
        "    for checkpoint_epoch_index in selected_epoch_index:\n",
        "        file_epoch = str(epoch_list[checkpoint_epoch_index])\n",
        "        print(f\"generate mesh for epoch {file_epoch}......\")\n",
        "        try:\n",
        "            ckpt_file = epoch_file_dict[file_epoch]\n",
        "            ckpt_file.download(replace=True)\n",
        "            generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {\"epoch\":file_epoch})\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"generate mesh for epoch {file_epoch} FAILED !!!\")\n",
        "else:\n",
        "    try:\n",
        "        ckpt_file = run.file(\"checkpoint.ckpt\").download(replace=True)\n",
        "        generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {})\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"loading from checkpoint.ckpt failed. Try checkpoint_prev.ckpt\")\n",
        "        ckpt_file = run.file(\"checkpoint_prev.ckpt\").download(replace=True)\n",
        "        generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {})\n",
        "\n",
        "#zip files in the directory\n",
        "if not browser_download:\n",
        "    raise Exception(\"will not download files from the browser. Terminate here.\")\n",
        "\n",
        "!zip -r /tmp/file.zip /tmp/generated/\n",
        "from google.colab import files\n",
        "files.download(\"/tmp/file.zip\")\n",
        "\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}