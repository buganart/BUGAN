{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_tree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/notebook_util/generate_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJnfvZCha84J"
      },
      "source": [
        "# Description\n",
        "\n",
        "This notebook is used for generating 3D mesh objects based on trained runs in the wandb project \"bugan/tree-gan\". For training models, please go to [train.ipynb](https://github.com/buganart/BUGAN/blob/master/notebook_util/train.ipynb). \n",
        "\n",
        "User will need to specify **one trained model** through run_id/checkpoint_file that are trained in bugan train notebook above and provide the **number of samples to generate**, then the notebook will generate samples to the **export_location** specified in the panel.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Instruction for specify trained model\n",
        "The trained model is loaded from the saved checkpoint. There are 2 options to specify trained model: \n",
        "\n",
        "1.   set **run_id** and **class_index** directly, then the saved checkpoint of the run will be downloaded\n",
        "2.   set **selected_tree_class**, which will load the preset *`run_id`* and *`class_index`* based on the **selected_tree_class**.\n",
        "<!-- 3.   specify **checkpoint_path** and **class_index** -->\n",
        "\n",
        "Note that the **class_index** is necessary if the loaded model is conditional. However, if the model is unconditional, setting **class_index** will not cause failure on generating 3D objects.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Instruction for other generate parameters\n",
        " \n",
        "\n",
        "**test_num_samples**: \n",
        "*   number of samples to generate from the loaded model.\n",
        "\n",
        "*   If the model is unconditional, it will generate **[test_num_samples]** samples.\n",
        "\n",
        "*   If the model is conditional, it will generate **[test_num_samples]** samples of class **[class_index]**.\n",
        "\n",
        "**generateMeshHistory**: \n",
        "*   boolean to choose whether to generate from list of history checkpoints or just the latest checkpoint.\n",
        "\n",
        "*   In the model training, if *`history_checkpoint_frequency`* is set, then the model will save history checkpoint based on the number of epoch (e.g. save 1 checkpoint per 40 epochs). As that lots of history checkpoints will be saved, only **num_selected_checkpoint** checkpoints will be selected in the list. Enable this will make the model to generate **[test_num_samples]** samples per selected history checkpoint.\n",
        "\n",
        "**num_selected_checkpoint**: \n",
        "\n",
        "*   If the **generateMeshHistory** option is True, select **num_selected_checkpoint** checkpoints in the saved history checkpoint list. \n",
        "\n",
        "**export_location**:\n",
        "*   the export location of generated 3D meshes in the Drive.\n",
        "\n",
        "**browser_download**:\n",
        "*   if **browser_download** is True, after generating meshes into **export_location**, the generated meshes will also be zipped into a zip file, and the browser will download the zip file.\n",
        "*   Note that the **browser_download** is implemented using colab `files.download()`. The download processing speed will be very slow if the zip file is **> 300 MB** (1 mesh is around 4MB).\n",
        "*   Also, if **browser_download** is False, `Exception: will not download files from the browser. Terminate here.` will occur, but it is normal, and the meshes are already saved in the **export_location**.\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "oumAkLp429pi"
      },
      "source": [
        "#@title specify trained model\n",
        "#@markdown - choose which option to specify trained model\n",
        "\n",
        "#@markdown - select class index for conditional model (will be ignored for choice 2 or if the model is unconditional)\n",
        "class_index = 3 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Choice 1: wandb run_id and to select checkpoint file (leave empty if you want to use preset model option 2)\n",
        "#@markdown - set `\"run_id\"` to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "resume_id = \"3mzlr9u3\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Choice 2: generate tree from preset models based on class (please make sure resume_id is empty)\n",
        "#@markdown - Select tree class: load the preset run_id and class_index based on the selected_tree_class \n",
        "selected_tree_class = \"mustard_reaching_1\"    #@param ['double_trunk_1', 'double_trunk_2', 'formal_upright_1', 'formal_upright_2', 'friedrich_1', 'friedrich_2', 'friedrich_3', 'group_1', 'group_2', 'informal_upright_1', 'informal_upright_2', 'leaning_1', 'leaning_2', 'mustard_reaching_1', 'mustard_sapling_1', 'mustard_sapling_2', 'pn_banyan_1', 'pn_maple_1', 'pn_old_1', 'pn_pine_1', 'pn_pine_2', 'pn_pine_3', 'pn_pine_4', 'pn_pine_5', 'pn_pine_6', 'pn_tall_straight', 'pn_tall_straight_old', 'raft_1', 'raft_2', 'semi_cascade_1', 'semi_cascade_2', 'sept_chen_lin_1', 'sept_chen_lin_2', 'sept_chen_lin_3', 'sept_constable_1', 'sept_friedrich_4', 'sept_friedrich_5', 'sept_holten_a', 'sept_holten_b', 'sept_holten_c', 'sept_holten_d', 'sept_holten_e', 'sept_holten_f', 'sept_holten_g', 'sept_holten_h', 'sept_holten_i', 'sept_holten_j', 'sept_holten_k', 'sept_holten_l', 'sept_holten_m', 'sept_holten_n', 'sept_holten_o', 'sept_holten_p', 'sept_holten_q', 'sept_holten_r', 'sept_holten_s', 'sept_holten_t', 'sept_holten_u', 'sept_holten_v', 'sept_holten_w', 'sept_holten_x', 'sept_holten_y', 'sept_holten_z', 'sept_mondrian_1', 'sept_mondrian_2', 'sept_mondrian_3', 'sept_schiele_1', 'sept_schiele_2', 'sept_schiele_3', 'windswept_1', 'windswept_2', 'zan_gentlemen_1', 'zan_gentlemen_2', 'zan_gentlemen_3', 'zan_gentlemen_4', 'zan_gentlemen_5']\n",
        "\n",
        "preset_models = {\n",
        "'double_trunk_1': ['vtcf6k3t', 0],\n",
        "'double_trunk_2': ['vtcf6k3t', 0],\n",
        "'formal_upright_1': ['vtcf6k3t', 0],\n",
        "'formal_upright_2': ['vtcf6k3t', 0],\n",
        "'friedrich_1': ['vtcf6k3t', 0],\n",
        "'friedrich_2': ['vtcf6k3t', 0],\n",
        "'friedrich_3': ['1v3odhkm', 2],\n",
        "'group_1': ['1fj7x4dk', 4],\n",
        "'group_2': ['1fj7x4dk', 1],\n",
        "'informal_upright_1': ['1fj7x4dk', 2],\n",
        "'informal_upright_2': ['vtcf6k3t', 0],\n",
        "'leaning_1': ['vtcf6k3t', 0],\n",
        "'leaning_2': ['vtcf6k3t', 2],\n",
        "'mustard_reaching_1': ['29k3qjns', 4],\n",
        "'mustard_sapling_1': ['vtcf6k3t', 0],\n",
        "'mustard_sapling_2': ['1fj7x4dk', 3],\n",
        "'pn_banyan_1': ['1v3odhkm', 3],\n",
        "'pn_maple_1': ['1fj7x4dk', 0],\n",
        "'pn_old_1': ['vtcf6k3t', 0],\n",
        "'pn_pine_1': ['29k3qjns', 2],\n",
        "'pn_pine_2': ['1v3odhkm', 0],\n",
        "'pn_pine_3': ['29k3qjns', 0],\n",
        "'pn_pine_4': ['29k3qjns', 1],\n",
        "'pn_pine_5': ['vtcf6k3t', 0],\n",
        "'pn_pine_6': ['vtcf6k3t', 4],\n",
        "'pn_tall_straight': ['29k3qjns', 3],\n",
        "'pn_tall_straight_old': ['1v3odhkm', 4],\n",
        "'raft_1': ['vtcf6k3t', 0],\n",
        "'raft_2': ['1v3odhkm', 1],\n",
        "'semi_cascade_1': ['vtcf6k3t', 3],\n",
        "'semi_cascade_2': ['vtcf6k3t', 1],\n",
        "'sept_chen_lin_1': ['vtcf6k3t', 0],\n",
        "'sept_chen_lin_2': ['vtcf6k3t', 0],\n",
        "'sept_chen_lin_3': ['vtcf6k3t', 0],\n",
        "'sept_constable_1': ['vtcf6k3t', 0],\n",
        "'sept_friedrich_4': ['vtcf6k3t', 0],\n",
        "'sept_friedrich_5': ['vtcf6k3t', 0],\n",
        "'sept_holten_a': ['vtcf6k3t', 0],\n",
        "'sept_holten_b': ['vtcf6k3t', 0],\n",
        "'sept_holten_c': ['vtcf6k3t', 0],\n",
        "'sept_holten_d': ['vtcf6k3t', 0],\n",
        "'sept_holten_e': ['vtcf6k3t', 0],\n",
        "'sept_holten_f': ['vtcf6k3t', 0],\n",
        "'sept_holten_g': ['vtcf6k3t', 0],\n",
        "'sept_holten_h': ['vtcf6k3t', 0],\n",
        "'sept_holten_i': ['vtcf6k3t', 0],\n",
        "'sept_holten_j': ['vtcf6k3t', 0],\n",
        "'sept_holten_k': ['vtcf6k3t', 0],\n",
        "'sept_holten_l': ['vtcf6k3t', 0],\n",
        "'sept_holten_m': ['vtcf6k3t', 0],\n",
        "'sept_holten_n': ['vtcf6k3t', 0],\n",
        "'sept_holten_o': ['vtcf6k3t', 0],\n",
        "'sept_holten_p': ['vtcf6k3t', 0],\n",
        "'sept_holten_q': ['vtcf6k3t', 0],\n",
        "'sept_holten_r': ['vtcf6k3t', 0],\n",
        "'sept_holten_s': ['vtcf6k3t', 0],\n",
        "'sept_holten_t': ['vtcf6k3t', 0],\n",
        "'sept_holten_u': ['vtcf6k3t', 0],\n",
        "'sept_holten_v': ['vtcf6k3t', 0],\n",
        "'sept_holten_w': ['vtcf6k3t', 0],\n",
        "'sept_holten_x': ['vtcf6k3t', 0],\n",
        "'sept_holten_y': ['vtcf6k3t', 0],\n",
        "'sept_holten_z': ['vtcf6k3t', 0],\n",
        "'sept_mondrian_1': ['vtcf6k3t', 0],\n",
        "'sept_mondrian_2': ['vtcf6k3t', 0],\n",
        "'sept_mondrian_3': ['vtcf6k3t', 0],\n",
        "'sept_schiele_1': ['vtcf6k3t', 0],\n",
        "'sept_schiele_2': ['vtcf6k3t', 0],\n",
        "'sept_schiele_3': ['vtcf6k3t', 0],\n",
        "'windswept_1': ['vtcf6k3t', 0],\n",
        "'windswept_2': ['vtcf6k3t', 0],\n",
        "'zan_gentlemen_1': ['vtcf6k3t', 0],\n",
        "'zan_gentlemen_2': ['vtcf6k3t', 0],\n",
        "'zan_gentlemen_3': ['vtcf6k3t', 0],\n",
        "'zan_gentlemen_4': ['vtcf6k3t', 0],\n",
        "'zan_gentlemen_5': ['vtcf6k3t', 0]}\n",
        "\n",
        "if resume_id == \"\":\n",
        "    #find preset_model_id\n",
        "    preset_model_list = preset_models[selected_tree_class]\n",
        "    preset_model_id, class_index = preset_model_list\n",
        "    resume_id = preset_model_id\n",
        "    print(\"selected_tree_class:\", selected_tree_class)\n",
        "    print(\"preset_model_id:\", preset_model_id)\n",
        "else:\n",
        "    print(\"resume_id:\", resume_id)\n",
        "\n",
        "project_name = \"tree-gan\"\n",
        "print(\"class_index:\", class_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH",
        "cellView": "form"
      },
      "source": [
        "#@title other generate parameters\n",
        "\n",
        "#@markdown number of samples to generate from the loaded model.\n",
        "test_num_samples = 10    #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown OPTIONAL: boolean to choose whether to generate from list of history checkpoints or just the latest checkpoint.\n",
        "generateMeshHistory = False #@param {type:\"boolean\"}\n",
        "#@markdown OPTIONAL: If generateMeshHistory enabled, select \"num_selected_checkpoint\" checkpoints in the saved history checkpoint list.\n",
        "num_selected_checkpoint = 4 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Enter export location (folder/directory).   \n",
        "export_location = f\"/content/drive/MyDrive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/{resume_id}_{str(class_index)}\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown whether to zip file and download with browser\n",
        "browser_download = False #@param {type:\"boolean\"}\n",
        "\n",
        "print(\"test_num_samples:\", test_num_samples)\n",
        "print(\"export_location:\", export_location)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form"
      },
      "source": [
        "from argparse import Namespace, ArgumentParser\n",
        "#@markdown Install wandb and log in\n",
        "entity=\"bugan\"\n",
        "rev_number = None\n",
        "if resume_id:\n",
        "    !pip install wandb\n",
        "    output.clear()\n",
        "    #find wandb API key file to auto login\n",
        "    import wandb\n",
        "    wandb_drive_netrc_path = Path(\"drive/My Drive/colab/.netrc\")\n",
        "    wandb_local_netrc_path = Path(\"/root/.netrc\")\n",
        "    if wandb_drive_netrc_path.exists():\n",
        "        import shutil\n",
        "\n",
        "        print(\"Wandb .netrc file found, will use that to log in.\")\n",
        "        shutil.copy(wandb_drive_netrc_path, wandb_local_netrc_path)\n",
        "    else:\n",
        "        print(\n",
        "            f\"Wandb config not found at {wandb_drive_netrc_path}.\\n\"\n",
        "            f\"Using manual login.\\n\\n\"\n",
        "            f\"To use auto login in the future, finish the manual login first and then run:\\n\\n\"\n",
        "            f\"\\t!mkdir -p '{wandb_drive_netrc_path.parent}'\\n\"\n",
        "            f\"\\t!cp {wandb_local_netrc_path} '{wandb_drive_netrc_path}'\\n\\n\"\n",
        "            f\"Then that file will be used to login next time.\\n\"\n",
        "        )\n",
        "\n",
        "    !wandb login\n",
        "\n",
        "    #read information (run config, etc) stored online\n",
        "        #all config will be replaced by the stored one in wandb\n",
        "    api = wandb.Api()\n",
        "    run = api.run(f\"{entity}/{project_name}/{resume_id}\")\n",
        "    config = Namespace(**run.config)\n",
        "        #load selected_model, rev_number in the config\n",
        "    if hasattr(config, \"selected_model\"):\n",
        "        selected_model = config.selected_model\n",
        "    if hasattr(config, \"rev_number\"):\n",
        "        rev_number = config.rev_number\n",
        "\n",
        "    output.clear()\n",
        "    print(\"run id: \" + str(run.id))\n",
        "    print(\"run name: \" + str(run.name))\n",
        "    print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just load the model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "cellView": "form"
      },
      "source": [
        "#@markdown package and functions\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "from pathlib import Path\n",
        "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%pip install --upgrade git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "\n",
        "run_path = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\"\n",
        "\n",
        "from bugan.trainPL import _get_models\n",
        "from bugan.functionsPL import netarray2mesh\n",
        "\n",
        "def install_bugan_package(rev_number=None):\n",
        "    if rev_number:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                f\"git+https://github.com/buganart/BUGAN.git@{rev_number}#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                \"git+https://github.com/buganart/BUGAN.git#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "# load model\n",
        "def generateFromCheckpoint(selected_model, ckpt_filePath, class_index=None, num_samples=1, package_rev_number=None, output_file_name_dict = {}):\n",
        "    MODEL_CLASS = _get_models(selected_model)\n",
        "    try:\n",
        "        # restore bugan version\n",
        "        install_bugan_package(rev_number=package_rev_number)\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        # try newest bugan version\n",
        "        install_bugan_package()\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath)\n",
        "\n",
        "    model = model.eval()#.to(device)\n",
        "    try:\n",
        "        #assume conditional model\n",
        "        sample_trees = model.generate_tree(c=class_index, num_trees=test_num_samples)\n",
        "        output_file_name_dict[\"class\"] = class_index\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"generate with class label does not work. Now generate without label\")\n",
        "        #assume unconditional model\n",
        "        sample_trees = model.generate_tree(num_trees=test_num_samples)\n",
        "    \n",
        "    save_filename_header = \"\"\n",
        "    for k,v in output_file_name_dict.items():\n",
        "        save_filename_header = save_filename_header + f\"_{str(k)}_{str(v)}\"\n",
        "\n",
        "    for n in range(num_samples):\n",
        "        sample_tree_array = sample_trees[n]\n",
        "        voxelmesh = netarray2mesh(sample_tree_array)\n",
        "        save_filename = f\"sample_{n}{save_filename_header}.obj\"\n",
        "        if export_location:\n",
        "            export_path = export_location / save_filename\n",
        "            voxelmesh.export(file_obj=export_path, file_type=\"obj\")\n",
        "        #if zip, save also to temp_location \n",
        "        if browser_download:\n",
        "            temp_path = temp_location / save_filename\n",
        "            voxelmesh.export(file_obj=temp_path, file_type=\"obj\")\n",
        "\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5H_WnkNY_aE"
      },
      "source": [
        "#@markdown generate samples\n",
        "temp_location = Path(\"/tmp/generated/\")\n",
        "temp_location.mkdir(parents=True, exist_ok=True)\n",
        "# copy files to export location\n",
        "if export_location:\n",
        "    # create directory\n",
        "    export_location = Path(export_location)\n",
        "    export_location.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if generateMeshHistory:\n",
        "    # find necessary checkpoint file\n",
        "    epoch_list = []\n",
        "    epoch_file_dict = {}\n",
        "    for file in run.files():\n",
        "        filename = file.name\n",
        "        if not \".ckpt\" in filename:\n",
        "            continue\n",
        "        if (filename == \"checkpoint.ckpt\") or (filename == \"checkpoint_prev.ckpt\"):\n",
        "            continue\n",
        "        file_epoch = str((filename.split(\"_\")[1]).split(\".\")[0])\n",
        "        epoch_list.append(int(file_epoch))\n",
        "        epoch_file_dict[file_epoch] = file\n",
        "\n",
        "    epoch_list = sorted(epoch_list)\n",
        "    if len(epoch_list) < num_selected_checkpoint:\n",
        "        num_selected_checkpoint = len(epoch_list)\n",
        "    selected_epoch_index = [\n",
        "        int(i / (num_selected_checkpoint - 1) * (len(epoch_list) - 1) + 0.5)\n",
        "        for i in range(num_selected_checkpoint)\n",
        "    ]\n",
        "\n",
        "    #download checkpoint and generate mesh\n",
        "    for checkpoint_epoch_index in selected_epoch_index:\n",
        "        file_epoch = str(epoch_list[checkpoint_epoch_index])\n",
        "        print(f\"generate mesh for epoch {file_epoch}......\")\n",
        "        try:\n",
        "            ckpt_file = epoch_file_dict[file_epoch]\n",
        "            ckpt_file.download(replace=True)\n",
        "            generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {\"epoch\":file_epoch})\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"generate mesh for epoch {file_epoch} FAILED !!!\")\n",
        "else:\n",
        "    try:\n",
        "        ckpt_file = run.file(\"checkpoint.ckpt\").download(replace=True)\n",
        "        generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {})\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"loading from checkpoint.ckpt failed. Try checkpoint_prev.ckpt\")\n",
        "        ckpt_file = run.file(\"checkpoint_prev.ckpt\").download(replace=True)\n",
        "        generateFromCheckpoint(selected_model, ckpt_file.name, class_index, test_num_samples, rev_number, {})\n",
        "\n",
        "#zip files in the directory\n",
        "if not browser_download:\n",
        "    raise Exception(\"will not download files from the browser. Terminate here.\")\n",
        "\n",
        "!zip -r /tmp/file.zip /tmp/generated/\n",
        "from google.colab import files\n",
        "files.download(\"/tmp/file.zip\")\n",
        "\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}