{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualize_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/Visualize_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form"
      },
      "source": [
        "#@markdown Install wandb and log in\n",
        "%pip install wandb\n",
        "output.clear()\n",
        "import wandb\n",
        "wandb_drive_netrc_path = Path(\"drive/My Drive/colab/.netrc\")\n",
        "wandb_local_netrc_path = Path(\"/root/.netrc\")\n",
        "if wandb_drive_netrc_path.exists():\n",
        "    import shutil\n",
        "\n",
        "    print(\"Wandb .netrc file found, will use that to log in.\")\n",
        "    shutil.copy(wandb_drive_netrc_path, wandb_local_netrc_path)\n",
        "else:\n",
        "    print(\n",
        "        f\"Wandb config not found at {wandb_drive_netrc_path}.\\n\"\n",
        "        f\"Using manual login.\\n\\n\"\n",
        "        f\"To use auto login in the future, finish the manual login first and then run:\\n\\n\"\n",
        "        f\"\\t!mkdir -p '{wandb_drive_netrc_path.parent}'\\n\"\n",
        "        f\"\\t!cp {wandb_local_netrc_path} '{wandb_drive_netrc_path}'\\n\\n\"\n",
        "        f\"Then that file will be used to login next time.\\n\"\n",
        "    )\n",
        "\n",
        "!wandb login\n",
        "output.clear()\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH"
      },
      "source": [
        "#@title Configure dataset\n",
        "#@markdown Enter project name (either `chair-gan`, `handtool-gan` or `tree-gan`)\n",
        "project_name = \"tree-gan\" #@param [\"tree-gan\", \"handtool-gan\", \"chair-gan\"]\n",
        "#@markdown Enter dataset location.  \n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.)\n",
        "#@markdown - zipfile example: `/content/drive/My Drive/h/k/a.zip`\n",
        "#@markdown - file folder example: `/content/drive/My Drive/h/k` \n",
        "data_location = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj_auto_generated/sessions/simplified/tree-session-2020-09-14_23-23-Friedrich_2-target-face-num-1000.zip\" #@param {type:\"string\"}\n",
        "#@markdown - choose rotation augmentation on-the-fly \n",
        "#@markdown (augmentation only support file folder in data_location)\n",
        "data_augmentation = False    #@param {type:\"boolean\"}\n",
        "aug_rotation_type = \"random rotation\"  #@param [\"random rotation\", \"axis rotation\"]\n",
        "#@markdown - specify the rotation axis [x,y,z] (only for aug_rotation_type = \"axis rotation\")\n",
        "rotation_axis_x = 0    #@param {type:\"number\"}\n",
        "rotation_axis_y = 1    #@param {type:\"number\"}\n",
        "rotation_axis_z = 0    #@param {type:\"number\"}\n",
        "\n",
        "#@markdown - resolution of the voxelized array (shape resolution**3)\n",
        "resolution = \"32\"    #@param [32, 64]\n",
        "\n",
        "#@markdown WANDB log\n",
        "#@markdown - how many samples to log per data batch (size=32)\n",
        "log_num_samples = 4 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#adjust parameter datatype\n",
        "resolution = int(resolution)\n",
        "\n",
        "colab_config = {\n",
        "    \"aug_rotation_type\": aug_rotation_type,\n",
        "    \"data_augmentation\": data_augmentation,\n",
        "    \"aug_rotation_axis\": (rotation_axis_x,rotation_axis_y,rotation_axis_z),\n",
        "    \"data_location\": data_location,\n",
        "    \"project_name\": project_name,\n",
        "    \"log_num_samples\": log_num_samples,\n",
        "    \"resolution\": resolution\n",
        "}\n",
        "\n",
        "for k, v in colab_config.items():\n",
        "    print(f\"=> {k:20}: {v}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUduMFlzmKmO"
      },
      "source": [
        "# To just train a model, no edits should be required in any cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%cd /content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\n",
        "if project_name == \"tree-gan\":\n",
        "    %cd colab-treegan/\n",
        "elif project_name == \"handtool-gan\":\n",
        "    %cd colab-handtool/\n",
        "else:\n",
        "    %cd colab-chair/\n",
        "\n",
        "dataset_path = Path(data_location)\n",
        "run_path = \"./\"\n",
        "\n",
        "!apt-get update\n",
        "\n",
        "%pip install pytorch-lightning\n",
        "%pip install trimesh\n",
        "!apt install -y xvfb\n",
        "%pip install trimesh xvfbwrapper\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU8OYjiWtzeo"
      },
      "source": [
        "import io\n",
        "from io import BytesIO\n",
        "import sys\n",
        "import zipfile\n",
        "import trimesh\n",
        "import numpy as np\n",
        "from argparse import Namespace, ArgumentParser\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "from xvfbwrapper import Xvfb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww3zbHkxAw8B"
      },
      "source": [
        "entity=\"bugan\"\n",
        "#keep track of hyperparams\n",
        "config = Namespace(**colab_config)\n",
        "#datamodule config\n",
        "config.batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2lZ9OiNchg0"
      },
      "source": [
        "run_id = wandb.util.generate_id()\n",
        "\n",
        "run = wandb.init(project=project_name, id=run_id, entity=entity, resume=True, dir=run_path, group=\"Visualize Data\")\n",
        "\n",
        "print(\"run id: \" + str(wandb.run.id))\n",
        "print(\"run name: \" + str(wandb.run.name))\n",
        "wandb.watch_called = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alz0eunxK9hI"
      },
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLlZwwAoKuR"
      },
      "source": [
        "### load our package\n",
        "#directly install using pip\n",
        "print(\"loading BUGAN package latest\")\n",
        "%pip install --upgrade git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "\n",
        "import bugan\n",
        "#EXTRACT package version\n",
        "    #switch stdout to temperary stringIO\n",
        "old_stdout = sys.stdout\n",
        "temp_stdout = io.StringIO()\n",
        "sys.stdout = temp_stdout\n",
        "    #get version\n",
        "%pip freeze | grep bugan\n",
        "version = temp_stdout.getvalue()\n",
        "rev_number = version.split(\"+g\")[1].rstrip()\n",
        "    #switch back stdout\n",
        "sys.stdout = old_stdout\n",
        "output.clear()\n",
        "\n",
        "print(\"bugan package version: \",version)\n",
        "print(\"bugan package revision number: \",rev_number)\n",
        "config.rev_number = rev_number\n",
        "\n",
        "\n",
        "from bugan.functionsPL import *\n",
        "\n",
        "###     load dataset\n",
        "\n",
        "dataset_path = Path(config.data_location)\n",
        "if config.data_location.endswith(\".zip\"):\n",
        "    config.dataset = dataset_path.stem\n",
        "else:\n",
        "    config.dataset = \"dataset_array_custom\"\n",
        "\n",
        "dataModule = DataModule_process(config, run, dataset_path)\n",
        "config.num_data = dataModule.size\n",
        "\n",
        "print(\"dataset name: \",config.dataset)\n",
        "print(\"dataset path: \",dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Pz4e7eOTlu"
      },
      "source": [
        "#base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yezVsM1uOTv-"
      },
      "source": [
        "class PrintDatasetModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(PrintDatasetModel, self).__init__()\n",
        "        self.config = config\n",
        "        self.layer = nn.Linear(1, 1)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.layer.parameters(), lr=0.01)\n",
        "\n",
        "    def training_step(self, dataset_batch, batch_idx):\n",
        "        initial_log_dict={}\n",
        "\n",
        "        dataset_batch = dataset_batch[0] * 2 - 1\n",
        "        dataset_batch = dataset_batch.float().detach().cpu().numpy() \n",
        "\n",
        "        sample_trees = dataset_batch[:, 0, :, :, :]\n",
        "        # log_dict list record\n",
        "        sample_tree_numpoints = []\n",
        "        eval_num_cluster = []\n",
        "        sample_tree_image = []\n",
        "        sample_tree_voxelmesh = []\n",
        "        for n in range(self.config.log_num_samples):\n",
        "            # sample_trees are before sigmoid\n",
        "            sample_tree_bool_array = sample_trees[n] > 0\n",
        "            # log number of points to wandb\n",
        "            sample_tree_indices = netarray2indices(sample_tree_bool_array)\n",
        "            sample_tree_numpoints.append(sample_tree_indices.shape[0])\n",
        "            # count number of cluster in the tree (grouped with dist_inf = 1)\n",
        "            num_cluster = eval_count_cluster(sample_tree_bool_array)\n",
        "            eval_num_cluster.append(num_cluster)\n",
        "\n",
        "            voxelmesh = netarray2mesh(sample_tree_bool_array)\n",
        "\n",
        "            # image / 3D object to log_dict\n",
        "            image = mesh2wandbImage(voxelmesh)\n",
        "            if image is not None:\n",
        "                sample_tree_image.append(image)\n",
        "            voxelmeshfile = mesh2wandb3D(voxelmesh)\n",
        "            sample_tree_voxelmesh.append(voxelmeshfile)\n",
        "\n",
        "        # add list record to log_dict\n",
        "        initial_log_dict[\"sample_tree_numpoints\"] = np.mean(sample_tree_numpoints)\n",
        "        initial_log_dict[\"eval_num_cluster\"] = np.mean(eval_num_cluster)\n",
        "        initial_log_dict[\"sample_tree_image\"] = sample_tree_image\n",
        "        initial_log_dict[\"sample_tree_voxelmesh\"] = sample_tree_voxelmesh\n",
        "\n",
        "        wandb.log(initial_log_dict)\n",
        "\n",
        "        #construct loss\n",
        "        loss = self.layer(torch.zeros(1))\n",
        "        return loss - loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1TU9N4Y8se3"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzV_Mzfd_MZ"
      },
      "source": [
        "#render setup\n",
        "vdisplay = Xvfb()\n",
        "vdisplay.start()\n",
        "\n",
        "#wandb logger setup\n",
        "wandb_logger = WandbLogger(experiment=run, log_model=True)\n",
        "#log config\n",
        "wandb.config.update(config)\n",
        "wandb.jupyter.Notebook(Namespace(save_code=True)).save_history()\n",
        "wandb.save(os.path.join(wandb.run.dir, \"code\", \"_session_history.ipynb\"), base_path=wandb.run.dir)\n",
        "\n",
        "#model\n",
        "model = PrintDatasetModel(config)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 1, logger=wandb_logger,\\\n",
        "                     default_root_dir=wandb.run.dir, checkpoint_callback = None)\n",
        "\n",
        "\n",
        "#train\n",
        "trainer.fit(model, dataModule)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}