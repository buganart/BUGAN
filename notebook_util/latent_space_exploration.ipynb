{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "latent_space_exploration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buganart/BUGAN/blob/master/notebook_util/latent_space_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbGaO5aJS8y"
      },
      "source": [
        "Before starting please save the notebook in your drive by clicking on `File -> Save a copy in drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQtEpYYRh9LM",
        "cellView": "form"
      },
      "source": [
        "#@markdown Mount google drive.\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if we have linked the folder\n",
        "from pathlib import Path\n",
        "if not Path(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database\").exists():\n",
        "    print(\n",
        "        \"Shortcut to our shared drive folder doesn't exits.\\n\\n\"\n",
        "        \"\\t1. Go to the google drive web UI\\n\"\n",
        "        \"\\t2. Right click shared folder IRCMS_GAN_collaborative_database and click \\\"Add shortcut to Drive\\\"\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc1e1IFDN-dJ"
      },
      "source": [
        "# $Description:$\n",
        "\n",
        "This script takes the trained BUGAN model to generate output meshes based on specifying 2 latent vectors [$z_1$, $z_2$], and then latent vectors in a line interval between $z_1$ and $z_2$ will be drawn, and latent space vectors $Z_0, Z_1, ..., Z_{n-1}$ in between will be sampled evenly according to the test_num_samples ($n$) set above.\n",
        "\n",
        "$n = test\\_num\\_samples, i \\in [0, n-1]$\n",
        "\n",
        "$Z_i = \\frac{i}{n-1} z_1 + \\frac{n-1-i}{n-1} z_2$ (Note that $Z_0 = z_1$ and $Z_{n-1} = z_2$)\n",
        "\n",
        "Finally, new meshs will be produced based on those latent space vectors $Z_0, Z_1, ..., Z_{n-1}$:\n",
        "\n",
        "$latent \\ space \\ vector \\ Z_i → decoder/generator → generated \\ mesh \\ m_i$\n",
        "\n",
        "All meshes $m_0, m_1, ..., m_i$ will be stored in the export_location set above.\n",
        "\n",
        "## Note:\n",
        "\n",
        "1. Please have a look at the **Configure notebook setting** below to set BUGAN model using \n",
        "    1. wandb run id (**id**), or \n",
        "    2. using the path to saved checkpoint file (**ckpt_file_location**) and **selected_model**\n",
        "\n",
        "2. Please have a look at the cell to set the latent vectors [$z_1$, $z_2$] in the **SET 2 latent vectors for latent space exploration**.\n",
        "\n",
        "3. If the loaded model is conditional, the **class_index** will also affect the latent vectors. User can also set class indices [$c_1$, $c_2$] in the **SET 2 latent vectors for latent space exploration**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-Vx_QVHLXH",
        "cellView": "form"
      },
      "source": [
        "#@title Configure notebook setting\n",
        "#@markdown - choose whether to use wandb id or use checkpoint_path to select checkpoint file\n",
        "\n",
        "#@markdown Choice 1: wandb id and project_name to select checkpoint file\n",
        "#@markdown - set `\"run_id\"` to resume a run (for example: `u9imsvva`)\n",
        "#@markdown - The id of the current run is shown below in the cell with `wandb.init()` or you can find it in the wandb web UI.\n",
        "id = \"25z72k0w\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Choice 2: file path and model type to select saved checkpoint .ckpt file\n",
        "#@markdown - For example via the file browser on the left to locate and right click to copy the path.\n",
        "#@markdown - file path example: `/content/drive/My Drive/h/k/checkpoint.ckpt` \n",
        "ckpt_file_location = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Enter trained neural network model type\n",
        "#@markdown - (may be necessary for wandb_id if selected_model is not saved in config)\n",
        "selected_model = \"VAEGAN\"    #@param [\"VAEGAN\", \"GAN\", \"VAE\", \"WGAN\", \"WGAN_GP\"]\n",
        "\n",
        "#@markdown Enter how many samples to generate\n",
        "test_num_samples = 100    #@param {type:\"integer\"}\n",
        "#@markdown whether to zip file and download with browser\n",
        "browser_download = False #@param {type:\"boolean\"}\n",
        "#@markdown Enter export location (folder/directory).    \n",
        "export_location = f\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/exportObjects/{id}\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "if id and ckpt_file_location:\n",
        "    raise Exception(\"Only one of id / ckpt_file_location can be set!\")\n",
        "if (not id) and (not ckpt_file_location):\n",
        "    raise Exception(\"Please set id / ckpt_file_location!\")\n",
        "\n",
        "if id:\n",
        "    print(\"id:\", id)\n",
        "else:\n",
        "    print(\"selected_model:\", selected_model)\n",
        "    print(\"ckpt_file_location:\", ckpt_file_location)\n",
        "print(\"test_num_samples:\", test_num_samples)\n",
        "print(\"export_location:\", export_location)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1sqgZf5lRv",
        "cellView": "form"
      },
      "source": [
        "from argparse import Namespace, ArgumentParser\n",
        "#@markdown Install wandb and log in\n",
        "rev_number = None\n",
        "if id:\n",
        "    !pip install wandb\n",
        "    output.clear()\n",
        "    #find wandb API key file to auto login\n",
        "    import wandb\n",
        "    wandb_drive_netrc_path = Path(\"drive/My Drive/colab/.netrc\")\n",
        "    wandb_local_netrc_path = Path(\"/root/.netrc\")\n",
        "    if wandb_drive_netrc_path.exists():\n",
        "        import shutil\n",
        "\n",
        "        print(\"Wandb .netrc file found, will use that to log in.\")\n",
        "        shutil.copy(wandb_drive_netrc_path, wandb_local_netrc_path)\n",
        "    else:\n",
        "        print(\n",
        "            f\"Wandb config not found at {wandb_drive_netrc_path}.\\n\"\n",
        "            f\"Using manual login.\\n\\n\"\n",
        "            f\"To use auto login in the future, finish the manual login first and then run:\\n\\n\"\n",
        "            f\"\\t!mkdir -p '{wandb_drive_netrc_path.parent}'\\n\"\n",
        "            f\"\\t!cp {wandb_local_netrc_path} '{wandb_drive_netrc_path}'\\n\\n\"\n",
        "            f\"Then that file will be used to login next time.\\n\"\n",
        "        )\n",
        "\n",
        "    !wandb login\n",
        "\n",
        "    #read information (run config, etc) stored online\n",
        "        #all config will be replaced by the stored one in wandb\n",
        "    api = wandb.Api()\n",
        "    try:\n",
        "        project_name = \"tree-gan\"\n",
        "        run = api.run(f\"bugan/{project_name}/{id}\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"set project_name to tree-gan Failed. Try handtool-gan\")\n",
        "        try:\n",
        "            project_name = \"handtool-gan\"\n",
        "            run = api.run(f\"bugan/{project_name}/{id}\")\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"set project_name to handtool-gan Failed. Try chair-gan\")\n",
        "            project_name = \"chair-gan\"\n",
        "            run = api.run(f\"bugan/{project_name}/{id}\")\n",
        "\n",
        "\n",
        "    config = Namespace(**run.config)\n",
        "        #load selected_model, rev_number in the config\n",
        "    if hasattr(config, \"selected_model\"):\n",
        "        selected_model = config.selected_model\n",
        "    if hasattr(config, \"rev_number\"):\n",
        "        rev_number = config.rev_number\n",
        "\n",
        "    output.clear()\n",
        "    print(\"run id: \" + str(run.id))\n",
        "    print(\"run name: \" + str(run.name))\n",
        "    print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3jIEKP7i4Nt",
        "cellView": "form"
      },
      "source": [
        "#@markdown package and functions\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "from pathlib import Path\n",
        "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
        "\n",
        "%pip install --upgrade git+https://github.com/buganart/BUGAN.git#egg=bugan\n",
        "\n",
        "run_path = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/\"\n",
        "\n",
        "from bugan.trainPL import _get_models\n",
        "from bugan.functionsPL import netarray2mesh, mesh2arrayCentered\n",
        "\n",
        "def install_bugan_package(rev_number=None):\n",
        "    if rev_number:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                f\"git+https://github.com/buganart/BUGAN.git@{rev_number}#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        subprocess.check_call(\n",
        "            [\n",
        "                sys.executable,\n",
        "                \"-m\",\n",
        "                \"pip\",\n",
        "                \"install\",\n",
        "                \"--upgrade\",\n",
        "                \"git+https://github.com/buganart/BUGAN.git#egg=bugan\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "# load model\n",
        "def getModelFromCheckpoint(selected_model, ckpt_filePath):\n",
        "    # in case loading model failure can be fixed by modifying config params, modify here.\n",
        "    # config.z_size=512\n",
        "    MODEL_CLASS = _get_models(selected_model)\n",
        "    try:\n",
        "        # try newest bugan version\n",
        "        install_bugan_package()\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath, config=config)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        # restore bugan version\n",
        "        install_bugan_package(rev_number=package_rev_number)\n",
        "        model = MODEL_CLASS.load_from_checkpoint(ckpt_filePath, config=config)\n",
        "\n",
        "    model = model.eval()#.to(device)\n",
        "    return model\n",
        "\n",
        "# generateMesh\n",
        "def generateMesh(model, z, class_index=None):\n",
        "    test_num_samples = z.shape[0]\n",
        "    # get generator\n",
        "    if hasattr(model, \"vae\"):\n",
        "        generator = model.vae.vae_decoder\n",
        "        if class_index is not None:\n",
        "            embedding_fn = model.vae.embedding\n",
        "    else:\n",
        "        generator = model.generator\n",
        "        if class_index is not None:\n",
        "            embedding_fn = model.embedding\n",
        "\n",
        "    z = torch.tensor(z).type_as(generator.gen_fc.weight)\n",
        "    if class_index is not None:\n",
        "        if isinstance (class_index,int):\n",
        "            # turn class vector the same device as z, but with dtype Long\n",
        "            c = torch.ones(test_num_samples) * class_index\n",
        "            c = c.type_as(z).to(torch.int64)\n",
        "\n",
        "            # combine z and c\n",
        "            z = model.merge_latent_and_class_vector(\n",
        "                z,\n",
        "                c,\n",
        "                model.config.num_classes,\n",
        "                embedding_fn=embedding_fn,\n",
        "            )\n",
        "        else:\n",
        "            # assume class_index are processed class_vectors\n",
        "            class_vectors = torch.tensor(class_index).type_as(z)\n",
        "\n",
        "            # merge with z to be generator input\n",
        "            z = torch.cat((z, class_vectors), 1)\n",
        "    \n",
        "    generated_tree = generator(z)[:, 0, :, :, :]\n",
        "    generated_tree = generated_tree.detach().cpu().numpy()\n",
        "\n",
        "    return generated_tree\n",
        "\n",
        "#for VAEGAN / VAE, get latent vector from the meshfiles\n",
        "def get_encoded_vector(vae, f_loc, resolution=32):\n",
        "    f = Path(f_loc)\n",
        "    m = trimesh.load(f, force=\"mesh\")\n",
        "    m = mesh2arrayCentered(m, array_length=resolution)\n",
        "    m = m[np.newaxis,np.newaxis,:,:,:]\n",
        "    m = torch.Tensor(m).float().type_as(vae.vae_encoder.dis_fc.weight)\n",
        "    _, z, _ = vae(m, output_all=True)\n",
        "    return z[0].detach().cpu().numpy()\n",
        "\n",
        "output.clear()\n",
        "print('ok!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5H_WnkNY_aE",
        "cellView": "form"
      },
      "source": [
        "#@markdown setup model\n",
        "\n",
        "# load model\n",
        "if ckpt_file_location:\n",
        "    model = getModelFromCheckpoint(selected_model, ckpt_file_location)\n",
        "else:\n",
        "    try:\n",
        "        ckpt_file = run.file(\"checkpoint.ckpt\").download(replace=True)\n",
        "        model = getModelFromCheckpoint(selected_model, ckpt_file.name)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"loading from checkpoint.ckpt failed. Try checkpoint_prev.ckpt\")\n",
        "        ckpt_file = run.file(\"checkpoint_prev.ckpt\").download(replace=True)\n",
        "        model = getModelFromCheckpoint(selected_model, ckpt_file.name)\n",
        "\n",
        "z_size = config.z_size\n",
        "\n",
        "print(\"latent vector z_size:\", z_size)\n",
        "# print(\"class_list:\", config.class_list)\n",
        "print(\"ok!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsk8V5oQiE5"
      },
      "source": [
        "# **SET 2 latent vectors for latent space exploration**\n",
        "\n",
        "## **latent space walk (for VAE/VAEGAN)**\n",
        "\n",
        "### **Required**:\n",
        "\n",
        "The code below requires user to select 2 latent vectors [$z_1$, $z_2$] by manually setting the 2 select latent vector (*latent_1 ($z_1$)* and *latent_2 ($z_2$)*) in the following cell based on the parameter **z_size**. \n",
        "\n",
        "If user wants to specify latent vectors instead of using default vector, user will need to manually CODE the vector in the *latent_1 ($z_1$)* and *latent_2 ($z_2$)* below.\n",
        "\n",
        "If the model is conditional, the class vectors will be appended into the latent vectors. For example, with num_test_samples = 100, the latent vector has shape (100, z_size), and the class index is 2, then the class vector of index 2 will be retrieved from the trained embedding layer and has shape (100, c_dim). The resulting latent vector of the model will be (100, z_size+c_dim).\n",
        "\n",
        "\n",
        "### **Option only available for models with VAE**:\n",
        "\n",
        "The 2 latent vectors [$z_1$, $z_2$] can be specified using the VAE encoder to process **2 meshfiles**, then *latent_1 ($z_1$)* and *latent_2 ($z_2$)* will be skipped.\n",
        "\n",
        "The VAE in the model has 2 components: encoder / decoder.\n",
        "\n",
        "To generate 2 latent vectors [$z_1$, $z_2$]:\n",
        "\n",
        "$3D mesh 1 → encoder → latent \\ space \\ vector \\ z1$\n",
        "\n",
        "$3D mesh 2 → encoder → latent \\ space \\ vector \\ z2$\n",
        "\n",
        "Then, a line between $z_1$ and $z_2$ will be drawn.\n",
        "\n",
        "### **Option only available for conditional models**:\n",
        "\n",
        "The 2 class indices [$c_1$, $c_2$] can be specified here, then the corresponding class vectors [$C_1$, $C_2$] will be retrieved from the trained embedding layer in the model.\n",
        "\n",
        "To generate 2 class vectors [$C_1$, $C_2$]:\n",
        "\n",
        "class index $c_1$ $ → $model embedding layer$ → $class vector $C_1$\n",
        "\n",
        "class index $c_2$ $ → $model embedding layer$ → $class vector $C_2$\n",
        "\n",
        "Then, a line between $C_1$ and $C_2$ will be drawn to be class vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7Pkb0I_lrhW",
        "cellView": "form"
      },
      "source": [
        "#@markdown # SET 2 latent vectors for latent space exploration\n",
        "\n",
        "#@markdown ## For VAEGAN/VAE only: Enter 2 mesh file location to specify 2 latent vectors.   \n",
        "# meshfile1 = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj/obj_files/old_1.obj\" #@param {type:\"string\"}\n",
        "meshfile1 = \"\" #@param {type:\"string\"}\n",
        "# meshfile2 = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Peter/Tree_3D_models_obj/obj_files/maple_example2.obj\" #@param {type:\"string\"}\n",
        "meshfile2 = \"\" #@param {type:\"string\"}\n",
        "#@markdown For all other models, please specify the latent vector in this cell.\n",
        "\n",
        "#@markdown If meshfile above is set, and the model contains VAE, latent vector values below will be replaced.\n",
        "# specify latent vector below. \n",
        "latent_1 = np.ones(z_size)\n",
        "latent_2 = np.ones(z_size)*-1\n",
        "\n",
        "try:\n",
        "    if meshfile1 and hasattr(model, \"vae\"):\n",
        "        latent_1 = get_encoded_vector(model.vae, meshfile1, resolution=config.resolution)\n",
        "    else:\n",
        "        print(\"meshfile1 is empty or model does not contain VAE. Use specified latent_1 vector in the cell.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Error on processing meshfile1, use specified latent_1 vector in the cell.\")\n",
        "\n",
        "try:\n",
        "    if meshfile2 and hasattr(model, \"vae\"):\n",
        "        latent_2 = get_encoded_vector(model.vae, meshfile2, resolution=config.resolution)\n",
        "    else:\n",
        "        print(\"meshfile2 is empty or model does not contain VAE. Use specified latent_2 vector in the cell.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Error on processing meshfile2, use specified latent_2 vector in the cell.\")\n",
        "\n",
        "\n",
        "latent_array = [latent_1, latent_2]\n",
        "print(\"latent_1:\")\n",
        "print(latent_1[:20], \"......\")\n",
        "print(\"latent_2:\")\n",
        "print(latent_2[:20], \"......\")\n",
        "print(f\"linear interpolate {test_num_samples} vectors between these 2 latent vectors\")\n",
        "latent_vectors = np.linspace(latent_array[0], latent_array[1], num=test_num_samples)\n",
        "\n",
        "#@markdown ## For conditional model, specify class index here.\n",
        "class_index1 = 2 #@param {type:\"integer\"}\n",
        "class_index2 =  2#@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "if hasattr(model, \"classifier\"):\n",
        "    print(\"conditional model. Process class index.......\")\n",
        "    if class_index1 == class_index2:\n",
        "        class_index = class_index1\n",
        "        print(f\"class_index:{class_index1}\")\n",
        "    else:\n",
        "        class_index = [class_index1, class_index2]\n",
        "\n",
        "        #process class_index\n",
        "        if hasattr(model, \"vae\"):\n",
        "            embedding_fn = model.vae.embedding\n",
        "        else:\n",
        "            embedding_fn = model.embedding\n",
        "        c_start, c_end = class_index\n",
        "        c_start = embedding_fn(torch.tensor(c_start)).detach().cpu().numpy()\n",
        "        c_end = embedding_fn(torch.tensor(c_end)).detach().cpu().numpy()\n",
        "\n",
        "        class_vectors = np.linspace(c_start, c_end, num=test_num_samples)\n",
        "        print(f\"1st class index:{class_index1}, the class vector is:\")\n",
        "        print(c_start[:20], \"......\")\n",
        "        print(f\"2nd class index:{class_index2}, the class vector is:\")\n",
        "        print(c_end[:20], \"......\")\n",
        "        print(f\"linear interpolate {test_num_samples} vectors between these 2 class vectors\")\n",
        "else:\n",
        "    print(\"unconditional model. Class index will not be processed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1FnA7xRlTY-",
        "cellView": "form"
      },
      "source": [
        "#@markdown generate samples\n",
        "# set saving location\n",
        "temp_location = Path(\"/tmp/generated/\")\n",
        "temp_location.mkdir(parents=True, exist_ok=True)\n",
        "# copy files to export location\n",
        "if export_location:\n",
        "    # create directory\n",
        "    export_location = Path(export_location)\n",
        "    export_location.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "meshes = []\n",
        "batch_size = 8\n",
        "loops = int(np.ceil(test_num_samples/batch_size))\n",
        "for i in range(loops):\n",
        "    start = i*batch_size\n",
        "    end = (i+1)*batch_size \n",
        "    if end > test_num_samples:\n",
        "        end = test_num_samples\n",
        "    latent_vector = latent_vectors[start:end]\n",
        "    try:\n",
        "        if isinstance (class_index, int):\n",
        "            mesh = generateMesh(model, latent_vector, class_index=class_index)\n",
        "        else:\n",
        "            class_vector = class_vectors[start:end]\n",
        "            mesh = generateMesh(model, latent_vector, class_index=class_vector)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"try generate with class_index failed. Try generate without class_index\")\n",
        "        mesh = generateMesh(model, latent_vector, class_index=None)\n",
        "    meshes.append(mesh)\n",
        "meshes = np.concatenate(meshes)\n",
        "\n",
        "#store generated meshes to export_location\n",
        "for n in range(test_num_samples):\n",
        "    sample_tree_array = meshes[n] > 0\n",
        "    voxelmesh = netarray2mesh(sample_tree_array)\n",
        "    save_filename = f\"sample_{n}.obj\"\n",
        "    if export_location:\n",
        "        export_path = export_location / save_filename\n",
        "        voxelmesh.export(file_obj=export_path, file_type=\"obj\")\n",
        "    #if zip, save also to temp_location \n",
        "    if browser_download:\n",
        "        temp_path = temp_location / save_filename\n",
        "        voxelmesh.export(file_obj=temp_path, file_type=\"obj\")\n",
        "\n",
        "\n",
        "#zip files in the directory\n",
        "if not browser_download:\n",
        "    raise Exception(\"will not download files from the browser. Terminate here.\")\n",
        "\n",
        "!zip -r /tmp/file.zip /tmp/generated/\n",
        "from google.colab import files\n",
        "files.download(\"/tmp/file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}