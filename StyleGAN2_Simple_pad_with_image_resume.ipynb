{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2 Simple pad with image resume",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1JgIIo8CQvg",
        "colab_type": "text"
      },
      "source": [
        "# StyleGAN2 Simple pytorch\n",
        "\n",
        "https://github.com/lucidrains/stylegan2-pytorch\n",
        "\n",
        "Make sure you have a GPU runtime!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_q_ADt3E7mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Xgxt9ib0Cu",
        "colab_type": "text"
      },
      "source": [
        "- Set a tag `my_tag` for this experiment in the form, for example your name, dataset whatever else is imporatant.\n",
        "- Or set a path to a `model_N.pt` file as the `resume_from` field. The code will resume training for that model. For example: \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/colab-stylegan2-simple/mathis-pad-double-attn-256/0003/models/stock-images/model_41.pt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPrHZfyCk9Y",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# Set a tag for _your_ experiments, for example your name.\n",
        "my_tag = \"\" #@param {type:\"string\"}\n",
        "\n",
        "dataset = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Research/Daniel/ALL CROP.zip\" #@param {type:\"string\"}\n",
        "\n",
        "resume_from = \"\" #@param {type:\"string\"}\n",
        "\n",
        "desired_size = 256 #@param {type:\"integer\"}\n",
        "\n",
        "name = \"stock-images\" #@param {type: \"string\"}\n",
        "\n",
        "if not resume_from and not my_tag:\n",
        "    raise ValueError(\"Please set 'my_tag' for new experiments or 'resume_from' to continue training.\")\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def print_config(d):\n",
        "    for k, v in sorted(d.items()):\n",
        "        print(f\"=> {k}: {v}\")\n",
        "\n",
        "if resume_from:\n",
        "    resume_path = Path(resume_from)\n",
        "    load_epoch = int(resume_path.name.split('.')[0].split('_')[1])\n",
        "    name = resume_path.parent.name\n",
        "    models_dir = resume_path.parent.parent\n",
        "    results_dir = models_dir.parent.joinpath(\"results\")\n",
        "    print(\"Resuming from checkpoint:\")\n",
        "    print_config(dict(models_dir=models_dir, results_dir=results_dir, name=name, load_epoch=load_epoch))\n",
        "else:\n",
        "    resume_path = None\n",
        "    load_epoch = -1\n",
        "    experiment_dir = f\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/colab-stylegan2-simple/{my_tag}\"\n",
        "    models_dir = Path(experiment_dir).joinpath('models')\n",
        "    results_dir = Path(experiment_dir).joinpath('results')\n",
        "\n",
        "    if Path(experiment_dir).exists():\n",
        "        raise ValueError(f\"The directory {experiment_dir} already exists. Please choose another 'my_tag' to avoid overwriting.\")\n",
        "        \n",
        "    print(f\"Running new experiment:\")\n",
        "    print_config(dict(models_dir=models_dir, results_dir=results_dir, name=name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S8o4e5bmnBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check with GPU we have, P100 is the fast one\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPh88XCjFLCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rsync -avP \"$dataset\" /content/dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jrx_RAFFWvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_dir = \"dataset_extracted\"\n",
        "!unzip -q dataset.zip -d $extract_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11wEwkabjqqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "resize_dir = 'dataset_resized'\n",
        "\n",
        "# 'crop' or 'pad'\n",
        "resize_method = 'pad'\n",
        "\n",
        "files = list(Path(extract_dir).rglob(\"*.*\"))\n",
        "\n",
        "for path in tqdm(files):\n",
        "    im = Image.open(path)\n",
        "    relative_path = path.relative_to(extract_dir)\n",
        "\n",
        "    old_size = im.size \n",
        "    ratio = float(desired_size) / (max(old_size) if resize_method == 'pad' else min(old_size)) \n",
        "    new_size = tuple([int(x * ratio) for x in old_size])\n",
        "    im = im.resize(new_size, Image.ANTIALIAS)\n",
        "    # create a new image and paste the resized on it\n",
        "\n",
        "    imResize = Image.new(\"RGB\", (desired_size, desired_size), color=(0, 0, 0, 255))\n",
        "    imResize.paste(im, ((desired_size - new_size[0]) // 2, new_size[1]))\n",
        "    imResize.paste(im, ((desired_size - new_size[0]) // 2, 0))\n",
        "    destination = Path(resize_dir).joinpath(relative_path)\n",
        "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
        "    imResize.save(destination, 'JPEG', quality=99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFkwQK4wkMo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check a few images to make sure we didn't mess them up.\n",
        "\n",
        "from IPython.display import Image\n",
        "for img in list(Path(resize_dir).rglob(\"*.*\"))[:3]:\n",
        "    print(img)\n",
        "    display(Image(str(img)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6R2Nrc5FbcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install stylegan2_pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBJrd7hfFov7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "from stylegan2_pytorch import Trainer, NanException\n",
        "from datetime import datetime\n",
        "\n",
        "data = resize_dir\n",
        "\n",
        "new = False\n",
        "load_from = -1\n",
        "image_size = 128\n",
        "network_capacity = 16\n",
        "transparent = False\n",
        "batch_size = 3\n",
        "gradient_accumulate_every = 5\n",
        "num_train_steps = 150000\n",
        "learning_rate = 2e-4\n",
        "num_workers =  None\n",
        "save_every = 1000\n",
        "generate = False\n",
        "generate_interpolation = False\n",
        "save_frames = False\n",
        "num_image_tiles = 8\n",
        "trunc_psi = 0.75\n",
        "fp16 = False\n",
        "cl_reg = False\n",
        "fq_layers = []\n",
        "fq_dict_size = 256\n",
        "attn_layers = []\n",
        "no_const = False\n",
        "aug_prob = 0.\n",
        "dataset_aug_prob = 0.\n",
        "\n",
        "model = Trainer(\n",
        "    name,        \n",
        "    results_dir,\n",
        "    models_dir,\n",
        "    batch_size = batch_size,\n",
        "    gradient_accumulate_every = gradient_accumulate_every,\n",
        "    image_size = image_size,\n",
        "    network_capacity = network_capacity,\n",
        "    transparent = transparent,\n",
        "    lr = learning_rate,\n",
        "    num_workers = num_workers,\n",
        "    save_every = save_every,\n",
        "    trunc_psi = trunc_psi,\n",
        "    fp16 = fp16,\n",
        "    cl_reg = cl_reg,\n",
        "    fq_layers = fq_layers,\n",
        "    fq_dict_size = fq_dict_size,\n",
        "    attn_layers = attn_layers,\n",
        "    no_const = no_const,\n",
        "    aug_prob = aug_prob,\n",
        "    dataset_aug_prob = dataset_aug_prob,\n",
        ")\n",
        "\n",
        "if load_from:\n",
        "    model.load(load_from)\n",
        "else:\n",
        "    model.clear()\n",
        "\n",
        "model.set_data_src(data)\n",
        "\n",
        "for _ in tqdm(range(num_train_steps - model.steps), mininterval=10., desc=f'{name}<{data}>'):\n",
        "    model.train()\n",
        "    if _ % 50 == 0:\n",
        "        model.print_log()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E39OkS1TdKvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}